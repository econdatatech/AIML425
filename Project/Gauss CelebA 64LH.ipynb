{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Get precalculated wavelet data LH"
      ],
      "metadata": {
        "id": "rWK1n8NoPk1V"
      },
      "id": "rWK1n8NoPk1V"
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticate and create the PyDrive client\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"15KFbRlG18QAMyzQ9__fblp0iRhz0ItGq\"})   \n",
        "downloaded.GetContentFile('LH.zip')  "
      ],
      "metadata": {
        "id": "e6sDe7B6PjaC"
      },
      "id": "e6sDe7B6PjaC",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "145012dc",
      "metadata": {
        "id": "145012dc",
        "outputId": "90d7fdb6-6861-401e-9bec-44616b039a6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cold-Diffusion-Models'...\n",
            "remote: Enumerating objects: 262, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 262 (delta 47), reused 38 (delta 33), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (262/262), 2.65 MiB | 14.29 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arpitbansal297/Cold-Diffusion-Models.git\n",
        "!apt-get install unzip\n",
        "!unzip -q -j LH.zip -d ./root_celebA_128_train_new_LH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22708788",
      "metadata": {
        "id": "22708788",
        "outputId": "52ed02f3-9cae-448f-d598-72b31f1a7314"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml einops tqdm torchgeometry matplotlib einops scikit-image sklearn pywavelets --quiet\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "import pywt\n",
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/')\n",
        "from comet_ml import Experiment\n",
        "import torchvision\n",
        "import os\n",
        "import errno\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c9d149",
      "metadata": {
        "id": "d0c9d149"
      },
      "outputs": [],
      "source": [
        "# %load 'Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py'\n",
        "from comet_ml import Experiment\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "from torch.utils import data\n",
        "from pathlib import Path\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange\n",
        "\n",
        "import torchgeometry as tgm\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch import linalg as LA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "try:\n",
        "    from apex import amp\n",
        "    APEX_AVAILABLE = True\n",
        "except:\n",
        "    APEX_AVAILABLE = False\n",
        "\n",
        "# helpers functions\n",
        "\n",
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if isfunction(d) else d\n",
        "\n",
        "def cycle(dl):\n",
        "    while True:\n",
        "        for data in dl:\n",
        "            yield data\n",
        "\n",
        "def num_to_groups(num, divisor):\n",
        "    groups = num // divisor\n",
        "    remainder = num % divisor\n",
        "    arr = [divisor] * groups\n",
        "    if remainder > 0:\n",
        "        arr.append(remainder)\n",
        "    return arr\n",
        "\n",
        "def loss_backwards(fp16, loss, optimizer, **kwargs):\n",
        "    if fp16:\n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "            scaled_loss.backward(**kwargs)\n",
        "    else:\n",
        "        loss.backward(**kwargs)\n",
        "\n",
        "# small helper modules\n",
        "\n",
        "class EMA():\n",
        "    def __init__(self, beta):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def update_model_average(self, ma_model, current_model):\n",
        "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
        "            old_weight, up_weight = ma_params.data, current_params.data\n",
        "            ma_params.data = self.update_average(old_weight, up_weight)\n",
        "\n",
        "    def update_average(self, old, new):\n",
        "        if old is None:\n",
        "            return new\n",
        "        return old * self.beta + (1 - self.beta) * new\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "def Upsample(dim):\n",
        "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "def Downsample(dim):\n",
        "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim, eps = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
        "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
        "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
        "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)\n",
        "\n",
        "# building block modules\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    \"\"\" https://arxiv.org/abs/2201.03545 \"\"\"\n",
        "\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim = None, mult = 2, norm = True):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_emb_dim, dim)\n",
        "        ) if exists(time_emb_dim) else None\n",
        "\n",
        "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding = 3, groups = dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            LayerNorm(dim) if norm else nn.Identity(),\n",
        "            nn.Conv2d(dim, dim_out * mult, 3, padding = 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim_out * mult, dim_out, 3, padding = 1)\n",
        "        )\n",
        "\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb = None):\n",
        "        h = self.ds_conv(x)\n",
        "\n",
        "        if exists(self.mlp):\n",
        "            assert exists(time_emb), 'time emb must be passed in'\n",
        "            condition = self.mlp(time_emb)\n",
        "            h = h + rearrange(condition, 'b c -> b c 1 1')\n",
        "\n",
        "        h = self.net(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
        "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
        "        q = q * self.scale\n",
        "\n",
        "        k = k.softmax(dim = -1)\n",
        "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
        "\n",
        "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
        "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "# model\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 3,\n",
        "        with_time_emb = True,\n",
        "        residual = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.residual = residual\n",
        "        print(\"Is Time embed used ? \", with_time_emb)\n",
        "\n",
        "        dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        if with_time_emb:\n",
        "            time_dim = dim\n",
        "            self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPosEmb(dim),\n",
        "                nn.Linear(dim, dim * 4),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(dim * 4, dim)\n",
        "            )\n",
        "        else:\n",
        "            time_dim = None\n",
        "            self.time_mlp = None\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_in, dim_out, time_emb_dim = time_dim, norm = ind != 0),\n",
        "                ConvNextBlock(dim_out, dim_out, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                Downsample(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim)))\n",
        "        self.mid_block2 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_out * 2, dim_in, time_emb_dim = time_dim),\n",
        "                ConvNextBlock(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                Upsample(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        out_dim = default(out_dim, channels)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            ConvNextBlock(dim, dim),\n",
        "            nn.Conv2d(dim, out_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        orig_x = x\n",
        "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
        "\n",
        "        h = []\n",
        "\n",
        "        for convnext, convnext2, attn, downsample in self.downs:\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        for convnext, convnext2, attn, upsample in self.ups:\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            x = upsample(x)\n",
        "        if self.residual:\n",
        "            return self.final_conv(x) + orig_x\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# gaussian diffusion trainer class\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "def noise_like(shape, device, repeat=False):\n",
        "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n",
        "    noise = lambda: torch.randn(shape, device=device)\n",
        "    return repeat_noise() if repeat else noise()\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s = 0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule\n",
        "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, steps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "class GaussianDiffusion(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        denoise_fn,\n",
        "        *,\n",
        "        image_size,\n",
        "        channels = 3,\n",
        "        timesteps = 1000,\n",
        "        loss_type = 'l1',\n",
        "        train_routine = 'Final',\n",
        "        sampling_routine='default',\n",
        "        discrete=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.denoise_fn = denoise_fn\n",
        "\n",
        "        self.num_timesteps = int(timesteps)\n",
        "        self.loss_type = loss_type\n",
        "\n",
        "        betas = cosine_beta_schedule(timesteps)\n",
        "        alphas = 1. - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
        "\n",
        "        self.train_routine = train_routine\n",
        "        self.sampling_routine = sampling_routine\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, batch_size = 16, img=None, t=None):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        xt = img\n",
        "        direct_recons = None\n",
        "\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            if direct_recons is None:\n",
        "                direct_recons = x1_bar\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        self.denoise_fn.train()\n",
        "\n",
        "        return xt, direct_recons, img\n",
        "\n",
        "    def get_x2_bar_from_xt(self, x1_bar, xt, t):\n",
        "        return (\n",
        "                (xt - extract(self.sqrt_alphas_cumprod, t, x1_bar.shape) * x1_bar) /\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x1_bar.shape)\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def gen_sample(self, batch_size=16, img=None, t=None):\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        noise = img\n",
        "        direct_recons = None\n",
        "\n",
        "        if self.sampling_routine == 'ddim':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        elif self.sampling_routine == 'x0_step_down':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = noise\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        return noise, direct_recons, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward_and_backward(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        Forward = []\n",
        "        Forward.append(img)\n",
        "\n",
        "        noise = torch.randn_like(img)\n",
        "\n",
        "        for i in range(t):\n",
        "            with torch.no_grad():\n",
        "                step = torch.full((batch_size,), i, dtype=torch.long, device=img.device)\n",
        "                n_img = self.q_sample(x_start=img, x_end=noise, t=step)\n",
        "                Forward.append(n_img)\n",
        "\n",
        "        Backward = []\n",
        "        img = n_img\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = noise #self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            Backward.append(img)\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return Forward, Backward, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def all_sample(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        if eval:\n",
        "            self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        X1_0s, X2_0s, X_ts = [], [], []\n",
        "        while (t):\n",
        "\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "\n",
        "            X1_0s.append(x1_bar.detach().cpu())\n",
        "            X2_0s.append(x2_bar.detach().cpu())\n",
        "            X_ts.append(img.detach().cpu())\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return X1_0s, X2_0s, X_ts\n",
        "\n",
        "    def q_sample(self, x_start, x_end, t):\n",
        "        # simply use the alphas to interpolate\n",
        "        return (\n",
        "                extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * x_end\n",
        "        )\n",
        "\n",
        "    def p_losses(self, x_start, x_end, t):\n",
        "        b, c, h, w = x_start.shape\n",
        "        if self.train_routine == 'Final':\n",
        "            x_mix = self.q_sample(x_start=x_start, x_end=x_end, t=t)\n",
        "            x_recon = self.denoise_fn(x_mix, t)\n",
        "            if self.loss_type == 'l1':\n",
        "                loss = (x_start - x_recon).abs().mean()\n",
        "            elif self.loss_type == 'l2':\n",
        "                loss = F.mse_loss(x_start, x_recon)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x1, x2, *args, **kwargs):\n",
        "        b, c, h, w, device, img_size, = *x1.shape, x1.device, self.image_size\n",
        "        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n",
        "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
        "        return self.p_losses(x1, x2, t, *args, **kwargs)\n",
        "\n",
        "class Dataset_Aug1(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts = ['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.RandomCrop(image_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts=['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "# trainer class\n",
        "import os\n",
        "import errno\n",
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "from collections import OrderedDict\n",
        "def remove_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('.module', '')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "def adjust_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('denoise_fn.module', 'module.denoise_fn')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        diffusion_model,\n",
        "        folder,\n",
        "        *,\n",
        "        ema_decay = 0.995,\n",
        "        image_size = 128,\n",
        "        train_batch_size = 32,\n",
        "        train_lr = 2e-5,\n",
        "        train_num_steps = 100000,\n",
        "        gradient_accumulate_every = 2,\n",
        "        fp16 = False,\n",
        "        step_start_ema = 2000,\n",
        "        update_ema_every = 10,\n",
        "        save_and_sample_every = 1000,\n",
        "        results_folder = './results',\n",
        "        load_path = None,\n",
        "        dataset = None,\n",
        "        shuffle=True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = diffusion_model\n",
        "        self.ema = EMA(ema_decay)\n",
        "        self.ema_model = copy.deepcopy(self.model)\n",
        "        self.update_ema_every = update_ema_every\n",
        "\n",
        "        self.step_start_ema = step_start_ema\n",
        "        self.save_and_sample_every = save_and_sample_every\n",
        "\n",
        "        self.batch_size = train_batch_size\n",
        "        self.image_size = image_size\n",
        "        self.gradient_accumulate_every = gradient_accumulate_every\n",
        "        self.train_num_steps = train_num_steps\n",
        "\n",
        "        if dataset == 'train':\n",
        "            print(dataset, \"DA used\")\n",
        "            self.ds = Dataset_Aug1(folder, image_size)\n",
        "        else:\n",
        "            print(dataset)\n",
        "            self.ds = Dataset(folder, image_size)\n",
        "\n",
        "        self.dl = cycle(data.DataLoader(self.ds, batch_size = train_batch_size, shuffle=shuffle, pin_memory=True, num_workers=16, drop_last=True))\n",
        "\n",
        "        self.opt = Adam(diffusion_model.parameters(), lr=train_lr)\n",
        "        self.step = 0\n",
        "\n",
        "        self.results_folder = Path(results_folder)\n",
        "        self.results_folder.mkdir(exist_ok = True)\n",
        "\n",
        "        self.fp16 = fp16\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "        if load_path != None:\n",
        "            self.load(load_path)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.ema_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def step_ema(self):\n",
        "        if self.step < self.step_start_ema:\n",
        "            self.reset_parameters()\n",
        "            return\n",
        "        self.ema.update_model_average(self.ema_model, self.model)\n",
        "\n",
        "    def save(self, itrs=None):\n",
        "        data = {\n",
        "            'step': self.step,\n",
        "            'model': self.model.state_dict(),\n",
        "            'ema': self.ema_model.state_dict()\n",
        "        }\n",
        "        if itrs is None:\n",
        "            torch.save(data, str(self.results_folder / f'model.pt'))\n",
        "        else:\n",
        "            torch.save(data, str(self.results_folder / f'model_{itrs}.pt'))\n",
        "\n",
        "    def load(self, load_path):\n",
        "        print(\"Loading : \", load_path)\n",
        "        data = torch.load(load_path)\n",
        "\n",
        "        self.step = data['step']\n",
        "        self.model.load_state_dict(data['model'])\n",
        "        self.ema_model.load_state_dict(data['ema'])\n",
        "\n",
        "\n",
        "    def add_title(self, path, title):\n",
        "\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        img1 = cv2.imread(path)\n",
        "\n",
        "        # --- Here I am creating the border---\n",
        "        black = [0, 0, 0]  # ---Color of the border---\n",
        "        constant = cv2.copyMakeBorder(img1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "        height = 20\n",
        "        violet = np.zeros((height, constant.shape[1], 3), np.uint8)\n",
        "        violet[:] = (255, 0, 180)\n",
        "\n",
        "        vcat = cv2.vconcat((violet, constant))\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        cv2.putText(vcat, str(title), (violet.shape[1] // 2, height-2), font, 0.5, (0, 0, 0), 1, 0)\n",
        "        cv2.imwrite(path, vcat)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        backwards = partial(loss_backwards, self.fp16)\n",
        "\n",
        "        acc_loss = 0\n",
        "        while self.step < self.train_num_steps:\n",
        "            u_loss = 0\n",
        "            for i in range(self.gradient_accumulate_every):\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "\n",
        "                data_1, data_2 = data_1.cuda(), data_2.cuda()\n",
        "                loss = torch.mean(self.model(data_1, data_2))\n",
        "                if self.step % 100 == 0:\n",
        "                    print(f'{self.step}: {loss.item()}')\n",
        "                u_loss += loss.item()\n",
        "                backwards(loss / self.gradient_accumulate_every, self.opt)\n",
        "\n",
        "            acc_loss = acc_loss + (u_loss/self.gradient_accumulate_every)\n",
        "\n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "            if self.step % self.update_ema_every == 0:\n",
        "                self.step_ema()\n",
        "\n",
        "            if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
        "                milestone = self.step // self.save_and_sample_every\n",
        "                batches = self.batch_size\n",
        "\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "                og_img = data_2.cuda()\n",
        "\n",
        "                xt, direct_recons, all_images = self.ema_model.module.sample(batch_size=batches, img=og_img)\n",
        "\n",
        "                og_img = (og_img + 1) * 0.5\n",
        "                utils.save_image(og_img, str(self.results_folder / f'sample-og-{milestone}.png'), nrow=6)\n",
        "\n",
        "                all_images = (all_images + 1) * 0.5\n",
        "                utils.save_image(all_images, str(self.results_folder / f'sample-recon-{milestone}.png'), nrow = 6)\n",
        "\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'sample-direct_recons-{milestone}.png'), nrow=6)\n",
        "\n",
        "                xt = (xt + 1) * 0.5\n",
        "                utils.save_image(xt, str(self.results_folder / f'sample-xt-{milestone}.png'),\n",
        "                                 nrow=6)\n",
        "\n",
        "                acc_loss = acc_loss/(self.save_and_sample_every+1)\n",
        "                print(f'Mean of last {self.step}: {acc_loss}')\n",
        "                acc_loss=0\n",
        "\n",
        "                self.save()\n",
        "                if self.step % (self.save_and_sample_every * 100) == 0:\n",
        "                    self.save(self.step)\n",
        "\n",
        "            self.step += 1\n",
        "\n",
        "        print('training completed')\n",
        "\n",
        "    def test_from_data(self, extra_path, s_times=None):\n",
        "        batches = self.batch_size\n",
        "        og_img = next(self.dl).cuda()\n",
        "        X_0s, X_ts = self.ema_model.module.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images, str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "    def sample_and_save_for_fid(self, noise=0):\n",
        "\n",
        "        # xt_folder = f'{self.results_folder}_xt'\n",
        "        # create_folder(xt_folder)\n",
        "\n",
        "        out_folder = f'{self.results_folder}_out'\n",
        "        create_folder(out_folder)\n",
        "\n",
        "        # direct_recons_folder = f'{self.results_folder}_dir_recons'\n",
        "        # create_folder(direct_recons_folder)\n",
        "\n",
        "        # data_1 = next(self.dl)\n",
        "\n",
        "        cnt = 0\n",
        "        bs = 128\n",
        "        for j in range(int(6400/bs)):\n",
        "\n",
        "            data_2 = torch.randn(bs, 3, 128, 128)\n",
        "            og_img = data_2.cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            xt, direct_recons, all_images = self.ema_model.module.gen_sample(batch_size=bs, img=og_img)\n",
        "\n",
        "            for i in range(all_images.shape[0]):\n",
        "                utils.save_image((all_images[i] + 1) * 0.5,\n",
        "                                 str(f'{out_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                # utils.save_image((xt[i] + 1) * 0.5,\n",
        "                #                  str(f'{xt_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                #\n",
        "                # utils.save_image((direct_recons[i] + 1) * 0.5,\n",
        "                #                  str(f'{direct_recons_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images_cover_page(self):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # for 200 steps\n",
        "        # to_show = [2, 4, 8, 16, 32, 64, 128, 192]\n",
        "        to_show = [2, 4, 16, 64, 128, 256, 384, 448, 480]\n",
        "\n",
        "        for i in range(5):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            Forward, Backward, final_all = self.ema_model.module.forward_and_backward(batch_size=batches, img=og_img)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            final_all = (final_all + 1) * 0.5\n",
        "\n",
        "\n",
        "\n",
        "            for k in range(Forward[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                utils.save_image(og_img[k], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "                start = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "                l.append(start)\n",
        "\n",
        "                for j in range(len(Forward)):\n",
        "                    x_t = Forward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "                for j in range(len(Backward)):\n",
        "                    x_t = Backward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if (len(Backward) - j) in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                utils.save_image(final_all[k], str(self.results_folder / f'final_{cnt}.png'), nrow=1)\n",
        "                final = cv2.imread(f'{self.results_folder}/final_{cnt}.png')\n",
        "                l.append(final)\n",
        "\n",
        "\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_invert_section_images(self, s_times=None):\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for j in range(og_img.shape[0]//3):\n",
        "                original = og_img[j: j + 1]\n",
        "                utils.save_image(original, str(self.results_folder / f'original_{cnt}.png'), nrow=3)\n",
        "\n",
        "                direct_recons = X_0s[0][j: j + 1]\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'direct_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                sampling_recons = X_0s[-1][j: j + 1]\n",
        "                sampling_recons = (sampling_recons + 1) * 0.5\n",
        "                utils.save_image(sampling_recons, str(self.results_folder / f'sampling_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                blurry_image = X_ts[0][j: j + 1]\n",
        "                blurry_image = (blurry_image + 1) * 0.5\n",
        "                utils.save_image(blurry_image, str(self.results_folder / f'blurry_image_{cnt}.png'), nrow=3)\n",
        "\n",
        "\n",
        "\n",
        "                import cv2\n",
        "\n",
        "                blurry_image = cv2.imread(f'{self.results_folder}/blurry_image_{cnt}.png')\n",
        "                direct_recons = cv2.imread(f'{self.results_folder}/direct_recons_{cnt}.png')\n",
        "                sampling_recons = cv2.imread(f'{self.results_folder}/sampling_recons_{cnt}.png')\n",
        "                original = cv2.imread(f'{self.results_folder}/original_{cnt}.png')\n",
        "\n",
        "                black = [0, 0, 0]\n",
        "                blurry_image = cv2.copyMakeBorder(blurry_image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                direct_recons = cv2.copyMakeBorder(direct_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                sampling_recons = cv2.copyMakeBorder(sampling_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                original = cv2.copyMakeBorder(original, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([blurry_image, direct_recons, sampling_recons, original])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 24, 32, 40, 44, 46, 48, 49]\n",
        "        to_show = [0, 2, 4, 8, 16, 32, 64, 80, 88, 92, 96, 98, 99]\n",
        "\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for k in range(X_ts[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                for j in range(len(X_ts)):\n",
        "                    x_t = X_ts[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'x_{len(X_ts)-j}_{cnt}.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/x_{len(X_ts)-j}_{cnt}.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                x_0 = X_0s[-1][k]\n",
        "                x_0 = (x_0 + 1) * 0.5\n",
        "                utils.save_image(x_0, str(self.results_folder / f'x_best_{cnt}.png'), nrow=1)\n",
        "                x_0 = cv2.imread(f'{self.results_folder}/x_best_{cnt}.png')\n",
        "                l.append(x_0)\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_showing_diffusion_images_diff(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, X_ts_alg2 = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "            X_0s_alg1, X_ts_alg1 = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            alg2 = []\n",
        "            alg1 = []\n",
        "\n",
        "            #to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "            to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "\n",
        "            for j in range(len(X_ts_alg2)):\n",
        "                x_t = X_ts_alg2[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg2)-j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg2)-j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg2.append(x_t)\n",
        "\n",
        "                x_t = X_ts_alg1[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg1) - j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg1) - j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg1.append(x_t)\n",
        "\n",
        "\n",
        "            x_0 = X_0s_alg2[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg2_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg2_{i}.png')\n",
        "            alg2.append(x_0)\n",
        "            im_h = cv2.hconcat(alg2)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg2_{i}.png', im_h)\n",
        "\n",
        "            x_0 = X_0s_alg1[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg1_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg1_{i}.png')\n",
        "            alg1.append(x_0)\n",
        "            im_h = cv2.hconcat(alg1)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg1_{i}.png', im_h)\n",
        "\n",
        "\n",
        "    def paper_showing_sampling_diff_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        for i in range(10):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, _ = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches, img=og_img, times=s_times)\n",
        "            X_0s_alg1, _ = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            x0_alg1 = (X_0s_alg1[-1] + 1) * 0.5\n",
        "            x0_alg2 = (X_0s_alg2[-1] + 1) * 0.5\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "\n",
        "            for j in range(og_img.shape[0]):\n",
        "                utils.save_image(x0_alg1[j], str(self.results_folder / f'x0_alg1_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(x0_alg2[j], str(self.results_folder / f'x0_alg2_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(og_img[j], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "\n",
        "\n",
        "\n",
        "                alg1 = cv2.imread(f'{self.results_folder}/x0_alg1_{cnt}.png')\n",
        "                alg2 = cv2.imread(f'{self.results_folder}/x0_alg2_{cnt}.png')\n",
        "                og = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "\n",
        "\n",
        "                black = [255, 255, 255]\n",
        "                alg1 = cv2.copyMakeBorder(alg1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                alg2 = cv2.copyMakeBorder(alg2, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                og = cv2.copyMakeBorder(og, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([og, alg1, alg2])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def sample_as_a_vector_gmm(self, start=0, end=1000, siz=64, ch=3, clusters=10):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "\n",
        "        num_samples = 100\n",
        "\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "        og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "        og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "        og_x = torch.from_numpy(og_x).cuda()\n",
        "        og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "        print(og_x.shape)\n",
        "        og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "\n",
        "\n",
        "        X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "        extra_path = 'vec'\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{start}-{end}-{siz}-{clusters}-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'),\n",
        "                             nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images,\n",
        "                             str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_gmm_and_save(self, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 10000\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "            og_x = torch.from_numpy(og_x).cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "        all_samples = None\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "\n",
        "        #all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num / num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/')\n",
        "\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            #og_x, _ = model.sample(n=num_samples)\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            blurs = X_ts[0]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((blurs[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/' + f'sample-blur-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "    def sample_as_a_vector_from_blur_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "\n",
        "        #sample_at = self.ema_model.num_timesteps // 2\n",
        "        sample_at = self.ema_model.num_timesteps // 2\n",
        "        all_samples = None\n",
        "\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = self.ema_model.opt(img.cuda(), t=sample_at)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "                #all_samples.append(img[0])\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        # all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}_{sample_at}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample_from_blur(batch_size=og_img.shape[0], img=og_img, start_times=sample_at)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "\n",
        "\n",
        "\n",
        "    def sample_from_data_save(self, start=0, end=1000):\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 1000]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "    def fid_distance_decrease_from_manifold(self, fid_func, start=0, end=1000):\n",
        "\n",
        "        #from skimage.metrics import structural_similarity as ssim\n",
        "        from pytorch_msssim import ssim\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        # create_folder(f'{self.results_folder}/')\n",
        "        blurred_samples = None\n",
        "        original_sample = None\n",
        "        deblurred_samples = None\n",
        "        direct_deblurred_samples = None\n",
        "\n",
        "        sanity_check = 1\n",
        "\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 100]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            og_img = og_img.to('cpu')\n",
        "            blurry_imgs = X_ts[0].to('cpu')\n",
        "            deblurry_imgs = X_0s[-1].to('cpu')\n",
        "            direct_deblurry_imgs = X_0s[0].to('cpu')\n",
        "\n",
        "            og_img = og_img.repeat(1, 3 // og_img.shape[1], 1, 1)\n",
        "            blurry_imgs = blurry_imgs.repeat(1, 3 // blurry_imgs.shape[1], 1, 1)\n",
        "            deblurry_imgs = deblurry_imgs.repeat(1, 3 // deblurry_imgs.shape[1], 1, 1)\n",
        "            direct_deblurry_imgs = direct_deblurry_imgs.repeat(1, 3 // direct_deblurry_imgs.shape[1], 1, 1)\n",
        "\n",
        "\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            blurry_imgs = (blurry_imgs + 1) * 0.5\n",
        "            deblurry_imgs = (deblurry_imgs + 1) * 0.5\n",
        "            direct_deblurry_imgs = (direct_deblurry_imgs + 1) * 0.5\n",
        "\n",
        "            if cnt == 0:\n",
        "                print(og_img.shape)\n",
        "                print(blurry_imgs.shape)\n",
        "                print(deblurry_imgs.shape)\n",
        "                print(direct_deblurry_imgs.shape)\n",
        "\n",
        "                if sanity_check:\n",
        "                    folder = './sanity_check/'\n",
        "                    create_folder(folder)\n",
        "\n",
        "                    san_imgs = og_img[0: 32]\n",
        "                    utils.save_image(san_imgs,str(folder + f'sample-og.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = blurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-xt.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-recons.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = direct_deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-direct-recons.png'), nrow=6)\n",
        "\n",
        "\n",
        "            if blurred_samples is None:\n",
        "                blurred_samples = blurry_imgs\n",
        "            else:\n",
        "                blurred_samples = torch.cat((blurred_samples, blurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if original_sample is None:\n",
        "                original_sample = og_img\n",
        "            else:\n",
        "                original_sample = torch.cat((original_sample, og_img), dim=0)\n",
        "\n",
        "\n",
        "            if deblurred_samples is None:\n",
        "                deblurred_samples = deblurry_imgs\n",
        "            else:\n",
        "                deblurred_samples = torch.cat((deblurred_samples, deblurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if direct_deblurred_samples is None:\n",
        "                direct_deblurred_samples = direct_deblurry_imgs\n",
        "            else:\n",
        "                direct_deblurred_samples = torch.cat((direct_deblurred_samples, direct_deblurry_imgs), dim=0)\n",
        "\n",
        "            cnt += og_img.shape[0]\n",
        "\n",
        "        print(blurred_samples.shape)\n",
        "        print(original_sample.shape)\n",
        "        print(deblurred_samples.shape)\n",
        "        print(direct_deblurred_samples.shape)\n",
        "\n",
        "        fid_blur = fid_func(samples=[original_sample, blurred_samples])\n",
        "        rmse_blur = torch.sqrt(torch.mean( (original_sample - blurred_samples)**2 ))\n",
        "        ssim_blur = ssim(original_sample, blurred_samples, data_range=1, size_average=True)\n",
        "        # n_og = original_sample.cpu().detach().numpy()\n",
        "        # n_bs = blurred_samples.cpu().detach().numpy()\n",
        "        # ssim_blur = ssim(n_og, n_bs, data_range=n_og.max() - n_og.min(), multichannel=True)\n",
        "        print(f'The FID of blurry images with original image is {fid_blur}')\n",
        "        print(f'The RMSE of blurry images with original image is {rmse_blur}')\n",
        "        print(f'The SSIM of blurry images with original image is {ssim_blur}')\n",
        "\n",
        "\n",
        "        fid_deblur = fid_func(samples=[original_sample, deblurred_samples])\n",
        "        rmse_deblur = torch.sqrt(torch.mean((original_sample - deblurred_samples) ** 2))\n",
        "        ssim_deblur = ssim(original_sample, deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of deblurred images with original image is {fid_deblur}')\n",
        "        print(f'The RMSE of deblurred images with original image is {rmse_deblur}')\n",
        "        print(f'The SSIM of deblurred images with original image is {ssim_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using sampling is {fid_blur - fid_deblur}')\n",
        "\n",
        "        fid_direct_deblur = fid_func(samples=[original_sample, direct_deblurred_samples])\n",
        "        rmse_direct_deblur = torch.sqrt(torch.mean((original_sample - direct_deblurred_samples) ** 2))\n",
        "        ssim_direct_deblur = ssim(original_sample, direct_deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of direct deblurred images with original image is {fid_direct_deblur}')\n",
        "        print(f'The RMSE of direct deblurred images with original image is {rmse_direct_deblur}')\n",
        "        print(f'The SSIM of direct deblurred images with original image is {ssim_direct_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using direct sampling is {fid_blur - fid_direct_deblur}')\n",
        "\n",
        "\n",
        "            # x0s = X_0s[-1]\n",
        "            # for i in range(x0s.shape[0]):\n",
        "            #     utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "            #     cnt += 1\n",
        "\n",
        "    def save_training_data(self):\n",
        "        dataset = self.ds\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = (img + 1) * 0.5\n",
        "            utils.save_image(img, str(f'{self.results_folder}/' + f'{idx}.png'))\n",
        "            if idx%1000 == 0:\n",
        "                print(idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d076ce5c",
      "metadata": {
        "id": "d076ce5c"
      },
      "outputs": [],
      "source": [
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "def del_folder(path):\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "    except OSError as exc:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafcb743",
      "metadata": {
        "id": "eafcb743",
        "outputId": "9e6bc6bd-6a32-4aab-affa-810b64cbd70e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Time embed used ?  False\n",
            "LH\n"
          ]
        }
      ],
      "source": [
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA\"\n",
        "data_path=\"./root_celebA_128_train_new_LH/\"\n",
        "load_path=None\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine =  train_routine,\n",
        "    sampling_routine =  sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    folder=data_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps =  train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder =  save_folder,\n",
        "    load_path =  load_path,\n",
        "    dataset = 'LH'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740da495",
      "metadata": {
        "id": "740da495",
        "outputId": "623716f8-94e7-4c3f-802c-9188b4561903"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 0.5435109734535217\n",
            "0: 0.5826095342636108\n",
            "100: 0.500806987285614\n",
            "100: 0.42192935943603516\n",
            "200: 0.3470733165740967\n",
            "200: 0.30293387174606323\n",
            "300: 0.25665944814682007\n",
            "300: 0.24431610107421875\n",
            "400: 0.19214722514152527\n",
            "400: 0.2179042100906372\n",
            "500: 0.1448388248682022\n",
            "500: 0.1637708693742752\n",
            "600: 0.13616159558296204\n",
            "600: 0.1332421749830246\n",
            "700: 0.12977585196495056\n",
            "700: 0.12230914831161499\n",
            "800: 0.111881785094738\n",
            "800: 0.12279799580574036\n",
            "900: 0.11351288855075836\n",
            "900: 0.138203963637352\n",
            "1000: 0.10549648851156235\n",
            "1000: 0.10463960468769073\n",
            "Mean of last 1000: 0.22216191066505311\n",
            "1100: 0.12187399715185165\n",
            "1100: 0.0978841632604599\n",
            "1200: 0.10825991630554199\n",
            "1200: 0.10828986018896103\n",
            "1300: 0.10272135585546494\n",
            "1300: 0.08922569453716278\n",
            "1400: 0.10692156851291656\n",
            "1400: 0.10425931215286255\n",
            "1500: 0.10007433593273163\n",
            "1500: 0.0992986261844635\n",
            "1900: 0.09802266210317612\n",
            "1900: 0.09295105934143066\n",
            "2000: 0.08641322702169418\n",
            "2000: 0.09092091023921967\n",
            "Mean of last 2000: 0.10014600833723476\n",
            "2100: 0.10178421437740326\n",
            "2100: 0.09576549381017685\n",
            "2200: 0.09604378789663315\n",
            "2200: 0.09558399766683578\n",
            "2300: 0.09050768613815308\n",
            "2300: 0.08256660401821136\n",
            "2400: 0.08984346687793732\n",
            "2400: 0.10205890238285065\n",
            "2500: 0.0941677987575531\n",
            "2500: 0.08674207329750061\n",
            "2600: 0.08409920334815979\n",
            "2600: 0.09431030601263046\n",
            "2700: 0.08522260189056396\n",
            "2700: 0.09881776571273804\n",
            "2800: 0.0935530811548233\n",
            "2800: 0.08940776437520981\n",
            "2900: 0.09101244062185287\n",
            "2900: 0.08776609599590302\n",
            "3000: 0.07743346691131592\n",
            "3000: 0.09084583818912506\n",
            "Mean of last 3000: 0.09053149445728584\n",
            "3100: 0.09211663901805878\n",
            "3100: 0.08388753980398178\n",
            "3200: 0.08195409923791885\n",
            "3200: 0.08552055060863495\n",
            "3300: 0.09109295904636383\n",
            "3300: 0.09729324281215668\n",
            "3400: 0.08259010314941406\n",
            "3400: 0.07898913323879242\n",
            "3500: 0.08816060423851013\n",
            "3500: 0.0924416184425354\n",
            "3600: 0.088385671377182\n",
            "3600: 0.08558668196201324\n",
            "3700: 0.08076950162649155\n",
            "3700: 0.09086720645427704\n",
            "3800: 0.08254304528236389\n",
            "3800: 0.08431880176067352\n",
            "3900: 0.08122434467077255\n",
            "3900: 0.08294370770454407\n",
            "4000: 0.09548039734363556\n",
            "4000: 0.08232218027114868\n",
            "Mean of last 4000: 0.08426791137004351\n",
            "4100: 0.07759121060371399\n",
            "4100: 0.07737119495868683\n",
            "4200: 0.0868174135684967\n",
            "4200: 0.08966182917356491\n",
            "4300: 0.07801546901464462\n",
            "4300: 0.08586928248405457\n",
            "4400: 0.06921255588531494\n",
            "4400: 0.07129238545894623\n",
            "4500: 0.07851159572601318\n",
            "4500: 0.08048970997333527\n",
            "4600: 0.07757851481437683\n",
            "4600: 0.07788097858428955\n",
            "4700: 0.07265642285346985\n",
            "4700: 0.08840496838092804\n",
            "4800: 0.07038631290197372\n",
            "4800: 0.07557836174964905\n",
            "4900: 0.07097595930099487\n",
            "4900: 0.0717073306441307\n",
            "5000: 0.0745023712515831\n",
            "5000: 0.0722307562828064\n",
            "Mean of last 5000: 0.07928652794181289\n",
            "5100: 0.08597350120544434\n",
            "5100: 0.07416442036628723\n",
            "5200: 0.07851945608854294\n",
            "5200: 0.06498022377490997\n",
            "5300: 0.07235021889209747\n",
            "5300: 0.07704794406890869\n",
            "5400: 0.0798337459564209\n",
            "5400: 0.06972136348485947\n",
            "5500: 0.07723557204008102\n",
            "5500: 0.07956468313932419\n",
            "5600: 0.07917075604200363\n",
            "5600: 0.07011178135871887\n",
            "5700: 0.07058963179588318\n",
            "5700: 0.07759127020835876\n",
            "5800: 0.07006846368312836\n",
            "5800: 0.06767673790454865\n",
            "5900: 0.07052136957645416\n",
            "5900: 0.06478607654571533\n",
            "6000: 0.06891828775405884\n",
            "6000: 0.0726766437292099\n",
            "Mean of last 6000: 0.07487479814483629\n",
            "6100: 0.06615625321865082\n",
            "6100: 0.0643080621957779\n",
            "6200: 0.06140732392668724\n",
            "6200: 0.07441267371177673\n",
            "6300: 0.07512975484132767\n",
            "6300: 0.06476737558841705\n",
            "6400: 0.06753315776586533\n",
            "6400: 0.06996910274028778\n",
            "6500: 0.07271771878004074\n",
            "6500: 0.0704399049282074\n",
            "6600: 0.08205509185791016\n",
            "6600: 0.06454327702522278\n",
            "6700: 0.06545408815145493\n",
            "6700: 0.06655420362949371\n",
            "6800: 0.07238319516181946\n",
            "6800: 0.06725796312093735\n",
            "6900: 0.06366228312253952\n",
            "6900: 0.06795376539230347\n",
            "7000: 0.06677969545125961\n",
            "7000: 0.07421594858169556\n",
            "Mean of last 7000: 0.07168353609108068\n",
            "7100: 0.06582506000995636\n",
            "7100: 0.07035769522190094\n",
            "7200: 0.08311791718006134\n",
            "7200: 0.06461060792207718\n",
            "7300: 0.07226108014583588\n",
            "7300: 0.06954704225063324\n",
            "7400: 0.06689520180225372\n",
            "7400: 0.07206156104803085\n",
            "7500: 0.06651051342487335\n",
            "7500: 0.06593992561101913\n",
            "7600: 0.06873443722724915\n",
            "7600: 0.06648807227611542\n",
            "7700: 0.06671055406332016\n",
            "7700: 0.06111956760287285\n",
            "7800: 0.06185739487409592\n",
            "7800: 0.06927520036697388\n",
            "7900: 0.07248382270336151\n",
            "7900: 0.061119671911001205\n",
            "8000: 0.06539298593997955\n",
            "8000: 0.0616115927696228\n",
            "Mean of last 8000: 0.06835754733573604\n",
            "8100: 0.0662110447883606\n",
            "8100: 0.07317036390304565\n",
            "8200: 0.05929991602897644\n",
            "8200: 0.058361928910017014\n",
            "8300: 0.07857830077409744\n",
            "8300: 0.0790376216173172\n",
            "8400: 0.06919188797473907\n",
            "8400: 0.06374015659093857\n",
            "8500: 0.06795009225606918\n",
            "8500: 0.06744148582220078\n",
            "8600: 0.07294294238090515\n",
            "8600: 0.06258927285671234\n",
            "8700: 0.07524082809686661\n",
            "8700: 0.06524544954299927\n",
            "8800: 0.06635203212499619\n",
            "8800: 0.06692304462194443\n",
            "8900: 0.06145288795232773\n",
            "8900: 0.06502790749073029\n",
            "9000: 0.06582707166671753\n",
            "9000: 0.06509631127119064\n",
            "Mean of last 9000: 0.06513992317028336\n",
            "9100: 0.05911892652511597\n",
            "9100: 0.0745733231306076\n",
            "9200: 0.06094351038336754\n",
            "9200: 0.06059684976935387\n",
            "9300: 0.058143146336078644\n",
            "9300: 0.06151644513010979\n",
            "9400: 0.06444061547517776\n",
            "9400: 0.060533326119184494\n",
            "9500: 0.06718429177999496\n",
            "9500: 0.0634499192237854\n",
            "9600: 0.058217741549015045\n",
            "9600: 0.06074279546737671\n",
            "9700: 0.06557388603687286\n",
            "9700: 0.06427908688783646\n",
            "9800: 0.05609951168298721\n",
            "9800: 0.06404176354408264\n",
            "9900: 0.05626165494322777\n",
            "9900: 0.0591815710067749\n",
            "10000: 0.05812561511993408\n",
            "10000: 0.06262935698032379\n",
            "Mean of last 10000: 0.0631424759353672\n",
            "10100: 0.06431236118078232\n",
            "10100: 0.06336917728185654\n",
            "10200: 0.06452186405658722\n",
            "10200: 0.07201644033193588\n",
            "10300: 0.05929161235690117\n",
            "10300: 0.061678409576416016\n",
            "10400: 0.06365509331226349\n",
            "10400: 0.06694762408733368\n",
            "10500: 0.0654062032699585\n",
            "10500: 0.06069978326559067\n",
            "10600: 0.05350553244352341\n",
            "10600: 0.061361636966466904\n",
            "10700: 0.058824460953474045\n",
            "10700: 0.06640160828828812\n",
            "10800: 0.06661708652973175\n",
            "10800: 0.05898129194974899\n",
            "10900: 0.05898334085941315\n",
            "10900: 0.061857905238866806\n",
            "11000: 0.06361053884029388\n",
            "11000: 0.059048112481832504\n",
            "Mean of last 11000: 0.0619383680556978\n",
            "11100: 0.05531905218958855\n",
            "11100: 0.058033883571624756\n",
            "11200: 0.059450261294841766\n",
            "11200: 0.05978667363524437\n",
            "11300: 0.06471451371908188\n",
            "11300: 0.06454198807477951\n",
            "11400: 0.06955976784229279\n",
            "11400: 0.059393882751464844\n",
            "11500: 0.05376596748828888\n",
            "11500: 0.057087600231170654\n",
            "11600: 0.056874506175518036\n",
            "11600: 0.05544237419962883\n",
            "11700: 0.07059655338525772\n",
            "11700: 0.060231924057006836\n",
            "11800: 0.06169948726892471\n",
            "11800: 0.06708519160747528\n",
            "11900: 0.06615325063467026\n",
            "11900: 0.05708785355091095\n",
            "12000: 0.06071513891220093\n",
            "12000: 0.0563591830432415\n",
            "Mean of last 12000: 0.06041283969703195\n",
            "12100: 0.06197599694132805\n",
            "12100: 0.06073415279388428\n",
            "12200: 0.0584842786192894\n",
            "12200: 0.060311079025268555\n",
            "12300: 0.06929099559783936\n",
            "12300: 0.05524950474500656\n",
            "12400: 0.051480263471603394\n",
            "12400: 0.0528784804046154\n",
            "12500: 0.05708007141947746\n",
            "12500: 0.06400687247514725\n",
            "12600: 0.05887839198112488\n",
            "12600: 0.06600227952003479\n",
            "12700: 0.06224335357546806\n",
            "12700: 0.06240444630384445\n",
            "12800: 0.058264173567295074\n",
            "12800: 0.058536823838949203\n",
            "12900: 0.05639154836535454\n",
            "12900: 0.06164485216140747\n",
            "13000: 0.06288118660449982\n",
            "13000: 0.05516551062464714\n",
            "Mean of last 13000: 0.05966503648543275\n",
            "13100: 0.05904090404510498\n",
            "13100: 0.05880400165915489\n",
            "13200: 0.054084450006484985\n",
            "13200: 0.061708997935056686\n",
            "13300: 0.06087800860404968\n",
            "13300: 0.06029381975531578\n",
            "13400: 0.05847526714205742\n",
            "13400: 0.057443439960479736\n",
            "13500: 0.05422675609588623\n",
            "13500: 0.061869826167821884\n",
            "13600: 0.06116338074207306\n",
            "13600: 0.06335705518722534\n",
            "13700: 0.05965703725814819\n",
            "13700: 0.058792367577552795\n",
            "13800: 0.05838923901319504\n",
            "13800: 0.06030435487627983\n",
            "13900: 0.05606764554977417\n",
            "13900: 0.06288105994462967\n",
            "14000: 0.05387749522924423\n",
            "14000: 0.05140232294797897\n",
            "Mean of last 14000: 0.05875331500952656\n",
            "14100: 0.05468800663948059\n",
            "14100: 0.05711430311203003\n",
            "14200: 0.05986540764570236\n",
            "14200: 0.05762927979230881\n",
            "14300: 0.0648314580321312\n",
            "14300: 0.05811794847249985\n",
            "14400: 0.055982016026973724\n",
            "14400: 0.05388530343770981\n",
            "14500: 0.06175321340560913\n",
            "14500: 0.05300294607877731\n",
            "14600: 0.061793893575668335\n",
            "14600: 0.06261561810970306\n",
            "14700: 0.05193880945444107\n",
            "14700: 0.052888330072164536\n",
            "14800: 0.051517337560653687\n",
            "14800: 0.0700712651014328\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14900: 0.04992896318435669\n",
            "14900: 0.05579104647040367\n",
            "15000: 0.06623440980911255\n",
            "15000: 0.055540066212415695\n",
            "Mean of last 15000: 0.05821125055258567\n",
            "15100: 0.06830987334251404\n",
            "15100: 0.05206496641039848\n",
            "15200: 0.05391582101583481\n",
            "15200: 0.05935383588075638\n",
            "15300: 0.05972355604171753\n",
            "15300: 0.05890620872378349\n",
            "15400: 0.05780977010726929\n",
            "15400: 0.05619002506136894\n",
            "15500: 0.05728960782289505\n",
            "15500: 0.05083778128027916\n",
            "15600: 0.061434075236320496\n",
            "15600: 0.06139606237411499\n",
            "15700: 0.06712010502815247\n",
            "15700: 0.05476311594247818\n",
            "15800: 0.054859042167663574\n",
            "15800: 0.061731383204460144\n",
            "15900: 0.05289851874113083\n",
            "15900: 0.05650091916322708\n",
            "16000: 0.06032609939575195\n",
            "16000: 0.05936114117503166\n",
            "Mean of last 16000: 0.057678099701201524\n",
            "16100: 0.052547335624694824\n",
            "16100: 0.056216321885585785\n",
            "16200: 0.052475541830062866\n",
            "16200: 0.05480099841952324\n",
            "16300: 0.05236329883337021\n",
            "16300: 0.05812336131930351\n",
            "16400: 0.05342100188136101\n",
            "16400: 0.058515191078186035\n",
            "16500: 0.06195206195116043\n",
            "16500: 0.06153559684753418\n",
            "16600: 0.07050463557243347\n",
            "16600: 0.05479765683412552\n",
            "16700: 0.05351976677775383\n",
            "16700: 0.052344910800457\n",
            "16800: 0.06212253123521805\n",
            "16800: 0.05451558157801628\n",
            "16900: 0.05247112736105919\n",
            "16900: 0.05821087956428528\n",
            "17000: 0.050585538148880005\n",
            "17000: 0.05173762887716293\n",
            "Mean of last 17000: 0.0573457366973906\n",
            "17100: 0.05586227774620056\n",
            "17100: 0.04974454641342163\n",
            "17200: 0.05284476280212402\n",
            "17200: 0.05776941031217575\n",
            "17300: 0.052149951457977295\n",
            "17300: 0.0581618957221508\n",
            "17400: 0.057911522686481476\n",
            "17400: 0.048888444900512695\n",
            "17500: 0.05422738194465637\n",
            "17500: 0.05695415660738945\n",
            "17600: 0.052834585309028625\n",
            "17600: 0.06324595212936401\n",
            "17700: 0.052272140979766846\n",
            "17700: 0.0517423115670681\n",
            "17800: 0.052923791110515594\n",
            "17800: 0.05390709638595581\n",
            "17900: 0.0508953332901001\n",
            "17900: 0.055731456726789474\n",
            "18000: 0.05271943658590317\n",
            "18000: 0.05118874832987785\n",
            "Mean of last 18000: 0.05679177528956196\n",
            "18100: 0.054336175322532654\n",
            "18100: 0.06065289303660393\n",
            "18200: 0.05648290365934372\n",
            "18200: 0.04898468777537346\n",
            "18300: 0.0586242750287056\n",
            "18300: 0.06271156668663025\n",
            "18400: 0.05718338489532471\n",
            "18400: 0.053592365235090256\n",
            "18500: 0.061545759439468384\n",
            "18500: 0.05476614832878113\n",
            "18600: 0.05477074906229973\n",
            "18600: 0.06141580268740654\n",
            "18700: 0.05583487078547478\n",
            "18700: 0.05143636465072632\n",
            "18800: 0.06998956203460693\n",
            "18800: 0.05514727160334587\n",
            "18900: 0.05703284591436386\n",
            "18900: 0.05397779867053032\n",
            "19000: 0.05897151678800583\n",
            "19000: 0.05566183850169182\n",
            "Mean of last 19000: 0.056705029752034765\n",
            "19100: 0.05582752451300621\n",
            "19100: 0.06509678065776825\n",
            "19200: 0.045293938368558884\n",
            "19200: 0.055390309542417526\n",
            "19300: 0.0655972808599472\n",
            "19300: 0.05780993029475212\n",
            "19400: 0.05568573996424675\n",
            "19400: 0.054086171090602875\n",
            "19500: 0.054851025342941284\n",
            "19500: 0.05826067551970482\n",
            "19600: 0.05593368411064148\n",
            "19600: 0.05386874079704285\n",
            "19700: 0.06170639023184776\n",
            "19700: 0.06021764501929283\n",
            "19800: 0.056254561990499496\n",
            "19800: 0.06133858114480972\n",
            "19900: 0.054534509778022766\n",
            "19900: 0.0565454363822937\n",
            "20000: 0.06526511907577515\n",
            "20000: 0.05887560546398163\n",
            "Mean of last 20000: 0.05638569052685629\n",
            "20100: 0.05918722599744797\n",
            "20100: 0.054978810250759125\n",
            "20200: 0.063901886343956\n",
            "20200: 0.05984878167510033\n",
            "20300: 0.05823349952697754\n",
            "20300: 0.05982261151075363\n",
            "20400: 0.06097603961825371\n",
            "20400: 0.05902198702096939\n",
            "20500: 0.05927620455622673\n",
            "20500: 0.055807530879974365\n",
            "20600: 0.04924207553267479\n",
            "20600: 0.049566011875867844\n",
            "20700: 0.05213309824466705\n",
            "20700: 0.06046511232852936\n",
            "20800: 0.051037997007369995\n",
            "20800: 0.05413044989109039\n",
            "20900: 0.056303273886442184\n",
            "20900: 0.05564042180776596\n",
            "21000: 0.04744591563940048\n",
            "21000: 0.05789094418287277\n",
            "Mean of last 21000: 0.05597071573845335\n",
            "21100: 0.05071355402469635\n",
            "21100: 0.04867684096097946\n",
            "21200: 0.06520500779151917\n",
            "21200: 0.05004100129008293\n",
            "21300: 0.05464419722557068\n",
            "21300: 0.05366159602999687\n",
            "21400: 0.05309570953249931\n",
            "21400: 0.06063845381140709\n",
            "21500: 0.0590493306517601\n",
            "21500: 0.06161732226610184\n",
            "21600: 0.05876550078392029\n",
            "21600: 0.05490382760763168\n",
            "21700: 0.056254636496305466\n",
            "21700: 0.06012672185897827\n",
            "21800: 0.05297800526022911\n",
            "21800: 0.05707555264234543\n",
            "21900: 0.05497655272483826\n",
            "21900: 0.06520569324493408\n",
            "22000: 0.05405178293585777\n",
            "22000: 0.055460136383771896\n",
            "Mean of last 22000: 0.05591432571031533\n",
            "22100: 0.0521974042057991\n",
            "22100: 0.054757826030254364\n",
            "22200: 0.0528152696788311\n",
            "22200: 0.053220003843307495\n",
            "22300: 0.05327442288398743\n",
            "22300: 0.052230820059776306\n",
            "22400: 0.06883161514997482\n",
            "22400: 0.05937809497117996\n",
            "22500: 0.06175560504198074\n",
            "22500: 0.06318487226963043\n",
            "22600: 0.055349454283714294\n",
            "22600: 0.058999620378017426\n",
            "22700: 0.04785929247736931\n",
            "22700: 0.05657781660556793\n",
            "22800: 0.04751691222190857\n",
            "22800: 0.051979418843984604\n",
            "22900: 0.054119594395160675\n",
            "22900: 0.0528644323348999\n",
            "23000: 0.055764831602573395\n",
            "23000: 0.0622684471309185\n",
            "Mean of last 23000: 0.055579451468217744\n",
            "23100: 0.05505329370498657\n",
            "23100: 0.05636066198348999\n",
            "23200: 0.04848497360944748\n",
            "23200: 0.0558830201625824\n",
            "23300: 0.04933851212263107\n",
            "23300: 0.056136928498744965\n",
            "23400: 0.05776366591453552\n",
            "23400: 0.0556441992521286\n",
            "23500: 0.05630333349108696\n",
            "23500: 0.05605854094028473\n",
            "23600: 0.06104103848338127\n",
            "23600: 0.05515436828136444\n",
            "23700: 0.04969809204339981\n",
            "23700: 0.05880631133913994\n",
            "23800: 0.05627278611063957\n",
            "23800: 0.05301904305815697\n",
            "23900: 0.059839241206645966\n",
            "23900: 0.06320976465940475\n",
            "24000: 0.06228122115135193\n",
            "24000: 0.04989028722047806\n",
            "Mean of last 24000: 0.055685670210884046\n",
            "24100: 0.05878961831331253\n",
            "24100: 0.060163043439388275\n",
            "24200: 0.054050546139478683\n",
            "24200: 0.04947924613952637\n",
            "24300: 0.05749429762363434\n",
            "24300: 0.05809924006462097\n",
            "24400: 0.05238604545593262\n",
            "24400: 0.052631475031375885\n",
            "24500: 0.062432244420051575\n",
            "24500: 0.06311792880296707\n",
            "24600: 0.06171373277902603\n",
            "24600: 0.05122153088450432\n",
            "24700: 0.06163409352302551\n",
            "24700: 0.05091629922389984\n",
            "24800: 0.05063638091087341\n",
            "24800: 0.0572887621819973\n",
            "24900: 0.05660195276141167\n",
            "24900: 0.05167272686958313\n",
            "25000: 0.050944723188877106\n",
            "25000: 0.06355287879705429\n",
            "Mean of last 25000: 0.05504737303710425\n",
            "25100: 0.05418882519006729\n",
            "25100: 0.05042209476232529\n",
            "25200: 0.05166596919298172\n",
            "25200: 0.051620494574308395\n",
            "25300: 0.052207499742507935\n",
            "25300: 0.04625644534826279\n",
            "25400: 0.0482356920838356\n",
            "25400: 0.04961938410997391\n",
            "25500: 0.06249547004699707\n",
            "25500: 0.05715758726000786\n",
            "25600: 0.052880845963954926\n",
            "25600: 0.05736115202307701\n",
            "25700: 0.05196515843272209\n",
            "25700: 0.06149258464574814\n",
            "25800: 0.051154375076293945\n",
            "25800: 0.07046662271022797\n",
            "25900: 0.05217241868376732\n",
            "25900: 0.053179483860731125\n",
            "26000: 0.06110324710607529\n",
            "26000: 0.051519256085157394\n",
            "Mean of last 26000: 0.055044258670224534\n",
            "26100: 0.05222192406654358\n",
            "26100: 0.06379921734333038\n",
            "26200: 0.053633540868759155\n",
            "26200: 0.05701894313097\n",
            "26300: 0.052059851586818695\n",
            "26300: 0.04958050698041916\n",
            "26400: 0.04936512932181358\n",
            "26400: 0.05163136124610901\n",
            "26500: 0.05882753059267998\n",
            "26500: 0.0527457520365715\n",
            "26600: 0.051892392337322235\n",
            "26600: 0.05344986170530319\n",
            "26700: 0.0554114505648613\n",
            "26700: 0.054752033203840256\n",
            "26800: 0.05775865167379379\n",
            "26800: 0.052571848034858704\n",
            "26900: 0.05546834319829941\n",
            "26900: 0.05978132411837578\n",
            "27000: 0.05840124934911728\n",
            "27000: 0.04856705293059349\n",
            "Mean of last 27000: 0.05478433881338302\n",
            "27100: 0.05299459397792816\n",
            "27100: 0.053501762449741364\n",
            "27200: 0.05134810134768486\n",
            "27200: 0.05123887583613396\n",
            "27300: 0.05548810213804245\n",
            "27300: 0.05289186164736748\n",
            "27400: 0.053738437592983246\n",
            "27400: 0.055660586804151535\n",
            "27500: 0.05301351472735405\n",
            "27500: 0.054892610758543015\n",
            "27600: 0.047712501138448715\n",
            "27600: 0.05526145547628403\n",
            "27700: 0.04759543389081955\n",
            "27700: 0.052780162543058395\n",
            "27800: 0.06278987973928452\n",
            "27800: 0.05001610517501831\n",
            "27900: 0.05078592523932457\n",
            "27900: 0.0473296120762825\n",
            "28000: 0.04923969507217407\n",
            "28000: 0.05029336363077164\n",
            "Mean of last 28000: 0.05468622979509842\n",
            "28100: 0.05094197019934654\n",
            "28100: 0.05701202154159546\n",
            "28200: 0.05484116077423096\n",
            "28200: 0.05672214552760124\n",
            "28300: 0.053213946521282196\n",
            "28300: 0.05161405727267265\n",
            "28400: 0.04513474553823471\n",
            "28400: 0.05826234817504883\n",
            "28500: 0.05108096823096275\n",
            "28500: 0.05030233412981033\n",
            "28600: 0.049627773463726044\n",
            "28600: 0.05210569128394127\n",
            "28700: 0.0523042306303978\n",
            "28700: 0.06006845086812973\n",
            "28800: 0.05359692499041557\n",
            "28800: 0.06994915008544922\n",
            "28900: 0.05043691396713257\n",
            "28900: 0.05301080644130707\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29000: 0.05579741299152374\n",
            "29000: 0.056816376745700836\n",
            "Mean of last 29000: 0.054707631969323885\n",
            "29100: 0.060923442244529724\n",
            "29100: 0.052946917712688446\n",
            "29200: 0.045471739023923874\n",
            "29200: 0.05354120582342148\n",
            "29300: 0.05567988008260727\n",
            "29300: 0.051208943128585815\n",
            "29400: 0.05073527619242668\n",
            "29400: 0.052284300327301025\n",
            "29500: 0.052731703966856\n",
            "29500: 0.05141259357333183\n",
            "29600: 0.05038141459226608\n",
            "29600: 0.0507945641875267\n",
            "29700: 0.058459408581256866\n",
            "29700: 0.05963495001196861\n",
            "29800: 0.05688663572072983\n",
            "29800: 0.055179983377456665\n",
            "30200: 0.05250254273414612\n",
            "30200: 0.04876888543367386\n",
            "30300: 0.05574197694659233\n",
            "30300: 0.053537897765636444\n",
            "30400: 0.052550267428159714\n",
            "30400: 0.049816787242889404\n",
            "30500: 0.05505458265542984\n",
            "30500: 0.051070746034383774\n",
            "30600: 0.05219220370054245\n",
            "30600: 0.05272912234067917\n",
            "30700: 0.05890928953886032\n",
            "30700: 0.05336970090866089\n",
            "30800: 0.04951886087656021\n",
            "30800: 0.052467312663793564\n",
            "30900: 0.046642132103443146\n",
            "30900: 0.053949158638715744\n",
            "31000: 0.05054403096437454\n",
            "31000: 0.05390132591128349\n",
            "Mean of last 31000: 0.05404017697628978\n",
            "31100: 0.057506829500198364\n",
            "31100: 0.06105725094676018\n",
            "31200: 0.055535461753606796\n",
            "31200: 0.05795855075120926\n",
            "31300: 0.05635550618171692\n",
            "31300: 0.05379548668861389\n",
            "31400: 0.06296394020318985\n",
            "31400: 0.060433559119701385\n",
            "31500: 0.051854997873306274\n",
            "31500: 0.053627900779247284\n",
            "31600: 0.05453503131866455\n",
            "31600: 0.056134745478630066\n",
            "31700: 0.04801241680979729\n",
            "31700: 0.05325893685221672\n",
            "31800: 0.05918080732226372\n",
            "31800: 0.06348515301942825\n",
            "31900: 0.04854181036353111\n",
            "31900: 0.049499981105327606\n",
            "32000: 0.048759590834379196\n",
            "32000: 0.051579803228378296\n",
            "Mean of last 32000: 0.05433555183509787\n",
            "32100: 0.05616950988769531\n",
            "32100: 0.04989415034651756\n",
            "32200: 0.05512121319770813\n",
            "32200: 0.04846765846014023\n",
            "32300: 0.057667076587677\n",
            "32300: 0.05139581486582756\n",
            "32400: 0.04928800091147423\n",
            "32400: 0.05051950365304947\n",
            "32500: 0.06056402251124382\n",
            "32500: 0.050014249980449677\n",
            "32600: 0.0531003400683403\n",
            "32600: 0.04759889096021652\n",
            "32700: 0.04845292493700981\n",
            "32700: 0.06012715399265289\n",
            "32800: 0.05216176062822342\n",
            "32800: 0.0509180948138237\n",
            "32900: 0.054330479353666306\n",
            "32900: 0.05045955628156662\n",
            "33000: 0.04862712323665619\n",
            "33000: 0.0515366867184639\n",
            "Mean of last 33000: 0.05373525896205471\n",
            "33100: 0.052269816398620605\n",
            "33100: 0.05287324637174606\n",
            "33200: 0.05155249685049057\n",
            "33200: 0.049210723489522934\n",
            "33300: 0.05815053731203079\n",
            "33300: 0.05359496921300888\n",
            "33400: 0.058618735522031784\n",
            "33400: 0.05337799713015556\n",
            "33500: 0.057453595101833344\n",
            "33500: 0.05679786205291748\n",
            "33600: 0.051858704537153244\n",
            "33600: 0.05148245394229889\n",
            "33700: 0.05446320027112961\n",
            "33700: 0.053371161222457886\n",
            "33800: 0.05650542303919792\n",
            "33800: 0.05403963848948479\n",
            "33900: 0.04731525108218193\n",
            "33900: 0.048405103385448456\n",
            "34000: 0.053378067910671234\n",
            "34000: 0.059875234961509705\n",
            "Mean of last 34000: 0.053880180575541566\n",
            "34100: 0.05436309799551964\n",
            "34100: 0.046542055904865265\n",
            "34200: 0.057298444211483\n",
            "34200: 0.06450929492712021\n",
            "34300: 0.05147957429289818\n",
            "34300: 0.057968415319919586\n",
            "34400: 0.05823591351509094\n",
            "34400: 0.05183138698339462\n",
            "34500: 0.045097749680280685\n",
            "34500: 0.05149116739630699\n",
            "34600: 0.0609344057738781\n",
            "34600: 0.055693309754133224\n",
            "34700: 0.05340281128883362\n",
            "34700: 0.049887821078300476\n",
            "34800: 0.0501716211438179\n",
            "34800: 0.05245780572295189\n",
            "34900: 0.0516311451792717\n",
            "34900: 0.044518209993839264\n",
            "35000: 0.04984481260180473\n",
            "35000: 0.06005384773015976\n",
            "Mean of last 35000: 0.053631429950316827\n",
            "35100: 0.04733306169509888\n",
            "35100: 0.06044855713844299\n",
            "35200: 0.053692709654569626\n",
            "35200: 0.049720048904418945\n",
            "35300: 0.05014992877840996\n",
            "35300: 0.05467626452445984\n",
            "35400: 0.05637107789516449\n",
            "35400: 0.05108955502510071\n",
            "35500: 0.04970811307430267\n",
            "35500: 0.04446929693222046\n",
            "35600: 0.053201161324977875\n",
            "35600: 0.0531904399394989\n",
            "35700: 0.05833609029650688\n",
            "35700: 0.05442479997873306\n",
            "35800: 0.0507117435336113\n",
            "35800: 0.04949882626533508\n",
            "35900: 0.050158899277448654\n",
            "35900: 0.05281863734126091\n",
            "36000: 0.058535292744636536\n",
            "36000: 0.04743970185518265\n",
            "Mean of last 36000: 0.053409805740941535\n",
            "36100: 0.051249828189611435\n",
            "36100: 0.05143950507044792\n",
            "36200: 0.05706987902522087\n",
            "36200: 0.05469580739736557\n",
            "36300: 0.0529678575694561\n",
            "36300: 0.0546988770365715\n",
            "36400: 0.05514407157897949\n",
            "36400: 0.0497155487537384\n",
            "36500: 0.050162553787231445\n",
            "36500: 0.053360652178525925\n",
            "36600: 0.05595898628234863\n",
            "36600: 0.05116911977529526\n",
            "36700: 0.05067514628171921\n",
            "36700: 0.05260764807462692\n",
            "36800: 0.05150116607546806\n",
            "36800: 0.052467089146375656\n",
            "36900: 0.0520649254322052\n",
            "36900: 0.05008448287844658\n",
            "37000: 0.06780099868774414\n",
            "37000: 0.06625165045261383\n",
            "Mean of last 37000: 0.05352630010330594\n",
            "37100: 0.051974110305309296\n",
            "37100: 0.05262957140803337\n",
            "37200: 0.06056535243988037\n",
            "37200: 0.0474884957075119\n",
            "37300: 0.04979213327169418\n",
            "37300: 0.05254135653376579\n",
            "37400: 0.0582425519824028\n",
            "37400: 0.05133282393217087\n",
            "37500: 0.05176835507154465\n",
            "37500: 0.05121457204222679\n",
            "37600: 0.050120823085308075\n",
            "37600: 0.053986843675374985\n",
            "37700: 0.05682280287146568\n",
            "37700: 0.053274475038051605\n",
            "37800: 0.04597648233175278\n",
            "37800: 0.047934919595718384\n",
            "37900: 0.057187169790267944\n",
            "37900: 0.049431707710027695\n",
            "38000: 0.050774943083524704\n",
            "38000: 0.054703518748283386\n",
            "Mean of last 38000: 0.05326120415097707\n",
            "38100: 0.0480436310172081\n",
            "38100: 0.054325126111507416\n",
            "38200: 0.05666813999414444\n",
            "38200: 0.060901619493961334\n",
            "38300: 0.059965670108795166\n",
            "38300: 0.051640115678310394\n",
            "38400: 0.05564679950475693\n",
            "38400: 0.05085137486457825\n",
            "38500: 0.05616724118590355\n",
            "38500: 0.06792496144771576\n",
            "38600: 0.07006070017814636\n",
            "38600: 0.050736717879772186\n",
            "38700: 0.0614226758480072\n",
            "38700: 0.050916366279125214\n",
            "38800: 0.05878356844186783\n",
            "38800: 0.051361262798309326\n",
            "38900: 0.04907387122511864\n",
            "38900: 0.054827895015478134\n",
            "39000: 0.053776007145643234\n",
            "39000: 0.051075439900159836\n",
            "Mean of last 39000: 0.05320408414643663\n",
            "39100: 0.053412020206451416\n",
            "39100: 0.05394554138183594\n",
            "39200: 0.04798194766044617\n",
            "39200: 0.05866824835538864\n",
            "39300: 0.050713151693344116\n",
            "39300: 0.047881223261356354\n",
            "39400: 0.05351344868540764\n",
            "39400: 0.056368447840213776\n",
            "39500: 0.05993758887052536\n",
            "39500: 0.05209619924426079\n",
            "39600: 0.04932801052927971\n",
            "39600: 0.06026406213641167\n",
            "39700: 0.05181504786014557\n",
            "39700: 0.04836658760905266\n",
            "39800: 0.0472571924328804\n",
            "39800: 0.04689236730337143\n",
            "39900: 0.05625545233488083\n",
            "39900: 0.05991591140627861\n",
            "40000: 0.06004165858030319\n",
            "40000: 0.04973297938704491\n",
            "Mean of last 40000: 0.0533736115554115\n",
            "40100: 0.04372183606028557\n",
            "40100: 0.048938654363155365\n",
            "40200: 0.05024629831314087\n",
            "40200: 0.04681932181119919\n",
            "40300: 0.04865550994873047\n",
            "40300: 0.05012984201312065\n",
            "40400: 0.057256873697042465\n",
            "40400: 0.05664994940161705\n",
            "40500: 0.05681544542312622\n",
            "40500: 0.0535598061978817\n",
            "40600: 0.0645647868514061\n",
            "40600: 0.04703494906425476\n",
            "40700: 0.04800618812441826\n",
            "40700: 0.062320925295352936\n",
            "40800: 0.04672103747725487\n",
            "40800: 0.055443763732910156\n",
            "40900: 0.05560244619846344\n",
            "40900: 0.052805475890636444\n",
            "41000: 0.052196890115737915\n",
            "41000: 0.04817628115415573\n",
            "Mean of last 41000: 0.05283979238657566\n",
            "41100: 0.053924672305583954\n",
            "41100: 0.052894800901412964\n",
            "41200: 0.053677722811698914\n",
            "41200: 0.06447824090719223\n",
            "41300: 0.04629398509860039\n",
            "41300: 0.047427646815776825\n",
            "41400: 0.060402534902095795\n",
            "41400: 0.04945455119013786\n",
            "41500: 0.0511368066072464\n",
            "41500: 0.06324556469917297\n",
            "41600: 0.06577758491039276\n",
            "41600: 0.0555458664894104\n",
            "41700: 0.04948146641254425\n",
            "41700: 0.052150093019008636\n",
            "41800: 0.060530148446559906\n",
            "41800: 0.051269225776195526\n",
            "41900: 0.0514388307929039\n",
            "41900: 0.05018661916255951\n",
            "42000: 0.05140630155801773\n",
            "42000: 0.05560215562582016\n",
            "Mean of last 42000: 0.052987636294919295\n",
            "42100: 0.05282766744494438\n",
            "42100: 0.05642664059996605\n",
            "42200: 0.05918111652135849\n",
            "42200: 0.05331563204526901\n",
            "42300: 0.05498237907886505\n",
            "42300: 0.05412588268518448\n",
            "42400: 0.052690938115119934\n",
            "42400: 0.05575165897607803\n",
            "42500: 0.05994173139333725\n",
            "42500: 0.05759456008672714\n",
            "42600: 0.04810835421085358\n",
            "42600: 0.06308905780315399\n",
            "42700: 0.053285859525203705\n",
            "42700: 0.05601966381072998\n",
            "42800: 0.058505281805992126\n",
            "42800: 0.06111578270792961\n",
            "42900: 0.0492243729531765\n",
            "42900: 0.0613764226436615\n",
            "43000: 0.05565066263079643\n",
            "43000: 0.05559492111206055\n",
            "Mean of last 43000: 0.05294091878207652\n",
            "43100: 0.04533722624182701\n",
            "43100: 0.05624870955944061\n",
            "43200: 0.04842664301395416\n",
            "43200: 0.050555139780044556\n",
            "43300: 0.0485120564699173\n",
            "43300: 0.056102000176906586\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43400: 0.05209232494235039\n",
            "43400: 0.05946678668260574\n",
            "43500: 0.05501843988895416\n",
            "43500: 0.05181748792529106\n",
            "43600: 0.05027516931295395\n",
            "43600: 0.053472768515348434\n",
            "43700: 0.0553053617477417\n",
            "43700: 0.05202696472406387\n",
            "43800: 0.05691415071487427\n",
            "43800: 0.055753063410520554\n",
            "43900: 0.05351024121046066\n",
            "43900: 0.05823243409395218\n",
            "44000: 0.05468162149190903\n",
            "44000: 0.057267289608716965\n",
            "Mean of last 44000: 0.05263654142059944\n",
            "44100: 0.04986390471458435\n",
            "44100: 0.04484570771455765\n",
            "44200: 0.05416155979037285\n",
            "44200: 0.04240165278315544\n",
            "44300: 0.05445096641778946\n",
            "44300: 0.05339432507753372\n",
            "44400: 0.06860975921154022\n",
            "44400: 0.04975372180342674\n",
            "44500: 0.0488799624145031\n",
            "44500: 0.04799922928214073\n",
            "44600: 0.05773184448480606\n",
            "44600: 0.05655844137072563\n",
            "44700: 0.05611329898238182\n",
            "44700: 0.051759541034698486\n",
            "44800: 0.053269922733306885\n",
            "44800: 0.05119576305150986\n",
            "44900: 0.05144188925623894\n",
            "44900: 0.04840090498328209\n",
            "45000: 0.05733596906065941\n",
            "45000: 0.05745503306388855\n",
            "Mean of last 45000: 0.05293248692428792\n",
            "45100: 0.061813682317733765\n",
            "45100: 0.048258792608976364\n",
            "45200: 0.06254136562347412\n",
            "45200: 0.05017989128828049\n",
            "45300: 0.046111833304166794\n",
            "45300: 0.0483957976102829\n",
            "45400: 0.05867674946784973\n",
            "45400: 0.05325247347354889\n",
            "45500: 0.053254690021276474\n",
            "45500: 0.041927799582481384\n",
            "45600: 0.05694848299026489\n",
            "45600: 0.044478923082351685\n",
            "45700: 0.049716755747795105\n",
            "45700: 0.0517524890601635\n",
            "45800: 0.05001789331436157\n",
            "45800: 0.0592665821313858\n",
            "45900: 0.06066504120826721\n",
            "45900: 0.054743122309446335\n",
            "46000: 0.048125073313713074\n",
            "46000: 0.059986453503370285\n",
            "Mean of last 46000: 0.05286143958516471\n",
            "46100: 0.06223342567682266\n",
            "46100: 0.04580196365714073\n",
            "46200: 0.05462981015443802\n",
            "46200: 0.05414275452494621\n",
            "46300: 0.04751455783843994\n",
            "46300: 0.057767730206251144\n",
            "46400: 0.049625396728515625\n",
            "46400: 0.0495356023311615\n",
            "46500: 0.049298353493213654\n",
            "46500: 0.043466370552778244\n",
            "46600: 0.049026958644390106\n",
            "46600: 0.04213182255625725\n",
            "46700: 0.048232536762952805\n",
            "46700: 0.05750332772731781\n",
            "46800: 0.050604164600372314\n",
            "46800: 0.052719131112098694\n",
            "46900: 0.05707989260554314\n",
            "46900: 0.05188889801502228\n",
            "47000: 0.05045406147837639\n",
            "47000: 0.04807211086153984\n",
            "Mean of last 47000: 0.0526274463197181\n",
            "47100: 0.05196506530046463\n",
            "47100: 0.062266528606414795\n",
            "47200: 0.05445222184062004\n",
            "47200: 0.0510774664580822\n",
            "47300: 0.05023682862520218\n",
            "47300: 0.04876432940363884\n",
            "47400: 0.054372742772102356\n",
            "47400: 0.05484507605433464\n",
            "47500: 0.05429401248693466\n",
            "47500: 0.056096918880939484\n",
            "47600: 0.051596056669950485\n",
            "47600: 0.048804618418216705\n",
            "47700: 0.05878622084856033\n",
            "47700: 0.048577647656202316\n",
            "47800: 0.054164569824934006\n",
            "47800: 0.04818568751215935\n",
            "47900: 0.050949424505233765\n",
            "47900: 0.05010393261909485\n",
            "48000: 0.05411798879504204\n",
            "48000: 0.06064070388674736\n",
            "Mean of last 48000: 0.052586088753440285\n",
            "48100: 0.04693160578608513\n",
            "48100: 0.05208452790975571\n",
            "48200: 0.05174201726913452\n",
            "48200: 0.048624902963638306\n",
            "48300: 0.051188867539167404\n",
            "48300: 0.05890892073512077\n",
            "48400: 0.051880862563848495\n",
            "48400: 0.05751229450106621\n",
            "48500: 0.05076661705970764\n",
            "48500: 0.04965090751647949\n",
            "48600: 0.051218800246715546\n",
            "48600: 0.05374271795153618\n",
            "48700: 0.052244883030653\n",
            "48700: 0.05085953325033188\n",
            "48800: 0.053015582263469696\n",
            "48800: 0.05141087621450424\n",
            "48900: 0.04790089651942253\n",
            "48900: 0.05250674486160278\n",
            "49000: 0.057186685502529144\n",
            "49000: 0.05956602096557617\n",
            "Mean of last 49000: 0.052449241271251806\n",
            "49100: 0.051924072206020355\n",
            "49100: 0.0532911941409111\n",
            "49200: 0.05690499395132065\n",
            "49200: 0.055003948509693146\n",
            "49300: 0.050039879977703094\n",
            "49300: 0.04992015287280083\n",
            "49400: 0.054294850677251816\n",
            "49400: 0.05206138640642166\n",
            "49500: 0.049272533506155014\n",
            "49500: 0.04920750856399536\n",
            "49600: 0.05966288596391678\n",
            "49600: 0.05928100273013115\n",
            "49700: 0.05589400231838226\n",
            "49700: 0.04543197154998779\n",
            "49800: 0.05804935097694397\n",
            "49800: 0.05957421660423279\n",
            "49900: 0.0583491325378418\n",
            "49900: 0.049261000007390976\n",
            "50000: 0.05414979159832001\n",
            "50000: 0.05076354742050171\n",
            "Mean of last 50000: 0.05242842127132666\n",
            "50100: 0.04865283519029617\n",
            "50100: 0.04759541153907776\n",
            "50200: 0.04861762374639511\n",
            "50200: 0.052050452679395676\n",
            "50300: 0.05052860826253891\n",
            "50300: 0.04662764072418213\n",
            "50400: 0.061323314905166626\n",
            "50400: 0.05596914142370224\n",
            "50500: 0.05284950137138367\n",
            "50500: 0.048783980309963226\n",
            "50600: 0.054434847086668015\n",
            "50600: 0.05058794468641281\n",
            "50700: 0.04926403611898422\n",
            "50700: 0.04848260432481766\n",
            "50800: 0.04884704202413559\n",
            "50800: 0.062063656747341156\n",
            "50900: 0.0486593171954155\n",
            "50900: 0.0517391674220562\n",
            "51000: 0.05107290297746658\n",
            "51000: 0.055488359183073044\n",
            "Mean of last 51000: 0.05242709121615677\n",
            "51100: 0.049701377749443054\n",
            "51100: 0.04586802423000336\n",
            "51200: 0.047936007380485535\n",
            "51200: 0.05182619020342827\n",
            "51300: 0.05322174355387688\n",
            "51300: 0.06077822670340538\n",
            "51400: 0.05883165821433067\n",
            "51400: 0.059534065425395966\n",
            "51500: 0.05162021517753601\n",
            "51500: 0.048271119594573975\n",
            "51600: 0.05712483078241348\n",
            "51600: 0.0523843877017498\n",
            "51700: 0.05214555189013481\n",
            "51700: 0.05837273225188255\n",
            "51800: 0.04821954295039177\n",
            "51800: 0.05009661242365837\n",
            "51900: 0.047085270285606384\n",
            "51900: 0.05459800362586975\n",
            "52000: 0.05045996233820915\n",
            "52000: 0.053045377135276794\n",
            "Mean of last 52000: 0.05210385679804183\n",
            "52100: 0.05242854356765747\n",
            "52100: 0.049848493188619614\n",
            "52200: 0.0436796173453331\n",
            "52200: 0.051334720104932785\n",
            "52300: 0.0537867471575737\n",
            "52300: 0.050741203129291534\n",
            "52400: 0.05702881142497063\n",
            "52400: 0.0547807440161705\n",
            "52500: 0.05063639208674431\n",
            "52500: 0.05498693883419037\n",
            "52600: 0.05272231996059418\n",
            "52600: 0.05772414803504944\n",
            "52700: 0.0492730550467968\n",
            "52700: 0.06064410135149956\n",
            "52800: 0.0517900213599205\n",
            "52800: 0.05345947667956352\n",
            "52900: 0.05556783080101013\n",
            "52900: 0.043174248188734055\n",
            "53000: 0.05001752823591232\n",
            "53000: 0.04571741819381714\n",
            "Mean of last 53000: 0.0524737984872424\n",
            "53100: 0.04919661208987236\n",
            "53100: 0.04900128394365311\n",
            "53200: 0.052673667669296265\n",
            "53200: 0.05123986303806305\n",
            "53300: 0.052681129425764084\n",
            "53300: 0.04858560115098953\n",
            "53400: 0.06314894556999207\n",
            "53400: 0.055798329412937164\n",
            "53500: 0.05306258797645569\n",
            "53500: 0.05583203583955765\n",
            "53600: 0.05579305812716484\n",
            "53600: 0.04242357239127159\n",
            "53700: 0.05319103226065636\n",
            "53700: 0.043170150369405746\n",
            "53800: 0.06325981020927429\n",
            "53800: 0.05185655504465103\n",
            "53900: 0.058074288070201874\n",
            "53900: 0.04997866600751877\n",
            "54000: 0.050402820110321045\n",
            "54000: 0.05002696067094803\n",
            "Mean of last 54000: 0.05211284775268305\n",
            "54100: 0.05408649146556854\n",
            "54100: 0.05598849058151245\n",
            "54200: 0.05823884531855583\n",
            "54200: 0.05312904715538025\n",
            "54300: 0.05317511409521103\n",
            "54300: 0.048297904431819916\n",
            "54400: 0.06079734489321709\n",
            "54400: 0.04863779991865158\n",
            "54500: 0.054127272218465805\n",
            "54500: 0.06057414412498474\n",
            "54600: 0.04615456610918045\n",
            "54600: 0.051738839596509933\n",
            "54700: 0.05147726461291313\n",
            "54700: 0.04986633360385895\n",
            "54800: 0.052366238087415695\n",
            "54800: 0.05206967890262604\n",
            "54900: 0.0451522096991539\n",
            "54900: 0.0462002158164978\n",
            "55000: 0.0503959022462368\n",
            "55000: 0.054230283945798874\n",
            "Mean of last 55000: 0.0520854571519734\n",
            "55100: 0.05999850481748581\n",
            "55100: 0.049940526485443115\n",
            "55200: 0.05233260616660118\n",
            "55200: 0.05157759040594101\n",
            "55700: 0.05674166604876518\n",
            "55700: 0.048946917057037354\n",
            "55800: 0.04990484565496445\n",
            "55800: 0.0537165105342865\n",
            "55900: 0.051208771765232086\n",
            "55900: 0.04863930493593216\n",
            "56000: 0.04678255319595337\n",
            "56000: 0.04822250455617905\n",
            "Mean of last 56000: 0.05213462126875793\n",
            "56100: 0.054471056908369064\n",
            "56100: 0.04855430871248245\n",
            "56200: 0.05322533845901489\n",
            "56200: 0.04986121878027916\n",
            "56300: 0.0572480633854866\n",
            "56300: 0.048996955156326294\n",
            "56400: 0.050318893045186996\n",
            "56400: 0.054123323410749435\n",
            "56500: 0.04777229577302933\n",
            "56500: 0.05363839864730835\n",
            "56600: 0.04861344397068024\n",
            "56600: 0.05989345535635948\n",
            "56700: 0.050373516976833344\n",
            "56700: 0.05213138461112976\n",
            "56800: 0.05738392099738121\n",
            "56800: 0.05371132493019104\n",
            "56900: 0.05082985386252403\n",
            "56900: 0.04849899932742119\n",
            "57000: 0.050904154777526855\n",
            "57000: 0.05425536632537842\n",
            "Mean of last 57000: 0.05196077758809189\n",
            "57100: 0.05355607718229294\n",
            "57100: 0.048663824796676636\n",
            "57200: 0.047346748411655426\n",
            "57200: 0.04841441661119461\n",
            "57300: 0.05131547898054123\n",
            "57300: 0.04353323578834534\n",
            "57400: 0.06432022154331207\n",
            "57400: 0.05706081911921501\n",
            "57500: 0.04962614178657532\n",
            "57500: 0.05075002461671829\n",
            "57600: 0.05016202852129936\n",
            "57600: 0.047952186316251755\n",
            "57700: 0.061399199068546295\n",
            "57700: 0.04983976483345032\n",
            "57800: 0.05014320835471153\n",
            "57800: 0.056255631148815155\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57900: 0.056580521166324615\n",
            "57900: 0.051163263618946075\n",
            "58000: 0.04921741411089897\n",
            "58000: 0.05107152462005615\n",
            "Mean of last 58000: 0.0519515837837647\n",
            "58100: 0.05303763598203659\n",
            "58100: 0.05119802802801132\n",
            "58200: 0.05333643779158592\n",
            "58200: 0.04985462874174118\n",
            "58300: 0.05516728758811951\n",
            "58300: 0.051367320120334625\n",
            "58400: 0.0515894740819931\n",
            "58400: 0.05384843796491623\n",
            "58500: 0.05000418424606323\n",
            "58500: 0.05766332149505615\n",
            "58600: 0.051230739802122116\n",
            "58600: 0.05009635537862778\n",
            "58700: 0.04600329324603081\n",
            "58700: 0.05053437501192093\n",
            "58800: 0.058005258440971375\n",
            "58800: 0.056839264929294586\n",
            "58900: 0.04530083388090134\n",
            "58900: 0.05898024141788483\n",
            "59000: 0.04531406983733177\n",
            "59000: 0.043112289160490036\n",
            "Mean of last 59000: 0.05188869732570696\n",
            "59100: 0.0555528961122036\n",
            "59100: 0.06667979806661606\n",
            "59200: 0.049468763172626495\n",
            "59200: 0.0507572665810585\n",
            "59300: 0.05283425375819206\n",
            "59300: 0.05895905941724777\n",
            "59400: 0.055466052144765854\n",
            "59400: 0.048744797706604004\n",
            "59500: 0.050328731536865234\n",
            "59500: 0.046735357493162155\n",
            "59600: 0.051354169845581055\n",
            "59600: 0.05283626914024353\n",
            "59700: 0.04932480305433273\n",
            "59700: 0.05669282004237175\n",
            "59800: 0.047772299498319626\n",
            "59800: 0.05286815017461777\n",
            "59900: 0.045840516686439514\n",
            "59900: 0.05201460421085358\n",
            "60000: 0.049531541764736176\n",
            "60000: 0.05246959254145622\n",
            "Mean of last 60000: 0.05190644983563211\n",
            "60100: 0.058047130703926086\n",
            "60100: 0.04882478341460228\n",
            "60200: 0.05658264458179474\n",
            "60200: 0.05258948728442192\n",
            "60300: 0.05486588925123215\n",
            "60300: 0.06133686751127243\n",
            "60400: 0.0557926706969738\n",
            "60400: 0.05991309881210327\n",
            "60500: 0.04850528761744499\n",
            "60500: 0.05678745359182358\n",
            "60600: 0.05092984065413475\n",
            "60600: 0.05130038782954216\n",
            "60700: 0.04699954390525818\n",
            "60700: 0.0540776364505291\n",
            "60800: 0.046499233692884445\n",
            "60800: 0.049316249787807465\n",
            "60900: 0.04745633527636528\n",
            "60900: 0.045279115438461304\n",
            "61000: 0.054497361183166504\n",
            "61000: 0.05001067742705345\n",
            "Mean of last 61000: 0.05173177886326294\n",
            "61100: 0.05422935634851456\n",
            "61100: 0.05458839237689972\n",
            "61200: 0.05036390945315361\n",
            "61200: 0.053430452942848206\n",
            "61300: 0.0467342734336853\n",
            "61300: 0.054099954664707184\n",
            "61400: 0.06305232644081116\n",
            "61400: 0.05407407879829407\n",
            "61500: 0.04614992067217827\n",
            "61500: 0.04735410213470459\n",
            "61600: 0.04179331287741661\n",
            "61600: 0.05010432004928589\n",
            "61700: 0.051715340465307236\n",
            "61700: 0.04515191540122032\n",
            "61800: 0.05803106352686882\n",
            "61800: 0.0493096262216568\n",
            "61900: 0.044986844062805176\n",
            "61900: 0.05307670682668686\n",
            "62000: 0.044987987726926804\n",
            "62000: 0.05739077180624008\n",
            "Mean of last 62000: 0.051717096543335894\n",
            "62100: 0.053282737731933594\n",
            "62100: 0.054998986423015594\n",
            "62200: 0.053837694227695465\n",
            "62200: 0.056585393846035004\n",
            "62300: 0.04801435396075249\n",
            "62300: 0.04569978266954422\n",
            "62400: 0.046290524303913116\n",
            "62400: 0.05473227798938751\n",
            "62500: 0.04769793152809143\n",
            "62500: 0.045737966895103455\n",
            "62600: 0.05491594225168228\n",
            "62600: 0.060881078243255615\n",
            "62700: 0.05051448568701744\n",
            "62700: 0.0537814162671566\n",
            "62800: 0.05195319652557373\n",
            "62800: 0.052087485790252686\n",
            "62900: 0.0539005771279335\n",
            "62900: 0.047298382967710495\n",
            "63000: 0.04690229892730713\n",
            "63000: 0.060849469155073166\n",
            "Mean of last 63000: 0.051779724106743384\n",
            "63100: 0.0521504282951355\n",
            "63100: 0.04894941300153732\n",
            "63200: 0.07031160593032837\n",
            "63200: 0.05584591627120972\n",
            "63300: 0.04970180615782738\n",
            "63300: 0.05378315970301628\n",
            "63400: 0.04873978719115257\n",
            "63400: 0.05360545963048935\n",
            "63500: 0.05512484163045883\n",
            "63500: 0.05054990202188492\n",
            "63600: 0.04852006956934929\n",
            "63600: 0.05849538370966911\n",
            "63700: 0.054026197642087936\n",
            "63700: 0.05262378975749016\n",
            "63800: 0.04692844673991203\n",
            "63800: 0.054794877767562866\n",
            "63900: 0.0443265438079834\n",
            "63900: 0.05126278102397919\n",
            "64000: 0.0522230863571167\n",
            "64000: 0.05173180624842644\n",
            "Mean of last 64000: 0.05177535235390558\n",
            "64100: 0.051277801394462585\n",
            "64100: 0.05312036722898483\n",
            "64200: 0.0482746884226799\n",
            "64200: 0.050960343331098557\n",
            "64300: 0.048621535301208496\n",
            "64300: 0.046823740005493164\n",
            "64400: 0.06420813500881195\n",
            "64400: 0.054002515971660614\n",
            "64500: 0.06796472519636154\n",
            "64500: 0.05194554850459099\n",
            "64600: 0.057310909032821655\n",
            "64600: 0.04990508407354355\n",
            "64700: 0.046003080904483795\n",
            "64700: 0.050063326954841614\n",
            "64800: 0.044956937432289124\n",
            "64800: 0.04528477415442467\n",
            "64900: 0.046729981899261475\n",
            "64900: 0.0535302571952343\n",
            "65000: 0.05532803386449814\n",
            "65000: 0.04829394072294235\n",
            "Mean of last 65000: 0.05163504068481994\n",
            "65100: 0.04192385822534561\n",
            "65100: 0.04458029195666313\n",
            "65200: 0.040516164153814316\n",
            "65200: 0.05633752793073654\n",
            "65300: 0.048683904111385345\n",
            "65300: 0.04909466952085495\n",
            "65400: 0.060588233172893524\n",
            "65400: 0.057703595608472824\n",
            "65500: 0.06182574853301048\n",
            "65500: 0.05510465428233147\n",
            "65600: 0.04992024227976799\n",
            "65600: 0.052659809589385986\n",
            "65700: 0.05130545794963837\n",
            "65700: 0.05299001932144165\n",
            "65800: 0.04677566885948181\n",
            "65800: 0.050064489245414734\n",
            "65900: 0.047558143734931946\n",
            "65900: 0.04963834211230278\n",
            "66000: 0.05584375187754631\n",
            "66000: 0.04417815059423447\n",
            "Mean of last 66000: 0.05177318404701266\n",
            "66100: 0.05476994067430496\n",
            "66100: 0.05478018522262573\n",
            "66200: 0.056396596133708954\n",
            "66200: 0.05686012655496597\n",
            "66300: 0.0558868907392025\n",
            "66300: 0.05512728542089462\n",
            "66400: 0.049179911613464355\n",
            "66400: 0.06603679060935974\n",
            "66500: 0.04724479839205742\n",
            "66500: 0.04511864483356476\n",
            "66600: 0.04628721997141838\n",
            "66600: 0.0495244562625885\n",
            "66700: 0.043327730149030685\n",
            "66700: 0.05710216984152794\n",
            "66800: 0.04997265338897705\n",
            "66800: 0.05204543471336365\n",
            "66900: 0.04158790782094002\n",
            "66900: 0.054124023765325546\n",
            "67000: 0.050010304898023605\n",
            "67000: 0.05077376961708069\n",
            "Mean of last 67000: 0.05166242497933137\n",
            "67100: 0.051236074417829514\n",
            "67100: 0.0553162507712841\n",
            "67200: 0.05046841502189636\n",
            "67200: 0.046695008873939514\n",
            "67300: 0.05521155521273613\n",
            "67300: 0.05111342668533325\n",
            "67400: 0.0513591468334198\n",
            "67400: 0.05155346542596817\n",
            "67500: 0.05337205529212952\n",
            "67500: 0.06012498587369919\n",
            "67600: 0.05666079372167587\n",
            "67600: 0.052043139934539795\n",
            "67700: 0.04665852710604668\n",
            "67700: 0.05230173468589783\n",
            "67800: 0.05044259876012802\n",
            "67800: 0.045755963772535324\n",
            "67900: 0.04402296245098114\n",
            "67900: 0.05592099949717522\n",
            "68000: 0.04503241926431656\n",
            "68000: 0.04809704050421715\n",
            "Mean of last 68000: 0.05163158814085054\n",
            "68100: 0.053606726229190826\n",
            "68100: 0.050008416175842285\n",
            "68200: 0.05398757755756378\n",
            "68200: 0.05281525105237961\n",
            "68300: 0.05721911042928696\n",
            "68300: 0.04578235745429993\n",
            "68400: 0.050281982868909836\n",
            "68400: 0.05512925237417221\n",
            "68500: 0.04888233542442322\n",
            "68500: 0.04963164031505585\n",
            "68600: 0.04743838310241699\n",
            "68600: 0.05171246826648712\n",
            "68700: 0.04919075220823288\n",
            "68700: 0.04863571375608444\n",
            "68800: 0.06616520881652832\n",
            "68800: 0.05487893149256706\n",
            "68900: 0.05409891530871391\n",
            "68900: 0.049098335206508636\n",
            "69000: 0.052988700568675995\n",
            "69000: 0.04693738371133804\n",
            "Mean of last 69000: 0.05161820911243186\n",
            "69100: 0.05221005529165268\n",
            "69100: 0.047313228249549866\n",
            "69200: 0.05022817850112915\n",
            "69200: 0.05515556037425995\n",
            "69300: 0.050479792058467865\n",
            "69300: 0.0427049957215786\n",
            "69400: 0.04571069777011871\n",
            "69400: 0.05022750794887543\n",
            "69500: 0.04780759662389755\n",
            "69500: 0.05647796392440796\n",
            "69600: 0.05530664324760437\n",
            "69600: 0.046212755143642426\n",
            "69700: 0.050998505204916\n",
            "69700: 0.0493430495262146\n",
            "69800: 0.04766421765089035\n",
            "69800: 0.05567656084895134\n",
            "69900: 0.04832163453102112\n",
            "69900: 0.0491708368062973\n",
            "70000: 0.047445110976696014\n",
            "70000: 0.05607708916068077\n",
            "Mean of last 70000: 0.05146984368763663\n",
            "70100: 0.04335234686732292\n",
            "70100: 0.05714337155222893\n",
            "70200: 0.05160689353942871\n",
            "70200: 0.04993659257888794\n",
            "70300: 0.05490940809249878\n",
            "70300: 0.06389814615249634\n",
            "70400: 0.054367050528526306\n",
            "70400: 0.051858168095350266\n",
            "70500: 0.04789455980062485\n",
            "70500: 0.05535757541656494\n",
            "70600: 0.051317691802978516\n",
            "70600: 0.05350648611783981\n",
            "70700: 0.05435128137469292\n",
            "70700: 0.0511973612010479\n",
            "70800: 0.05089744180440903\n",
            "70800: 0.05324902385473251\n",
            "70900: 0.05306663364171982\n",
            "70900: 0.05454808101058006\n",
            "71000: 0.05163035914301872\n",
            "71000: 0.05102316662669182\n",
            "Mean of last 71000: 0.05145676887699298\n",
            "71100: 0.0611262284219265\n",
            "71100: 0.04909757897257805\n",
            "71200: 0.04755598306655884\n",
            "71200: 0.04338528960943222\n",
            "71300: 0.04799766466021538\n",
            "71300: 0.056379616260528564\n",
            "71400: 0.04575648158788681\n",
            "71400: 0.059132471680641174\n",
            "71500: 0.05439114570617676\n",
            "71500: 0.056005239486694336\n",
            "71600: 0.05330878496170044\n",
            "71600: 0.048628754913806915\n",
            "71700: 0.058489955961704254\n",
            "71700: 0.07100357115268707\n",
            "71800: 0.04380977153778076\n",
            "71800: 0.05299215018749237\n",
            "71900: 0.0475357286632061\n",
            "71900: 0.05099768564105034\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72000: 0.04522016644477844\n",
            "72000: 0.04905091971158981\n",
            "Mean of last 72000: 0.05138814006443624\n",
            "72100: 0.04737379401922226\n",
            "72100: 0.044547826051712036\n",
            "72200: 0.05267823860049248\n",
            "72200: 0.048624929040670395\n",
            "72300: 0.053269486874341965\n",
            "72300: 0.054061003029346466\n",
            "72400: 0.052548669278621674\n",
            "72400: 0.051478248089551926\n",
            "72500: 0.04395397752523422\n",
            "72500: 0.053481392562389374\n",
            "72600: 0.05149270221590996\n",
            "72600: 0.05064120143651962\n",
            "72700: 0.051035355776548386\n",
            "72700: 0.055777471512556076\n",
            "72800: 0.04537685215473175\n",
            "72800: 0.04648831486701965\n",
            "72900: 0.06367522478103638\n",
            "72900: 0.04214542359113693\n",
            "73000: 0.04648765176534653\n",
            "73000: 0.05141543596982956\n",
            "Mean of last 73000: 0.051340443613407734\n",
            "73100: 0.05294879525899887\n",
            "73100: 0.05093040317296982\n",
            "73200: 0.05277369171380997\n",
            "73200: 0.053331516683101654\n",
            "73300: 0.05306319519877434\n",
            "73300: 0.05196600407361984\n",
            "73400: 0.04853226989507675\n",
            "73400: 0.04893971607089043\n",
            "73500: 0.05223745107650757\n",
            "73500: 0.051928795874118805\n",
            "73600: 0.05130030959844589\n",
            "73600: 0.05240718647837639\n",
            "73700: 0.044810276478528976\n",
            "73700: 0.04975090175867081\n",
            "73800: 0.05734436213970184\n",
            "73800: 0.06467978656291962\n",
            "73900: 0.049690477550029755\n",
            "73900: 0.059725210070610046\n",
            "74000: 0.04582371562719345\n",
            "74000: 0.04920818656682968\n",
            "Mean of last 74000: 0.05130382318916795\n",
            "74100: 0.050767384469509125\n",
            "74100: 0.05163433402776718\n",
            "74200: 0.04859771579504013\n",
            "74200: 0.04956364631652832\n",
            "74300: 0.049167465418577194\n",
            "74300: 0.05191856250166893\n",
            "74400: 0.04848764091730118\n",
            "74400: 0.0485912561416626\n",
            "74500: 0.04492400214076042\n",
            "74500: 0.048124413937330246\n",
            "74600: 0.047801773995161057\n",
            "74600: 0.05179530382156372\n",
            "74700: 0.054455578327178955\n",
            "74700: 0.0471063032746315\n",
            "74800: 0.0551079623401165\n",
            "74800: 0.06800996512174606\n",
            "74900: 0.04748537391424179\n",
            "74900: 0.04969152808189392\n",
            "75000: 0.05263291299343109\n",
            "75000: 0.05264226719737053\n",
            "Mean of last 75000: 0.051359937363467015\n",
            "75100: 0.05136733502149582\n",
            "75100: 0.05391806364059448\n",
            "75200: 0.057259973138570786\n",
            "75200: 0.04971998184919357\n",
            "75300: 0.04525056481361389\n",
            "75300: 0.0509452149271965\n",
            "75400: 0.05167044326663017\n",
            "75400: 0.051287949085235596\n",
            "75500: 0.05078735575079918\n",
            "75500: 0.046304769814014435\n",
            "75600: 0.05860390514135361\n",
            "75600: 0.05063930153846741\n",
            "75700: 0.06118328869342804\n",
            "75700: 0.05056801438331604\n",
            "75800: 0.055128440260887146\n",
            "75800: 0.04782786965370178\n",
            "75900: 0.04585372656583786\n",
            "75900: 0.049641333520412445\n",
            "76000: 0.054142020642757416\n",
            "76000: 0.05255484580993652\n",
            "Mean of last 76000: 0.05128520251727187\n",
            "76100: 0.04294394701719284\n",
            "76100: 0.049036722630262375\n",
            "76200: 0.05310143530368805\n",
            "76200: 0.046804964542388916\n",
            "76300: 0.0437362901866436\n",
            "76300: 0.05040422081947327\n",
            "76400: 0.0467802993953228\n",
            "76400: 0.04657571762800217\n",
            "76500: 0.04758721590042114\n",
            "76500: 0.04801403731107712\n",
            "76600: 0.058641113340854645\n",
            "76600: 0.04868358373641968\n",
            "76700: 0.04750041663646698\n",
            "76700: 0.04491493105888367\n",
            "76800: 0.04741501808166504\n",
            "76800: 0.055976755917072296\n",
            "76900: 0.051834940910339355\n",
            "76900: 0.04510939121246338\n",
            "77000: 0.05489928275346756\n",
            "77000: 0.05389430746436119\n",
            "Mean of last 77000: 0.05126442711290482\n",
            "77100: 0.05689408630132675\n",
            "77100: 0.06319930404424667\n",
            "77200: 0.06066308543086052\n",
            "77200: 0.051543306559324265\n",
            "77300: 0.051898933947086334\n",
            "77300: 0.05389179289340973\n",
            "77400: 0.05677440017461777\n",
            "77400: 0.048505984246730804\n",
            "77500: 0.055256437510252\n",
            "77500: 0.05523158237338066\n",
            "77600: 0.05389565974473953\n",
            "77600: 0.04497499763965607\n",
            "77700: 0.049362968653440475\n",
            "77700: 0.04449030011892319\n",
            "77800: 0.05364271625876427\n",
            "77800: 0.051276758313179016\n",
            "77900: 0.04910121485590935\n",
            "77900: 0.06047016382217407\n",
            "78000: 0.061378609389066696\n",
            "78000: 0.0452442392706871\n",
            "Mean of last 78000: 0.05137139183285829\n",
            "78100: 0.05125834047794342\n",
            "78100: 0.04753044247627258\n",
            "78200: 0.050517402589321136\n",
            "78200: 0.04866470396518707\n",
            "78300: 0.04227330535650253\n",
            "78300: 0.048844270408153534\n",
            "78400: 0.044127270579338074\n",
            "78400: 0.05124764144420624\n",
            "78500: 0.04929564520716667\n",
            "78500: 0.0499788336455822\n",
            "78600: 0.051453202962875366\n",
            "78600: 0.050486572086811066\n",
            "78700: 0.044182904064655304\n",
            "78700: 0.05577230453491211\n",
            "78800: 0.0493917241692543\n",
            "78800: 0.047187142074108124\n",
            "78900: 0.05031875893473625\n",
            "78900: 0.05871957540512085\n",
            "79000: 0.04775187373161316\n",
            "79000: 0.04187267646193504\n",
            "Mean of last 79000: 0.051304025757875474\n",
            "79100: 0.05144238471984863\n",
            "79100: 0.04702272638678551\n",
            "79200: 0.04899425059556961\n",
            "79200: 0.05413569137454033\n",
            "79300: 0.0503615140914917\n",
            "79300: 0.05394598841667175\n",
            "79400: 0.052137501537799835\n",
            "79400: 0.05003209039568901\n",
            "79500: 0.04847421497106552\n",
            "79500: 0.06223103031516075\n",
            "79600: 0.05531696602702141\n",
            "79600: 0.057129696011543274\n",
            "79700: 0.0476725809276104\n",
            "79700: 0.048904698342084885\n",
            "79800: 0.050389163196086884\n",
            "79800: 0.06312242895364761\n",
            "79900: 0.05529535561800003\n",
            "79900: 0.041691362857818604\n",
            "80000: 0.051035843789577484\n",
            "80000: 0.045321203768253326\n",
            "Mean of last 80000: 0.051169191687167825\n",
            "80100: 0.04686573147773743\n",
            "80100: 0.04574413225054741\n",
            "80200: 0.04833652824163437\n",
            "80200: 0.04646840691566467\n",
            "80300: 0.05145145580172539\n",
            "80300: 0.053595781326293945\n",
            "80400: 0.050930023193359375\n",
            "80400: 0.048205822706222534\n",
            "80500: 0.05256742238998413\n",
            "80500: 0.04889340698719025\n",
            "80600: 0.05098281428217888\n",
            "80600: 0.0504133515059948\n",
            "80700: 0.04433124512434006\n",
            "80700: 0.047379933297634125\n",
            "80800: 0.04783114790916443\n",
            "80800: 0.04736008495092392\n",
            "80900: 0.049583058804273605\n",
            "80900: 0.05328317731618881\n",
            "81000: 0.049364447593688965\n",
            "81000: 0.0547783225774765\n",
            "Mean of last 81000: 0.05120950016368936\n",
            "81100: 0.04751402139663696\n",
            "81100: 0.0501229465007782\n",
            "81200: 0.05149538815021515\n",
            "81200: 0.05365025997161865\n",
            "81300: 0.04509029537439346\n",
            "81300: 0.04954475909471512\n",
            "81400: 0.05651582404971123\n",
            "81400: 0.047711294144392014\n",
            "81500: 0.04485245794057846\n",
            "81500: 0.0455998033285141\n",
            "81600: 0.05417024716734886\n",
            "81600: 0.04967062175273895\n",
            "81700: 0.05063685402274132\n",
            "81700: 0.05864047259092331\n",
            "81800: 0.04709697887301445\n",
            "81800: 0.056413259357213974\n",
            "81900: 0.051013924181461334\n",
            "81900: 0.04980044066905975\n",
            "82000: 0.04585157334804535\n",
            "82000: 0.04701460152864456\n",
            "Mean of last 82000: 0.051238527677796936\n",
            "82100: 0.04915116727352142\n",
            "82100: 0.04867653548717499\n",
            "82200: 0.05102790892124176\n",
            "82200: 0.045974068343639374\n",
            "82300: 0.05377573519945145\n",
            "82300: 0.05632472038269043\n",
            "82400: 0.04212567210197449\n",
            "82400: 0.04836354777216911\n",
            "82500: 0.05166954919695854\n",
            "82500: 0.05050104856491089\n",
            "82600: 0.049988918006420135\n",
            "82600: 0.06132877618074417\n",
            "82700: 0.054211169481277466\n",
            "82700: 0.050251781940460205\n",
            "82800: 0.04468190297484398\n",
            "82800: 0.060116883367300034\n",
            "82900: 0.04391060397028923\n",
            "82900: 0.0506373755633831\n",
            "83000: 0.054711177945137024\n",
            "83000: 0.04737190529704094\n",
            "Mean of last 83000: 0.051094539078337685\n",
            "83100: 0.04672491177916527\n",
            "83100: 0.05608552321791649\n",
            "83200: 0.04510965570807457\n",
            "83200: 0.05749238654971123\n",
            "83300: 0.04910720884799957\n",
            "83300: 0.04551021009683609\n",
            "83400: 0.043958283960819244\n",
            "83400: 0.04824712499976158\n",
            "83500: 0.043248988687992096\n",
            "83500: 0.05363915488123894\n",
            "83600: 0.05199764296412468\n",
            "83600: 0.05122097581624985\n",
            "83700: 0.04462656378746033\n",
            "83700: 0.043585874140262604\n",
            "83800: 0.04492441937327385\n",
            "83800: 0.05709237977862358\n",
            "83900: 0.04401567578315735\n",
            "83900: 0.04412960633635521\n",
            "84000: 0.06105128675699234\n",
            "84000: 0.05416737124323845\n",
            "Mean of last 84000: 0.050921098990635676\n",
            "84100: 0.05577852576971054\n",
            "84100: 0.047891151160001755\n",
            "84200: 0.0439472422003746\n",
            "84200: 0.05607980117201805\n",
            "84300: 0.0404246561229229\n",
            "84300: 0.05122894048690796\n",
            "84400: 0.055430129170417786\n",
            "84400: 0.04724220559000969\n",
            "84500: 0.04857255145907402\n",
            "84500: 0.04952246695756912\n",
            "84600: 0.04903449863195419\n",
            "84600: 0.04593463987112045\n",
            "84700: 0.05078728497028351\n",
            "84700: 0.05498736351728439\n",
            "84800: 0.057393066585063934\n",
            "84800: 0.06154873967170715\n",
            "84900: 0.06050653010606766\n",
            "84900: 0.05474404618144035\n",
            "85000: 0.05145832523703575\n",
            "85000: 0.06548462808132172\n",
            "Mean of last 85000: 0.051151838103359513\n",
            "85100: 0.05949421972036362\n",
            "85100: 0.049645259976387024\n",
            "85200: 0.05087747797369957\n",
            "85200: 0.05099045857787132\n",
            "85300: 0.047419752925634384\n",
            "85300: 0.06561262905597687\n",
            "85400: 0.046989746391773224\n",
            "85400: 0.045921921730041504\n",
            "85500: 0.05562007427215576\n",
            "85500: 0.04994719848036766\n",
            "85600: 0.04970841109752655\n",
            "85600: 0.045170318335294724\n",
            "85700: 0.046913109719753265\n",
            "85700: 0.04467630013823509\n",
            "85800: 0.05452338978648186\n",
            "85800: 0.04906146228313446\n",
            "85900: 0.047035958617925644\n",
            "85900: 0.04602734372019768\n",
            "86000: 0.04995492845773697\n",
            "86000: 0.053717240691185\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of last 86000: 0.05074414533640181\n",
            "86100: 0.05235457420349121\n",
            "86100: 0.05278623104095459\n",
            "86200: 0.04788140207529068\n",
            "86200: 0.04868433624505997\n",
            "86300: 0.052841782569885254\n",
            "86300: 0.046087585389614105\n",
            "86400: 0.0492841973900795\n",
            "86400: 0.04980812594294548\n",
            "86500: 0.05827926844358444\n",
            "86500: 0.046086907386779785\n",
            "86600: 0.05593101680278778\n",
            "86600: 0.0466947928071022\n",
            "86700: 0.050065211951732635\n",
            "86700: 0.043556295335292816\n",
            "86800: 0.048065122216939926\n",
            "86800: 0.04573942348361015\n",
            "86900: 0.058404773473739624\n",
            "86900: 0.059779178351163864\n",
            "87000: 0.04875034838914871\n",
            "87000: 0.05089304968714714\n",
            "Mean of last 87000: 0.05095864346922635\n",
            "87100: 0.05559783801436424\n",
            "87100: 0.0545271597802639\n",
            "87600: 0.05775715038180351\n",
            "87600: 0.05009755492210388\n",
            "87700: 0.04932955652475357\n",
            "87700: 0.05240480601787567\n",
            "87800: 0.04919804260134697\n",
            "87800: 0.05802125856280327\n",
            "87900: 0.04398862272500992\n",
            "87900: 0.04907826706767082\n",
            "88000: 0.05522921308875084\n",
            "88000: 0.050005458295345306\n",
            "Mean of last 88000: 0.051053410738364204\n",
            "88100: 0.050666626542806625\n",
            "88100: 0.046611398458480835\n",
            "88200: 0.04641508683562279\n",
            "88200: 0.04558665305376053\n",
            "88300: 0.0648125633597374\n",
            "88300: 0.04741748794913292\n",
            "88400: 0.05022358149290085\n",
            "88400: 0.047580212354660034\n",
            "88500: 0.04751480743288994\n",
            "88500: 0.04664745554327965\n",
            "88600: 0.057431429624557495\n",
            "88600: 0.0488831102848053\n",
            "88700: 0.054044321179389954\n",
            "88700: 0.049794964492321014\n",
            "88800: 0.04758545011281967\n",
            "88800: 0.05114421248435974\n",
            "88900: 0.04658970236778259\n",
            "88900: 0.04604099318385124\n",
            "89000: 0.054285190999507904\n",
            "89000: 0.052702032029628754\n",
            "Mean of last 89000: 0.05093776788395066\n",
            "89100: 0.04414926469326019\n",
            "89100: 0.056692056357860565\n",
            "89200: 0.05156843364238739\n",
            "89200: 0.05042513459920883\n",
            "89300: 0.04888325184583664\n",
            "89300: 0.048315584659576416\n",
            "89400: 0.0431440994143486\n",
            "89400: 0.046618230640888214\n",
            "89500: 0.055847346782684326\n",
            "89500: 0.04624956101179123\n",
            "89600: 0.04849658161401749\n",
            "89600: 0.05429556593298912\n",
            "89700: 0.05109759420156479\n",
            "89700: 0.05188174173235893\n",
            "89800: 0.048772357404232025\n",
            "89800: 0.05107313394546509\n",
            "89900: 0.06001577898859978\n",
            "89900: 0.0469013974070549\n",
            "90000: 0.05992605909705162\n",
            "90000: 0.04929591715335846\n",
            "Mean of last 90000: 0.050972952132488224\n",
            "90100: 0.043097760528326035\n",
            "90100: 0.04796653985977173\n",
            "90200: 0.04682091996073723\n",
            "90200: 0.05054561421275139\n",
            "90300: 0.05027805268764496\n",
            "90300: 0.040577780455350876\n",
            "90400: 0.04417651891708374\n",
            "90400: 0.057224374264478683\n",
            "90500: 0.05321556329727173\n",
            "90500: 0.04531114548444748\n",
            "90600: 0.04972401261329651\n",
            "90600: 0.05032286047935486\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69dca0a0",
      "metadata": {
        "id": "69dca0a0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}