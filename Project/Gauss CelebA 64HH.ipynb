{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Download precalculated Wavelet data for HH"
      ],
      "metadata": {
        "id": "vH_lQ5PRRFwR"
      },
      "id": "vH_lQ5PRRFwR"
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticate and create the PyDrive client\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1wcuvhFWQ7HefHnhr90mPPsB8PTb-CJx8\"})   \n",
        "downloaded.GetContentFile('HH.zip')"
      ],
      "metadata": {
        "id": "wjN4Ohx_Q7d3"
      },
      "id": "wjN4Ohx_Q7d3",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "145012dc",
      "metadata": {
        "id": "145012dc",
        "outputId": "50aa768d-96ca-4f8d-a5fb-c2b611b936fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cold-Diffusion-Models'...\n",
            "remote: Enumerating objects: 262, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 262 (delta 47), reused 38 (delta 33), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (262/262), 2.65 MiB | 16.36 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/arpitbansal297/Cold-Diffusion-Models.git\n",
        "!apt-get install unzip\n",
        "!unzip -q -j HH.zip -d ./root_celebA_128_train_new_HH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22708788",
      "metadata": {
        "id": "22708788",
        "outputId": "213778a5-81ce-4986-c7e2-d47e99517492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!pip install comet_ml einops tqdm torchgeometry matplotlib einops scikit-image sklearn pywavelets opencv-python --quiet\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "import pywt\n",
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/')\n",
        "from comet_ml import Experiment\n",
        "import torchvision\n",
        "import os\n",
        "import errno\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0c9d149",
      "metadata": {
        "id": "d0c9d149"
      },
      "outputs": [],
      "source": [
        "# %load 'Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py'\n",
        "from comet_ml import Experiment\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "from torch.utils import data\n",
        "from pathlib import Path\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange\n",
        "\n",
        "import torchgeometry as tgm\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch import linalg as LA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "try:\n",
        "    from apex import amp\n",
        "    APEX_AVAILABLE = True\n",
        "except:\n",
        "    APEX_AVAILABLE = False\n",
        "\n",
        "# helpers functions\n",
        "\n",
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if isfunction(d) else d\n",
        "\n",
        "def cycle(dl):\n",
        "    while True:\n",
        "        for data in dl:\n",
        "            yield data\n",
        "\n",
        "def num_to_groups(num, divisor):\n",
        "    groups = num // divisor\n",
        "    remainder = num % divisor\n",
        "    arr = [divisor] * groups\n",
        "    if remainder > 0:\n",
        "        arr.append(remainder)\n",
        "    return arr\n",
        "\n",
        "def loss_backwards(fp16, loss, optimizer, **kwargs):\n",
        "    if fp16:\n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "            scaled_loss.backward(**kwargs)\n",
        "    else:\n",
        "        loss.backward(**kwargs)\n",
        "\n",
        "# small helper modules\n",
        "\n",
        "class EMA():\n",
        "    def __init__(self, beta):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def update_model_average(self, ma_model, current_model):\n",
        "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
        "            old_weight, up_weight = ma_params.data, current_params.data\n",
        "            ma_params.data = self.update_average(old_weight, up_weight)\n",
        "\n",
        "    def update_average(self, old, new):\n",
        "        if old is None:\n",
        "            return new\n",
        "        return old * self.beta + (1 - self.beta) * new\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "def Upsample(dim):\n",
        "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "def Downsample(dim):\n",
        "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim, eps = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
        "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
        "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
        "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)\n",
        "\n",
        "# building block modules\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    \"\"\" https://arxiv.org/abs/2201.03545 \"\"\"\n",
        "\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim = None, mult = 2, norm = True):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_emb_dim, dim)\n",
        "        ) if exists(time_emb_dim) else None\n",
        "\n",
        "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding = 3, groups = dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            LayerNorm(dim) if norm else nn.Identity(),\n",
        "            nn.Conv2d(dim, dim_out * mult, 3, padding = 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim_out * mult, dim_out, 3, padding = 1)\n",
        "        )\n",
        "\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb = None):\n",
        "        h = self.ds_conv(x)\n",
        "\n",
        "        if exists(self.mlp):\n",
        "            assert exists(time_emb), 'time emb must be passed in'\n",
        "            condition = self.mlp(time_emb)\n",
        "            h = h + rearrange(condition, 'b c -> b c 1 1')\n",
        "\n",
        "        h = self.net(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
        "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
        "        q = q * self.scale\n",
        "\n",
        "        k = k.softmax(dim = -1)\n",
        "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
        "\n",
        "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
        "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "# model\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 3,\n",
        "        with_time_emb = True,\n",
        "        residual = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.residual = residual\n",
        "        print(\"Is Time embed used ? \", with_time_emb)\n",
        "\n",
        "        dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        if with_time_emb:\n",
        "            time_dim = dim\n",
        "            self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPosEmb(dim),\n",
        "                nn.Linear(dim, dim * 4),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(dim * 4, dim)\n",
        "            )\n",
        "        else:\n",
        "            time_dim = None\n",
        "            self.time_mlp = None\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_in, dim_out, time_emb_dim = time_dim, norm = ind != 0),\n",
        "                ConvNextBlock(dim_out, dim_out, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                Downsample(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim)))\n",
        "        self.mid_block2 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_out * 2, dim_in, time_emb_dim = time_dim),\n",
        "                ConvNextBlock(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                Upsample(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        out_dim = default(out_dim, channels)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            ConvNextBlock(dim, dim),\n",
        "            nn.Conv2d(dim, out_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        orig_x = x\n",
        "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
        "\n",
        "        h = []\n",
        "\n",
        "        for convnext, convnext2, attn, downsample in self.downs:\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        for convnext, convnext2, attn, upsample in self.ups:\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            x = upsample(x)\n",
        "        if self.residual:\n",
        "            return self.final_conv(x) + orig_x\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# gaussian diffusion trainer class\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "def noise_like(shape, device, repeat=False):\n",
        "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n",
        "    noise = lambda: torch.randn(shape, device=device)\n",
        "    return repeat_noise() if repeat else noise()\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s = 0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule\n",
        "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, steps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "class GaussianDiffusion(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        denoise_fn,\n",
        "        *,\n",
        "        image_size,\n",
        "        channels = 3,\n",
        "        timesteps = 1000,\n",
        "        loss_type = 'l1',\n",
        "        train_routine = 'Final',\n",
        "        sampling_routine='default',\n",
        "        discrete=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.denoise_fn = denoise_fn\n",
        "\n",
        "        self.num_timesteps = int(timesteps)\n",
        "        self.loss_type = loss_type\n",
        "\n",
        "        betas = cosine_beta_schedule(timesteps)\n",
        "        alphas = 1. - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
        "\n",
        "        self.train_routine = train_routine\n",
        "        self.sampling_routine = sampling_routine\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, batch_size = 16, img=None, t=None):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        xt = img\n",
        "        direct_recons = None\n",
        "\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            if direct_recons is None:\n",
        "                direct_recons = x1_bar\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        self.denoise_fn.train()\n",
        "\n",
        "        return xt, direct_recons, img\n",
        "\n",
        "    def get_x2_bar_from_xt(self, x1_bar, xt, t):\n",
        "        return (\n",
        "                (xt - extract(self.sqrt_alphas_cumprod, t, x1_bar.shape) * x1_bar) /\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x1_bar.shape)\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def gen_sample(self, batch_size=16, img=None, t=None):\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        noise = img\n",
        "        direct_recons = None\n",
        "\n",
        "        if self.sampling_routine == 'ddim':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        elif self.sampling_routine == 'x0_step_down':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = noise\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        return noise, direct_recons, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward_and_backward(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        Forward = []\n",
        "        Forward.append(img)\n",
        "\n",
        "        noise = torch.randn_like(img)\n",
        "\n",
        "        for i in range(t):\n",
        "            with torch.no_grad():\n",
        "                step = torch.full((batch_size,), i, dtype=torch.long, device=img.device)\n",
        "                n_img = self.q_sample(x_start=img, x_end=noise, t=step)\n",
        "                Forward.append(n_img)\n",
        "\n",
        "        Backward = []\n",
        "        img = n_img\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = noise #self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            Backward.append(img)\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return Forward, Backward, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def all_sample(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        if eval:\n",
        "            self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        X1_0s, X2_0s, X_ts = [], [], []\n",
        "        while (t):\n",
        "\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "\n",
        "            X1_0s.append(x1_bar.detach().cpu())\n",
        "            X2_0s.append(x2_bar.detach().cpu())\n",
        "            X_ts.append(img.detach().cpu())\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return X1_0s, X2_0s, X_ts\n",
        "\n",
        "    def q_sample(self, x_start, x_end, t):\n",
        "        # simply use the alphas to interpolate\n",
        "        return (\n",
        "                extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * x_end\n",
        "        )\n",
        "\n",
        "    def p_losses(self, x_start, x_end, t):\n",
        "        b, c, h, w = x_start.shape\n",
        "        if self.train_routine == 'Final':\n",
        "            x_mix = self.q_sample(x_start=x_start, x_end=x_end, t=t)\n",
        "            x_recon = self.denoise_fn(x_mix, t)\n",
        "            if self.loss_type == 'l1':\n",
        "                loss = (x_start - x_recon).abs().mean()\n",
        "            elif self.loss_type == 'l2':\n",
        "                loss = F.mse_loss(x_start, x_recon)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x1, x2, *args, **kwargs):\n",
        "        b, c, h, w, device, img_size, = *x1.shape, x1.device, self.image_size\n",
        "        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n",
        "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
        "        return self.p_losses(x1, x2, t, *args, **kwargs)\n",
        "\n",
        "class Dataset_Aug1(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts = ['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.RandomCrop(image_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts=['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "# trainer class\n",
        "import os\n",
        "import errno\n",
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "from collections import OrderedDict\n",
        "def remove_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('.module', '')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "def adjust_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('denoise_fn.module', 'module.denoise_fn')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        diffusion_model,\n",
        "        folder,\n",
        "        *,\n",
        "        ema_decay = 0.995,\n",
        "        image_size = 128,\n",
        "        train_batch_size = 32,\n",
        "        train_lr = 2e-5,\n",
        "        train_num_steps = 100000,\n",
        "        gradient_accumulate_every = 2,\n",
        "        fp16 = False,\n",
        "        step_start_ema = 2000,\n",
        "        update_ema_every = 10,\n",
        "        save_and_sample_every = 1000,\n",
        "        results_folder = './results',\n",
        "        load_path = None,\n",
        "        dataset = None,\n",
        "        shuffle=True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = diffusion_model\n",
        "        self.ema = EMA(ema_decay)\n",
        "        self.ema_model = copy.deepcopy(self.model)\n",
        "        self.update_ema_every = update_ema_every\n",
        "\n",
        "        self.step_start_ema = step_start_ema\n",
        "        self.save_and_sample_every = save_and_sample_every\n",
        "\n",
        "        self.batch_size = train_batch_size\n",
        "        self.image_size = image_size\n",
        "        self.gradient_accumulate_every = gradient_accumulate_every\n",
        "        self.train_num_steps = train_num_steps\n",
        "\n",
        "        if dataset == 'train':\n",
        "            print(dataset, \"DA used\")\n",
        "            self.ds = Dataset_Aug1(folder, image_size)\n",
        "        else:\n",
        "            print(dataset)\n",
        "            self.ds = Dataset(folder, image_size)\n",
        "\n",
        "        self.dl = cycle(data.DataLoader(self.ds, batch_size = train_batch_size, shuffle=shuffle, pin_memory=True, num_workers=16, drop_last=True))\n",
        "\n",
        "        self.opt = Adam(diffusion_model.parameters(), lr=train_lr)\n",
        "        self.step = 0\n",
        "\n",
        "        self.results_folder = Path(results_folder)\n",
        "        self.results_folder.mkdir(exist_ok = True)\n",
        "\n",
        "        self.fp16 = fp16\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "        if load_path != None:\n",
        "            self.load(load_path)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.ema_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def step_ema(self):\n",
        "        if self.step < self.step_start_ema:\n",
        "            self.reset_parameters()\n",
        "            return\n",
        "        self.ema.update_model_average(self.ema_model, self.model)\n",
        "\n",
        "    def save(self, itrs=None):\n",
        "        data = {\n",
        "            'step': self.step,\n",
        "            'model': self.model.state_dict(),\n",
        "            'ema': self.ema_model.state_dict()\n",
        "        }\n",
        "        if itrs is None:\n",
        "            torch.save(data, str(self.results_folder / f'model.pt'))\n",
        "        else:\n",
        "            torch.save(data, str(self.results_folder / f'model_{itrs}.pt'))\n",
        "\n",
        "    def load(self, load_path):\n",
        "        print(\"Loading : \", load_path)\n",
        "        data = torch.load(load_path)\n",
        "\n",
        "        self.step = data['step']\n",
        "        self.model.load_state_dict(data['model'])\n",
        "        self.ema_model.load_state_dict(data['ema'])\n",
        "\n",
        "\n",
        "    def add_title(self, path, title):\n",
        "\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        img1 = cv2.imread(path)\n",
        "\n",
        "        # --- Here I am creating the border---\n",
        "        black = [0, 0, 0]  # ---Color of the border---\n",
        "        constant = cv2.copyMakeBorder(img1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "        height = 20\n",
        "        violet = np.zeros((height, constant.shape[1], 3), np.uint8)\n",
        "        violet[:] = (255, 0, 180)\n",
        "\n",
        "        vcat = cv2.vconcat((violet, constant))\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        cv2.putText(vcat, str(title), (violet.shape[1] // 2, height-2), font, 0.5, (0, 0, 0), 1, 0)\n",
        "        cv2.imwrite(path, vcat)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        backwards = partial(loss_backwards, self.fp16)\n",
        "\n",
        "        acc_loss = 0\n",
        "        while self.step < self.train_num_steps:\n",
        "            u_loss = 0\n",
        "            for i in range(self.gradient_accumulate_every):\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "\n",
        "                data_1, data_2 = data_1.cuda(), data_2.cuda()\n",
        "                loss = torch.mean(self.model(data_1, data_2))\n",
        "                if self.step % 100 == 0:\n",
        "                    print(f'{self.step}: {loss.item()}')\n",
        "                u_loss += loss.item()\n",
        "                backwards(loss / self.gradient_accumulate_every, self.opt)\n",
        "\n",
        "            acc_loss = acc_loss + (u_loss/self.gradient_accumulate_every)\n",
        "\n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "            if self.step % self.update_ema_every == 0:\n",
        "                self.step_ema()\n",
        "\n",
        "            if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
        "                milestone = self.step // self.save_and_sample_every\n",
        "                batches = self.batch_size\n",
        "\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "                og_img = data_2.cuda()\n",
        "\n",
        "                xt, direct_recons, all_images = self.ema_model.module.sample(batch_size=batches, img=og_img)\n",
        "\n",
        "                og_img = (og_img + 1) * 0.5\n",
        "                utils.save_image(og_img, str(self.results_folder / f'sample-og-{milestone}.png'), nrow=6)\n",
        "\n",
        "                all_images = (all_images + 1) * 0.5\n",
        "                utils.save_image(all_images, str(self.results_folder / f'sample-recon-{milestone}.png'), nrow = 6)\n",
        "\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'sample-direct_recons-{milestone}.png'), nrow=6)\n",
        "\n",
        "                xt = (xt + 1) * 0.5\n",
        "                utils.save_image(xt, str(self.results_folder / f'sample-xt-{milestone}.png'),\n",
        "                                 nrow=6)\n",
        "\n",
        "                acc_loss = acc_loss/(self.save_and_sample_every+1)\n",
        "                print(f'Mean of last {self.step}: {acc_loss}')\n",
        "                acc_loss=0\n",
        "\n",
        "                self.save()\n",
        "                if self.step % (self.save_and_sample_every * 100) == 0:\n",
        "                    self.save(self.step)\n",
        "\n",
        "            self.step += 1\n",
        "\n",
        "        print('training completed')\n",
        "\n",
        "    def test_from_data(self, extra_path, s_times=None):\n",
        "        batches = self.batch_size\n",
        "        og_img = next(self.dl).cuda()\n",
        "        a, X_0s, X_ts = self.ema_model.module.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images, str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "    def sample_and_save_for_fid(self, noise=0):\n",
        "\n",
        "        # xt_folder = f'{self.results_folder}_xt'\n",
        "        # create_folder(xt_folder)\n",
        "\n",
        "        out_folder = f'{self.results_folder}_out'\n",
        "        create_folder(out_folder)\n",
        "\n",
        "        # direct_recons_folder = f'{self.results_folder}_dir_recons'\n",
        "        # create_folder(direct_recons_folder)\n",
        "\n",
        "        # data_1 = next(self.dl)\n",
        "\n",
        "        cnt = 0\n",
        "        bs = 128\n",
        "        for j in range(int(6400/bs)):\n",
        "\n",
        "            data_2 = torch.randn(bs, 3, 64, 64)\n",
        "            og_img = data_2.cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            xt, direct_recons, all_images = self.ema_model.module.gen_sample(batch_size=bs, img=og_img)\n",
        "\n",
        "            for i in range(all_images.shape[0]):\n",
        "                utils.save_image((all_images[i] + 1) * 0.5,\n",
        "                                 str(f'{out_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                # utils.save_image((xt[i] + 1) * 0.5,\n",
        "                #                  str(f'{xt_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                #\n",
        "                # utils.save_image((direct_recons[i] + 1) * 0.5,\n",
        "                #                  str(f'{direct_recons_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images_cover_page(self):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # for 200 steps\n",
        "        # to_show = [2, 4, 8, 16, 32, 64, 128, 192]\n",
        "        to_show = [2, 4, 16, 64, 128, 256, 384, 448, 480]\n",
        "\n",
        "        for i in range(5):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            Forward, Backward, final_all = self.ema_model.module.forward_and_backward(batch_size=batches, img=og_img)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            final_all = (final_all + 1) * 0.5\n",
        "\n",
        "\n",
        "\n",
        "            for k in range(Forward[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                utils.save_image(og_img[k], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "                start = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "                l.append(start)\n",
        "\n",
        "                for j in range(len(Forward)):\n",
        "                    x_t = Forward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "                for j in range(len(Backward)):\n",
        "                    x_t = Backward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if (len(Backward) - j) in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                utils.save_image(final_all[k], str(self.results_folder / f'final_{cnt}.png'), nrow=1)\n",
        "                final = cv2.imread(f'{self.results_folder}/final_{cnt}.png')\n",
        "                l.append(final)\n",
        "\n",
        "\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_invert_section_images(self, s_times=None):\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for j in range(og_img.shape[0]//3):\n",
        "                original = og_img[j: j + 1]\n",
        "                utils.save_image(original, str(self.results_folder / f'original_{cnt}.png'), nrow=3)\n",
        "\n",
        "                direct_recons = X_0s[0][j: j + 1]\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'direct_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                sampling_recons = X_0s[-1][j: j + 1]\n",
        "                sampling_recons = (sampling_recons + 1) * 0.5\n",
        "                utils.save_image(sampling_recons, str(self.results_folder / f'sampling_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                blurry_image = X_ts[0][j: j + 1]\n",
        "                blurry_image = (blurry_image + 1) * 0.5\n",
        "                utils.save_image(blurry_image, str(self.results_folder / f'blurry_image_{cnt}.png'), nrow=3)\n",
        "\n",
        "\n",
        "\n",
        "                import cv2\n",
        "\n",
        "                blurry_image = cv2.imread(f'{self.results_folder}/blurry_image_{cnt}.png')\n",
        "                direct_recons = cv2.imread(f'{self.results_folder}/direct_recons_{cnt}.png')\n",
        "                sampling_recons = cv2.imread(f'{self.results_folder}/sampling_recons_{cnt}.png')\n",
        "                original = cv2.imread(f'{self.results_folder}/original_{cnt}.png')\n",
        "\n",
        "                black = [0, 0, 0]\n",
        "                blurry_image = cv2.copyMakeBorder(blurry_image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                direct_recons = cv2.copyMakeBorder(direct_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                sampling_recons = cv2.copyMakeBorder(sampling_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                original = cv2.copyMakeBorder(original, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([blurry_image, direct_recons, sampling_recons, original])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 24, 32, 40, 44, 46, 48, 49]\n",
        "        to_show = [0, 2, 4, 8, 16, 32, 64, 80, 88, 92, 96, 98, 99]\n",
        "\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for k in range(X_ts[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                for j in range(len(X_ts)):\n",
        "                    x_t = X_ts[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'x_{len(X_ts)-j}_{cnt}.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/x_{len(X_ts)-j}_{cnt}.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                x_0 = X_0s[-1][k]\n",
        "                x_0 = (x_0 + 1) * 0.5\n",
        "                utils.save_image(x_0, str(self.results_folder / f'x_best_{cnt}.png'), nrow=1)\n",
        "                x_0 = cv2.imread(f'{self.results_folder}/x_best_{cnt}.png')\n",
        "                l.append(x_0)\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_showing_diffusion_images_diff(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, X_ts_alg2 = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "            X_0s_alg1, X_ts_alg1 = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            alg2 = []\n",
        "            alg1 = []\n",
        "\n",
        "            #to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "            to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "\n",
        "            for j in range(len(X_ts_alg2)):\n",
        "                x_t = X_ts_alg2[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg2)-j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg2)-j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg2.append(x_t)\n",
        "\n",
        "                x_t = X_ts_alg1[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg1) - j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg1) - j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg1.append(x_t)\n",
        "\n",
        "\n",
        "            x_0 = X_0s_alg2[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg2_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg2_{i}.png')\n",
        "            alg2.append(x_0)\n",
        "            im_h = cv2.hconcat(alg2)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg2_{i}.png', im_h)\n",
        "\n",
        "            x_0 = X_0s_alg1[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg1_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg1_{i}.png')\n",
        "            alg1.append(x_0)\n",
        "            im_h = cv2.hconcat(alg1)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg1_{i}.png', im_h)\n",
        "\n",
        "\n",
        "    def paper_showing_sampling_diff_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        for i in range(10):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, _ = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches, img=og_img, times=s_times)\n",
        "            X_0s_alg1, _ = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            x0_alg1 = (X_0s_alg1[-1] + 1) * 0.5\n",
        "            x0_alg2 = (X_0s_alg2[-1] + 1) * 0.5\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "\n",
        "            for j in range(og_img.shape[0]):\n",
        "                utils.save_image(x0_alg1[j], str(self.results_folder / f'x0_alg1_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(x0_alg2[j], str(self.results_folder / f'x0_alg2_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(og_img[j], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "\n",
        "\n",
        "\n",
        "                alg1 = cv2.imread(f'{self.results_folder}/x0_alg1_{cnt}.png')\n",
        "                alg2 = cv2.imread(f'{self.results_folder}/x0_alg2_{cnt}.png')\n",
        "                og = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "\n",
        "\n",
        "                black = [255, 255, 255]\n",
        "                alg1 = cv2.copyMakeBorder(alg1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                alg2 = cv2.copyMakeBorder(alg2, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                og = cv2.copyMakeBorder(og, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([og, alg1, alg2])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def sample_as_a_vector_gmm(self, start=0, end=1000, siz=64, ch=3, clusters=10):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "\n",
        "        num_samples = 100\n",
        "\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "        og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "        og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "        og_x = torch.from_numpy(og_x).cuda()\n",
        "        og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "        print(og_x.shape)\n",
        "        og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "\n",
        "\n",
        "        X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "        extra_path = 'vec'\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{start}-{end}-{siz}-{clusters}-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'),\n",
        "                             nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images,\n",
        "                             str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_gmm_and_save(self, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 10000\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "            og_x = torch.from_numpy(og_x).cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "        all_samples = None\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "\n",
        "        #all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num / num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/')\n",
        "\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            #og_x, _ = model.sample(n=num_samples)\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            blurs = X_ts[0]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((blurs[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/' + f'sample-blur-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "    def sample_as_a_vector_from_blur_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "\n",
        "        #sample_at = self.ema_model.num_timesteps // 2\n",
        "        sample_at = self.ema_model.num_timesteps // 2\n",
        "        all_samples = None\n",
        "\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = self.ema_model.opt(img.cuda(), t=sample_at)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "                #all_samples.append(img[0])\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        # all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}_{sample_at}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample_from_blur(batch_size=og_img.shape[0], img=og_img, start_times=sample_at)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "\n",
        "\n",
        "\n",
        "    def sample_from_data_save(self, start=0, end=1000):\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 1000]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "    def fid_distance_decrease_from_manifold(self, fid_func, start=0, end=1000):\n",
        "\n",
        "        #from skimage.metrics import structural_similarity as ssim\n",
        "        from pytorch_msssim import ssim\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        # create_folder(f'{self.results_folder}/')\n",
        "        blurred_samples = None\n",
        "        original_sample = None\n",
        "        deblurred_samples = None\n",
        "        direct_deblurred_samples = None\n",
        "\n",
        "        sanity_check = 1\n",
        "\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 100]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            og_img = og_img.to('cpu')\n",
        "            blurry_imgs = X_ts[0].to('cpu')\n",
        "            deblurry_imgs = X_0s[-1].to('cpu')\n",
        "            direct_deblurry_imgs = X_0s[0].to('cpu')\n",
        "\n",
        "            og_img = og_img.repeat(1, 3 // og_img.shape[1], 1, 1)\n",
        "            blurry_imgs = blurry_imgs.repeat(1, 3 // blurry_imgs.shape[1], 1, 1)\n",
        "            deblurry_imgs = deblurry_imgs.repeat(1, 3 // deblurry_imgs.shape[1], 1, 1)\n",
        "            direct_deblurry_imgs = direct_deblurry_imgs.repeat(1, 3 // direct_deblurry_imgs.shape[1], 1, 1)\n",
        "\n",
        "\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            blurry_imgs = (blurry_imgs + 1) * 0.5\n",
        "            deblurry_imgs = (deblurry_imgs + 1) * 0.5\n",
        "            direct_deblurry_imgs = (direct_deblurry_imgs + 1) * 0.5\n",
        "\n",
        "            if cnt == 0:\n",
        "                print(og_img.shape)\n",
        "                print(blurry_imgs.shape)\n",
        "                print(deblurry_imgs.shape)\n",
        "                print(direct_deblurry_imgs.shape)\n",
        "\n",
        "                if sanity_check:\n",
        "                    folder = './sanity_check/'\n",
        "                    create_folder(folder)\n",
        "\n",
        "                    san_imgs = og_img[0: 32]\n",
        "                    utils.save_image(san_imgs,str(folder + f'sample-og.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = blurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-xt.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-recons.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = direct_deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-direct-recons.png'), nrow=6)\n",
        "\n",
        "\n",
        "            if blurred_samples is None:\n",
        "                blurred_samples = blurry_imgs\n",
        "            else:\n",
        "                blurred_samples = torch.cat((blurred_samples, blurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if original_sample is None:\n",
        "                original_sample = og_img\n",
        "            else:\n",
        "                original_sample = torch.cat((original_sample, og_img), dim=0)\n",
        "\n",
        "\n",
        "            if deblurred_samples is None:\n",
        "                deblurred_samples = deblurry_imgs\n",
        "            else:\n",
        "                deblurred_samples = torch.cat((deblurred_samples, deblurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if direct_deblurred_samples is None:\n",
        "                direct_deblurred_samples = direct_deblurry_imgs\n",
        "            else:\n",
        "                direct_deblurred_samples = torch.cat((direct_deblurred_samples, direct_deblurry_imgs), dim=0)\n",
        "\n",
        "            cnt += og_img.shape[0]\n",
        "\n",
        "        print(blurred_samples.shape)\n",
        "        print(original_sample.shape)\n",
        "        print(deblurred_samples.shape)\n",
        "        print(direct_deblurred_samples.shape)\n",
        "\n",
        "        fid_blur = fid_func(samples=[original_sample, blurred_samples])\n",
        "        rmse_blur = torch.sqrt(torch.mean( (original_sample - blurred_samples)**2 ))\n",
        "        ssim_blur = ssim(original_sample, blurred_samples, data_range=1, size_average=True)\n",
        "        # n_og = original_sample.cpu().detach().numpy()\n",
        "        # n_bs = blurred_samples.cpu().detach().numpy()\n",
        "        # ssim_blur = ssim(n_og, n_bs, data_range=n_og.max() - n_og.min(), multichannel=True)\n",
        "        print(f'The FID of blurry images with original image is {fid_blur}')\n",
        "        print(f'The RMSE of blurry images with original image is {rmse_blur}')\n",
        "        print(f'The SSIM of blurry images with original image is {ssim_blur}')\n",
        "\n",
        "\n",
        "        fid_deblur = fid_func(samples=[original_sample, deblurred_samples])\n",
        "        rmse_deblur = torch.sqrt(torch.mean((original_sample - deblurred_samples) ** 2))\n",
        "        ssim_deblur = ssim(original_sample, deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of deblurred images with original image is {fid_deblur}')\n",
        "        print(f'The RMSE of deblurred images with original image is {rmse_deblur}')\n",
        "        print(f'The SSIM of deblurred images with original image is {ssim_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using sampling is {fid_blur - fid_deblur}')\n",
        "\n",
        "        fid_direct_deblur = fid_func(samples=[original_sample, direct_deblurred_samples])\n",
        "        rmse_direct_deblur = torch.sqrt(torch.mean((original_sample - direct_deblurred_samples) ** 2))\n",
        "        ssim_direct_deblur = ssim(original_sample, direct_deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of direct deblurred images with original image is {fid_direct_deblur}')\n",
        "        print(f'The RMSE of direct deblurred images with original image is {rmse_direct_deblur}')\n",
        "        print(f'The SSIM of direct deblurred images with original image is {ssim_direct_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using direct sampling is {fid_blur - fid_direct_deblur}')\n",
        "\n",
        "\n",
        "            # x0s = X_0s[-1]\n",
        "            # for i in range(x0s.shape[0]):\n",
        "            #     utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "            #     cnt += 1\n",
        "\n",
        "    def save_training_data(self):\n",
        "        dataset = self.ds\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = (img + 1) * 0.5\n",
        "            utils.save_image(img, str(f'{self.results_folder}/' + f'{idx}.png'))\n",
        "            if idx%1000 == 0:\n",
        "                print(idx)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d076ce5c",
      "metadata": {
        "id": "d076ce5c"
      },
      "outputs": [],
      "source": [
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "def del_folder(path):\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "    except OSError as exc:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eafcb743",
      "metadata": {
        "id": "eafcb743",
        "outputId": "0dfec935-6568-49c1-d948-cdc7de86a8a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Time embed used ?  False\n",
            "HH\n"
          ]
        }
      ],
      "source": [
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA\"\n",
        "data_path=\"./root_celebA_128_train_new_HH/\"\n",
        "load_path=None\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine =  train_routine,\n",
        "    sampling_routine =  sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    folder=data_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps =  train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder =  save_folder,\n",
        "    load_path =  load_path,\n",
        "    dataset = 'HH'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "740da495",
      "metadata": {
        "id": "740da495",
        "outputId": "7aa3fe96-bbb3-4f5b-ae5a-d12d50069473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0: 0.5649994015693665\n",
            "0: 0.5710329413414001\n",
            "100: 0.3826390206813812\n",
            "100: 0.46969446539878845\n",
            "200: 0.2947993874549866\n",
            "200: 0.3344644010066986\n",
            "300: 0.23465560376644135\n",
            "300: 0.21614739298820496\n",
            "400: 0.15238547325134277\n",
            "400: 0.1355317085981369\n",
            "500: 0.1178150326013565\n",
            "500: 0.10833462327718735\n",
            "600: 0.12890887260437012\n",
            "600: 0.10636807978153229\n",
            "700: 0.1176949292421341\n",
            "700: 0.11621376127004623\n",
            "800: 0.10233896970748901\n",
            "800: 0.093064084649086\n",
            "900: 0.08596082776784897\n",
            "900: 0.10026880353689194\n",
            "1000: 0.09077537059783936\n",
            "1000: 0.08885715901851654\n",
            "Mean of last 1000: 0.1977576645282837\n",
            "1100: 0.10315732657909393\n",
            "1100: 0.0968347117304802\n",
            "1200: 0.09864383935928345\n",
            "1200: 0.0923033356666565\n",
            "1300: 0.07706309109926224\n",
            "1300: 0.09612008184194565\n",
            "1400: 0.08736471831798553\n",
            "1400: 0.09577368944883347\n",
            "1500: 0.08642353862524033\n",
            "1500: 0.08757328242063522\n",
            "1600: 0.08583106845617294\n",
            "1600: 0.0852741003036499\n",
            "1700: 0.08164310455322266\n",
            "1700: 0.08308329433202744\n",
            "1800: 0.08225881308317184\n",
            "1800: 0.07685521990060806\n",
            "1900: 0.08436690270900726\n",
            "1900: 0.07684950530529022\n",
            "2000: 0.08486931771039963\n",
            "2000: 0.0838630422949791\n",
            "Mean of last 2000: 0.08609926911977145\n",
            "2100: 0.07614298909902573\n",
            "2100: 0.08718421310186386\n",
            "2600: 0.08270780742168427\n",
            "2600: 0.0763699859380722\n",
            "2700: 0.08011437207460403\n",
            "2700: 0.06850185990333557\n",
            "2800: 0.07781065255403519\n",
            "2800: 0.0750047117471695\n",
            "2900: 0.07887803018093109\n",
            "2900: 0.07710908353328705\n",
            "3000: 0.07892816513776779\n",
            "3000: 0.0762285590171814\n",
            "Mean of last 3000: 0.07672775259146562\n",
            "3100: 0.07446622103452682\n",
            "3100: 0.08832856267690659\n",
            "3200: 0.07093973457813263\n",
            "3200: 0.06746162474155426\n",
            "3300: 0.06398408859968185\n",
            "3300: 0.06765779107809067\n",
            "3400: 0.07202911376953125\n",
            "3400: 0.0757983922958374\n",
            "3500: 0.07057734578847885\n",
            "3500: 0.06946907937526703\n",
            "3600: 0.06758072227239609\n",
            "3600: 0.06806571781635284\n",
            "3700: 0.06433840841054916\n",
            "3700: 0.07269945740699768\n",
            "3800: 0.06922893226146698\n",
            "3800: 0.07237105071544647\n",
            "3900: 0.06356215476989746\n",
            "3900: 0.07539486140012741\n",
            "4000: 0.06594765931367874\n",
            "4000: 0.0680915042757988\n",
            "Mean of last 4000: 0.07106369554430812\n",
            "4100: 0.07125629484653473\n",
            "4100: 0.07094001024961472\n",
            "4200: 0.069244384765625\n",
            "4200: 0.06892909854650497\n",
            "4300: 0.061348721385002136\n",
            "4300: 0.06452867388725281\n",
            "4400: 0.07421918958425522\n",
            "4400: 0.06449611485004425\n",
            "4500: 0.06105226278305054\n",
            "4500: 0.07605867832899094\n",
            "4600: 0.06500869244337082\n",
            "4600: 0.06019216030836105\n",
            "4700: 0.06304487586021423\n",
            "4700: 0.06270183622837067\n",
            "4800: 0.0781262144446373\n",
            "4800: 0.07058767974376678\n",
            "4900: 0.0626540333032608\n",
            "4900: 0.062388479709625244\n",
            "5000: 0.06302065402269363\n",
            "5000: 0.06258224695920944\n",
            "Mean of last 5000: 0.06672843210734092\n",
            "5100: 0.059032004326581955\n",
            "5100: 0.06354355812072754\n",
            "5200: 0.07084354758262634\n",
            "5200: 0.06337632983922958\n",
            "5300: 0.05791880935430527\n",
            "5300: 0.06477968394756317\n",
            "5400: 0.06580046564340591\n",
            "5400: 0.06083647534251213\n",
            "5500: 0.06578977406024933\n",
            "5500: 0.058678075671195984\n",
            "5600: 0.0623193085193634\n",
            "5600: 0.06535997986793518\n",
            "5700: 0.05681989714503288\n",
            "5700: 0.06399254500865936\n",
            "5800: 0.06180061027407646\n",
            "5800: 0.05743291974067688\n",
            "5900: 0.05757378786802292\n",
            "5900: 0.08068346232175827\n",
            "6000: 0.05718187987804413\n",
            "6000: 0.06335358321666718\n",
            "Mean of last 6000: 0.06326249226384409\n",
            "6100: 0.06377261132001877\n",
            "6100: 0.055924009531736374\n",
            "6200: 0.0662301629781723\n",
            "6200: 0.06450705230236053\n",
            "6300: 0.0639575719833374\n",
            "6300: 0.0603010468184948\n",
            "6400: 0.0684375986456871\n",
            "6400: 0.05252061039209366\n",
            "6500: 0.054426297545433044\n",
            "6500: 0.07372403144836426\n",
            "6600: 0.05119696259498596\n",
            "6600: 0.05545363947749138\n",
            "6700: 0.051902614533901215\n",
            "6700: 0.053895674645900726\n",
            "6800: 0.05838806554675102\n",
            "6800: 0.07217492908239365\n",
            "6900: 0.05542948096990585\n",
            "6900: 0.05569586902856827\n",
            "7000: 0.05770896002650261\n",
            "7000: 0.05431009829044342\n",
            "Mean of last 7000: 0.06047922454506427\n",
            "7100: 0.05725540965795517\n",
            "7100: 0.05981762707233429\n",
            "7200: 0.053351324051618576\n",
            "7200: 0.056789323687553406\n",
            "7300: 0.05763513967394829\n",
            "7300: 0.05207525193691254\n",
            "7400: 0.06232338398694992\n",
            "7400: 0.05757790431380272\n",
            "7500: 0.0641128420829773\n",
            "7500: 0.06494231522083282\n",
            "7600: 0.06108173727989197\n",
            "7600: 0.060629721730947495\n",
            "7700: 0.0488579086959362\n",
            "7700: 0.05622054263949394\n",
            "7800: 0.04881465062499046\n",
            "7800: 0.05916760861873627\n",
            "7900: 0.05187282711267471\n",
            "7900: 0.05207626149058342\n",
            "8000: 0.055812325328588486\n",
            "8000: 0.058488696813583374\n",
            "Mean of last 8000: 0.05776092973905248\n",
            "8100: 0.05471193790435791\n",
            "8100: 0.05609294772148132\n",
            "8200: 0.0508592389523983\n",
            "8200: 0.059183016419410706\n",
            "8300: 0.05762729048728943\n",
            "8300: 0.05599646270275116\n",
            "8400: 0.059142421931028366\n",
            "8400: 0.06475271284580231\n",
            "8500: 0.05537142604589462\n",
            "8500: 0.06544339656829834\n",
            "8600: 0.06463426351547241\n",
            "8600: 0.05138879269361496\n",
            "8700: 0.0513966903090477\n",
            "8700: 0.059693556278944016\n",
            "8800: 0.05246075242757797\n",
            "8800: 0.05484812706708908\n",
            "8900: 0.05153387784957886\n",
            "8900: 0.05883411318063736\n",
            "9000: 0.056937843561172485\n",
            "9000: 0.0536307655274868\n",
            "Mean of last 9000: 0.05524145848081483\n",
            "9100: 0.06038004159927368\n",
            "9100: 0.05725255608558655\n",
            "9200: 0.054312970489263535\n",
            "9200: 0.04892574995756149\n",
            "9300: 0.05311068147420883\n",
            "9300: 0.05030035972595215\n",
            "9400: 0.0583031103014946\n",
            "9400: 0.058027081191539764\n",
            "9500: 0.05323116108775139\n",
            "9500: 0.05311942100524902\n",
            "9600: 0.04971284791827202\n",
            "9600: 0.04818519949913025\n",
            "9700: 0.04737406224012375\n",
            "9700: 0.05157129466533661\n",
            "9800: 0.055852871388196945\n",
            "9800: 0.04849369451403618\n",
            "9900: 0.060825884342193604\n",
            "9900: 0.04876159876585007\n",
            "10000: 0.05114638805389404\n",
            "10000: 0.051305197179317474\n",
            "Mean of last 10000: 0.05325706477475155\n",
            "10100: 0.05520112067461014\n",
            "10100: 0.04815664887428284\n",
            "10200: 0.052245914936065674\n",
            "10200: 0.049395423382520676\n",
            "10300: 0.04253247380256653\n",
            "10300: 0.050472598522901535\n",
            "10400: 0.050172653049230576\n",
            "10400: 0.06376679986715317\n",
            "10500: 0.05275718867778778\n",
            "10500: 0.04725540801882744\n",
            "10600: 0.06104051694273949\n",
            "10600: 0.050652217119932175\n",
            "10700: 0.052038129419088364\n",
            "10700: 0.050062671303749084\n",
            "10800: 0.04705647751688957\n",
            "10800: 0.05335996299982071\n",
            "10900: 0.04866377264261246\n",
            "10900: 0.05181393027305603\n",
            "11000: 0.048109304159879684\n",
            "11000: 0.056016843765974045\n",
            "Mean of last 11000: 0.05127798769805398\n",
            "11100: 0.05036697909235954\n",
            "11100: 0.05086299777030945\n",
            "11200: 0.05112503096461296\n",
            "11200: 0.05686038359999657\n",
            "11300: 0.04785178601741791\n",
            "11300: 0.05128198117017746\n",
            "11400: 0.04494612663984299\n",
            "11400: 0.0527145192027092\n",
            "11500: 0.04706556722521782\n",
            "11500: 0.045340679585933685\n",
            "11600: 0.05290999263525009\n",
            "11600: 0.05091997981071472\n",
            "11700: 0.05058455467224121\n",
            "11700: 0.05417845398187637\n",
            "11800: 0.045224275439977646\n",
            "11800: 0.04509955272078514\n",
            "11900: 0.04813883826136589\n",
            "11900: 0.04608681797981262\n",
            "12000: 0.05639032647013664\n",
            "12000: 0.055451080203056335\n",
            "Mean of last 12000: 0.04998521209060848\n",
            "12100: 0.05840890854597092\n",
            "12100: 0.04652036353945732\n",
            "12200: 0.0476628802716732\n",
            "12200: 0.04413227364420891\n",
            "12300: 0.04148169234395027\n",
            "12300: 0.04860597476363182\n",
            "12400: 0.048270370811223984\n",
            "12400: 0.04630487412214279\n",
            "12500: 0.050008416175842285\n",
            "12500: 0.045998137444257736\n",
            "12600: 0.05212466046214104\n",
            "12600: 0.05492892116308212\n",
            "12700: 0.04806630313396454\n",
            "12700: 0.05365089699625969\n",
            "12800: 0.04866259545087814\n",
            "12800: 0.04916585236787796\n",
            "12900: 0.05466752499341965\n",
            "12900: 0.05164939910173416\n",
            "13000: 0.05312307924032211\n",
            "13000: 0.047528307884931564\n",
            "Mean of last 13000: 0.04930531056216368\n",
            "13100: 0.04667596518993378\n",
            "13100: 0.053701646625995636\n",
            "13200: 0.04846414923667908\n",
            "13200: 0.05218195170164108\n",
            "13300: 0.04265205189585686\n",
            "13300: 0.04331478103995323\n",
            "13400: 0.04398384317755699\n",
            "13400: 0.05058543384075165\n",
            "13500: 0.048621248453855515\n",
            "13500: 0.04393009468913078\n",
            "13600: 0.0460907518863678\n",
            "13600: 0.05244393274188042\n",
            "13700: 0.0446220338344574\n",
            "13700: 0.053091615438461304\n",
            "13800: 0.04750631004571915\n",
            "13800: 0.05451085418462753\n",
            "13900: 0.04853251203894615\n",
            "13900: 0.043616585433483124\n",
            "14000: 0.051056187599897385\n",
            "14000: 0.05686085671186447\n",
            "Mean of last 14000: 0.048357972897566874\n",
            "14100: 0.04536003991961479\n",
            "14100: 0.050216466188430786\n",
            "14200: 0.05654195696115494\n",
            "14200: 0.04297330230474472\n",
            "14300: 0.04412806034088135\n",
            "14300: 0.050093065947294235\n",
            "14400: 0.05189590901136398\n",
            "14400: 0.045993831008672714\n",
            "14500: 0.04423823580145836\n",
            "14500: 0.04035593569278717\n",
            "14600: 0.0461161732673645\n",
            "14600: 0.042999476194381714\n",
            "14700: 0.04138608276844025\n",
            "14700: 0.04600057005882263\n",
            "14800: 0.0559706911444664\n",
            "14800: 0.046450547873973846\n",
            "14900: 0.04199895262718201\n",
            "14900: 0.04874624311923981\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15000: 0.04648144170641899\n",
            "15000: 0.05821482464671135\n",
            "Mean of last 15000: 0.047753161859589735\n",
            "15100: 0.04604355990886688\n",
            "15100: 0.04061766713857651\n",
            "15200: 0.04541981220245361\n",
            "15200: 0.04629538953304291\n",
            "15300: 0.04762640595436096\n",
            "15300: 0.051541201770305634\n",
            "15400: 0.04146374389529228\n",
            "15400: 0.04177842289209366\n",
            "15500: 0.045389868319034576\n",
            "15500: 0.04084368422627449\n",
            "15600: 0.04551462456583977\n",
            "15600: 0.04679492115974426\n",
            "15700: 0.04597809910774231\n",
            "15700: 0.04838024079799652\n",
            "15800: 0.049945369362831116\n",
            "15800: 0.04744788631796837\n",
            "15900: 0.05417701601982117\n",
            "15900: 0.05090215057134628\n",
            "16000: 0.04623753949999809\n",
            "16000: 0.051024094223976135\n",
            "Mean of last 16000: 0.04724422560727501\n",
            "16100: 0.04347579926252365\n",
            "16100: 0.04175180196762085\n",
            "16200: 0.052437566220760345\n",
            "16200: 0.04348528012633324\n",
            "16300: 0.04169832170009613\n",
            "16300: 0.051394812762737274\n",
            "16400: 0.04696013778448105\n",
            "16400: 0.04608800634741783\n",
            "16500: 0.055172719061374664\n",
            "16500: 0.04400663822889328\n",
            "16600: 0.04164191707968712\n",
            "16600: 0.04379991441965103\n",
            "16700: 0.0461798720061779\n",
            "16700: 0.05223553627729416\n",
            "16800: 0.04519953578710556\n",
            "16800: 0.05043017491698265\n",
            "16900: 0.04512438178062439\n",
            "16900: 0.04392018914222717\n",
            "17000: 0.044858720153570175\n",
            "17000: 0.04116222262382507\n",
            "Mean of last 17000: 0.04683414324708692\n",
            "17100: 0.04091081768274307\n",
            "17100: 0.04957045242190361\n",
            "17200: 0.04068766161799431\n",
            "17200: 0.046410053968429565\n",
            "17300: 0.04825298488140106\n",
            "17300: 0.05454569309949875\n",
            "17400: 0.04316702485084534\n",
            "17400: 0.04536193609237671\n",
            "17500: 0.04675360023975372\n",
            "17500: 0.042891066521406174\n",
            "17600: 0.04542700573801994\n",
            "17600: 0.04889056086540222\n",
            "17700: 0.04998882859945297\n",
            "17700: 0.041927121579647064\n",
            "17800: 0.04753675311803818\n",
            "17800: 0.052816517651081085\n",
            "17900: 0.04989410936832428\n",
            "17900: 0.04670032113790512\n",
            "18000: 0.05124349519610405\n",
            "18000: 0.04259644076228142\n",
            "Mean of last 18000: 0.04656838546213987\n",
            "18100: 0.04236485809087753\n",
            "18100: 0.04759807512164116\n",
            "18200: 0.045755185186862946\n",
            "18200: 0.051563844084739685\n",
            "18300: 0.04511430859565735\n",
            "18300: 0.04280044883489609\n",
            "18400: 0.04804537817835808\n",
            "18400: 0.05329987406730652\n",
            "18500: 0.04669497534632683\n",
            "18500: 0.03943070024251938\n",
            "18600: 0.03941728547215462\n",
            "18600: 0.048761025071144104\n",
            "18700: 0.0389135517179966\n",
            "18700: 0.043739404529333115\n",
            "18800: 0.04906880110502243\n",
            "18800: 0.05056063085794449\n",
            "18900: 0.06555008888244629\n",
            "18900: 0.04683968424797058\n",
            "19000: 0.05344756692647934\n",
            "19000: 0.05484343692660332\n",
            "Mean of last 19000: 0.04633936378825735\n",
            "19100: 0.05031914636492729\n",
            "19100: 0.04183116555213928\n",
            "19200: 0.045770447701215744\n",
            "19200: 0.04958416521549225\n",
            "19300: 0.039652444422245026\n",
            "19300: 0.04621206223964691\n",
            "19400: 0.04040779173374176\n",
            "19400: 0.05608217045664787\n",
            "19500: 0.04832467436790466\n",
            "19500: 0.04422628879547119\n",
            "19600: 0.046494778245687485\n",
            "19600: 0.04209759086370468\n",
            "19700: 0.04352030158042908\n",
            "19700: 0.051242291927337646\n",
            "19800: 0.051138751208782196\n",
            "19800: 0.04274850711226463\n",
            "19900: 0.041232459247112274\n",
            "19900: 0.04087033495306969\n",
            "20000: 0.04570535942912102\n",
            "20000: 0.04249638319015503\n",
            "Mean of last 20000: 0.045934849432655626\n",
            "20100: 0.043858569115400314\n",
            "20100: 0.04067489504814148\n",
            "20200: 0.04817469045519829\n",
            "20200: 0.04197248816490173\n",
            "20300: 0.0432470440864563\n",
            "20300: 0.04351312667131424\n",
            "20400: 0.04374058172106743\n",
            "20400: 0.041940391063690186\n",
            "20500: 0.04374265298247337\n",
            "20500: 0.04443562030792236\n",
            "20600: 0.05007344111800194\n",
            "20600: 0.04750002548098564\n",
            "20700: 0.055081240832805634\n",
            "20700: 0.05094709247350693\n",
            "20800: 0.04813721403479576\n",
            "20800: 0.041099220514297485\n",
            "20900: 0.046712033450603485\n",
            "20900: 0.04510709270834923\n",
            "21000: 0.04315613955259323\n",
            "21000: 0.046188995242118835\n",
            "Mean of last 21000: 0.04556374802262514\n",
            "21100: 0.04387177154421806\n",
            "21100: 0.048646390438079834\n",
            "21200: 0.04211088642477989\n",
            "21200: 0.0445694699883461\n",
            "21300: 0.04188835620880127\n",
            "21300: 0.04840477928519249\n",
            "21400: 0.047711994498968124\n",
            "21400: 0.0470498651266098\n",
            "21500: 0.04739771783351898\n",
            "21500: 0.04249022528529167\n",
            "21600: 0.045022930949926376\n",
            "21600: 0.04182835668325424\n",
            "21700: 0.05285999923944473\n",
            "21700: 0.04258721321821213\n",
            "21800: 0.0667797103524208\n",
            "21800: 0.04391224682331085\n",
            "21900: 0.038146600127220154\n",
            "21900: 0.05067415162920952\n",
            "22000: 0.040386494249105453\n",
            "22000: 0.05050063133239746\n",
            "Mean of last 22000: 0.04544667817920178\n",
            "22100: 0.05003192648291588\n",
            "22100: 0.047822028398513794\n",
            "22200: 0.039441727101802826\n",
            "22200: 0.057179972529411316\n",
            "22300: 0.04653770849108696\n",
            "22300: 0.049093108624219894\n",
            "22400: 0.04648394510149956\n",
            "22400: 0.04059666767716408\n",
            "22500: 0.038274846971035004\n",
            "22500: 0.04676113650202751\n",
            "22600: 0.04685696214437485\n",
            "22600: 0.054378069937229156\n",
            "22700: 0.04086144268512726\n",
            "22700: 0.03708141669631004\n",
            "22800: 0.04756699502468109\n",
            "22800: 0.04358748719096184\n",
            "22900: 0.05108804255723953\n",
            "22900: 0.04428444057703018\n",
            "23000: 0.04448578879237175\n",
            "23000: 0.046728961169719696\n",
            "Mean of last 23000: 0.04548744696167323\n",
            "23100: 0.03831396624445915\n",
            "23100: 0.04246295616030693\n",
            "23200: 0.042702119797468185\n",
            "23200: 0.04029468819499016\n",
            "23300: 0.04128022864460945\n",
            "23300: 0.04065731167793274\n",
            "23400: 0.04395684599876404\n",
            "23400: 0.03988181799650192\n",
            "23500: 0.05594088137149811\n",
            "23500: 0.048131853342056274\n",
            "23600: 0.048763737082481384\n",
            "23600: 0.04437471553683281\n",
            "23700: 0.044080834835767746\n",
            "23700: 0.04370013624429703\n",
            "23800: 0.042077019810676575\n",
            "23800: 0.046524517238140106\n",
            "23900: 0.04574766010046005\n",
            "23900: 0.049049012362957\n",
            "24000: 0.04879045486450195\n",
            "24000: 0.04568469524383545\n",
            "Mean of last 24000: 0.04541705053794634\n",
            "24100: 0.043562792241573334\n",
            "24100: 0.04304639995098114\n",
            "24200: 0.04064206779003143\n",
            "24200: 0.04273701831698418\n",
            "24300: 0.04509048908948898\n",
            "24300: 0.04498479887843132\n",
            "24400: 0.04366665333509445\n",
            "24400: 0.052146077156066895\n",
            "24500: 0.04324353486299515\n",
            "24500: 0.044877659529447556\n",
            "24600: 0.044841255992650986\n",
            "24600: 0.04069461673498154\n",
            "24700: 0.04097337648272514\n",
            "24700: 0.047978322952985764\n",
            "24800: 0.04241287708282471\n",
            "24800: 0.040476541966199875\n",
            "24900: 0.04518534988164902\n",
            "24900: 0.03899712488055229\n",
            "25000: 0.04587438702583313\n",
            "25000: 0.04672732949256897\n",
            "Mean of last 25000: 0.044991951558616135\n",
            "25100: 0.04555904492735863\n",
            "25100: 0.040064387023448944\n",
            "25200: 0.04572673887014389\n",
            "25200: 0.04146238788962364\n",
            "25300: 0.0476086288690567\n",
            "25300: 0.04819703847169876\n",
            "25400: 0.04878717660903931\n",
            "25400: 0.05182584375143051\n",
            "25500: 0.04828270524740219\n",
            "25500: 0.04085533320903778\n",
            "25600: 0.04929670691490173\n",
            "25600: 0.05866781994700432\n",
            "25700: 0.04466542229056358\n",
            "25700: 0.042581669986248016\n",
            "25800: 0.048306338489055634\n",
            "25800: 0.050935517996549606\n",
            "25900: 0.042380984872579575\n",
            "25900: 0.04460174962878227\n",
            "26000: 0.044232599437236786\n",
            "26000: 0.05520879477262497\n",
            "Mean of last 26000: 0.04471635927895566\n",
            "26100: 0.04375447332859039\n",
            "26100: 0.04318910092115402\n",
            "26200: 0.04951835796236992\n",
            "26200: 0.04800531268119812\n",
            "26300: 0.046698492020368576\n",
            "26300: 0.04860031604766846\n",
            "26400: 0.04124218970537186\n",
            "26400: 0.040805988013744354\n",
            "26500: 0.04912693798542023\n",
            "26500: 0.04132054001092911\n",
            "26600: 0.03797972947359085\n",
            "26600: 0.03936121612787247\n",
            "26700: 0.0459970086812973\n",
            "26700: 0.04303812235593796\n",
            "26800: 0.04572805017232895\n",
            "26800: 0.050922244787216187\n",
            "26900: 0.04350380226969719\n",
            "26900: 0.043064575642347336\n",
            "27000: 0.043711334466934204\n",
            "27000: 0.041705917567014694\n",
            "Mean of last 27000: 0.044615092762670554\n",
            "27100: 0.03959494084119797\n",
            "27100: 0.04174354672431946\n",
            "27200: 0.03852679580450058\n",
            "27200: 0.04100532457232475\n",
            "27300: 0.04976767301559448\n",
            "27300: 0.047483086585998535\n",
            "27400: 0.045001812279224396\n",
            "27400: 0.04726932570338249\n",
            "27500: 0.041640523821115494\n",
            "27500: 0.045484792441129684\n",
            "27600: 0.040853261947631836\n",
            "27600: 0.039984721690416336\n",
            "27700: 0.041132956743240356\n",
            "27700: 0.047422390431165695\n",
            "27800: 0.04219171404838562\n",
            "27800: 0.042203210294246674\n",
            "27900: 0.041157305240631104\n",
            "27900: 0.04040655121207237\n",
            "28000: 0.04668339341878891\n",
            "28000: 0.047712620347738266\n",
            "Mean of last 28000: 0.044429569887546275\n",
            "28100: 0.044285111129283905\n",
            "28100: 0.04238530993461609\n",
            "28200: 0.04711877927184105\n",
            "28200: 0.0448874793946743\n",
            "28300: 0.051593117415905\n",
            "28300: 0.04455741494894028\n",
            "28400: 0.051646023988723755\n",
            "28400: 0.05407116934657097\n",
            "28500: 0.05381638556718826\n",
            "28500: 0.040005698800086975\n",
            "28600: 0.041648656129837036\n",
            "28600: 0.04244191199541092\n",
            "28700: 0.042493969202041626\n",
            "28700: 0.042540647089481354\n",
            "28800: 0.0419822596013546\n",
            "28800: 0.03884909301996231\n",
            "28900: 0.04239317774772644\n",
            "28900: 0.046714477241039276\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "29000: 0.04436880350112915\n",
            "29000: 0.04070213437080383\n",
            "Mean of last 29000: 0.04432177925473088\n",
            "29100: 0.041158609092235565\n",
            "29100: 0.049037035554647446\n",
            "29200: 0.042178064584732056\n",
            "29200: 0.04234014451503754\n",
            "29300: 0.04175734147429466\n",
            "29300: 0.04801894724369049\n",
            "29400: 0.040612250566482544\n",
            "29400: 0.04729946702718735\n",
            "29500: 0.06065418943762779\n",
            "29500: 0.04286716505885124\n",
            "29600: 0.042322319000959396\n",
            "29600: 0.05016138777136803\n",
            "29700: 0.03973102569580078\n",
            "29700: 0.03922266513109207\n",
            "29800: 0.04792387783527374\n",
            "29800: 0.054773978888988495\n",
            "29900: 0.041282977908849716\n",
            "29900: 0.04171330854296684\n",
            "30000: 0.047047875821590424\n",
            "30000: 0.04403461515903473\n",
            "Mean of last 30000: 0.04436258147735815\n",
            "30100: 0.04237748309969902\n",
            "30100: 0.04858534783124924\n",
            "30200: 0.05204491317272186\n",
            "30200: 0.043226614594459534\n",
            "30300: 0.04991352558135986\n",
            "30300: 0.040513284504413605\n",
            "30400: 0.04460541531443596\n",
            "30400: 0.04029896482825279\n",
            "30500: 0.053764935582876205\n",
            "30500: 0.04290314018726349\n",
            "30600: 0.04305332154035568\n",
            "30600: 0.04920107126235962\n",
            "30700: 0.05030383914709091\n",
            "30700: 0.04449872672557831\n",
            "30800: 0.03604310750961304\n",
            "30800: 0.0441289022564888\n",
            "30900: 0.04032294452190399\n",
            "30900: 0.046103090047836304\n",
            "31000: 0.04402124881744385\n",
            "31000: 0.045467130839824677\n",
            "Mean of last 31000: 0.04421553791469925\n",
            "31100: 0.04697493463754654\n",
            "31100: 0.04616831988096237\n",
            "31200: 0.040003079921007156\n",
            "31200: 0.03928861767053604\n",
            "31300: 0.04645390436053276\n",
            "31300: 0.03784957900643349\n",
            "31700: 0.04343177005648613\n",
            "31700: 0.041071489453315735\n",
            "31800: 0.04634396359324455\n",
            "31800: 0.044906727969646454\n",
            "31900: 0.05527234077453613\n",
            "31900: 0.043710753321647644\n",
            "32000: 0.04459458589553833\n",
            "32000: 0.04541386291384697\n",
            "Mean of last 32000: 0.04400071760566978\n",
            "32100: 0.04090811312198639\n",
            "32100: 0.041879232972860336\n",
            "32200: 0.03893602266907692\n",
            "32200: 0.039716944098472595\n",
            "32300: 0.049412861466407776\n",
            "32300: 0.04882501810789108\n",
            "32400: 0.04886326938867569\n",
            "32400: 0.049697935581207275\n",
            "32500: 0.0414920449256897\n",
            "32500: 0.054114483296871185\n",
            "32600: 0.048606377094984055\n",
            "32600: 0.04488193988800049\n",
            "32700: 0.048266634345054626\n",
            "32700: 0.04498865827918053\n",
            "32800: 0.0483255498111248\n",
            "32800: 0.03923805430531502\n",
            "32900: 0.042304378002882004\n",
            "32900: 0.04498919099569321\n",
            "33000: 0.04238153621554375\n",
            "33000: 0.04280608892440796\n",
            "Mean of last 33000: 0.044133238829337396\n",
            "33100: 0.038778893649578094\n",
            "33100: 0.04609284922480583\n",
            "33200: 0.04384410381317139\n",
            "33200: 0.03977176919579506\n",
            "33300: 0.06344762444496155\n",
            "33300: 0.047186173498630524\n",
            "33400: 0.0430712029337883\n",
            "33400: 0.040628306567668915\n",
            "33500: 0.04780853912234306\n",
            "33500: 0.04474776238203049\n",
            "33600: 0.040174007415771484\n",
            "33600: 0.04450162872672081\n",
            "33700: 0.041503965854644775\n",
            "33700: 0.03701058030128479\n",
            "33800: 0.0494365319609642\n",
            "33800: 0.04548410698771477\n",
            "33900: 0.04581081122159958\n",
            "33900: 0.04910261929035187\n",
            "34000: 0.04026089608669281\n",
            "34000: 0.04698948189616203\n",
            "Mean of last 34000: 0.043915284479355124\n",
            "34100: 0.04691045731306076\n",
            "34100: 0.038162603974342346\n",
            "34200: 0.04110976681113243\n",
            "34200: 0.04985146224498749\n",
            "34300: 0.04321187734603882\n",
            "34300: 0.04959544539451599\n",
            "34400: 0.03891342878341675\n",
            "34400: 0.05672214552760124\n",
            "34500: 0.04770399257540703\n",
            "34500: 0.040922537446022034\n",
            "34600: 0.04868825525045395\n",
            "34600: 0.04468733072280884\n",
            "34700: 0.046388834714889526\n",
            "34700: 0.040026091039180756\n",
            "34800: 0.0482359305024147\n",
            "34800: 0.044206418097019196\n",
            "34900: 0.0419338159263134\n",
            "34900: 0.04949994012713432\n",
            "35000: 0.038235150277614594\n",
            "35000: 0.0395854115486145\n",
            "Mean of last 35000: 0.043759280246320545\n",
            "35100: 0.0469185933470726\n",
            "35100: 0.03989464044570923\n",
            "35200: 0.03701336309313774\n",
            "35200: 0.04113294556736946\n",
            "35300: 0.04149402305483818\n",
            "35300: 0.03837160766124725\n",
            "35400: 0.043728671967983246\n",
            "35400: 0.0482572577893734\n",
            "35500: 0.048888202756643295\n",
            "35500: 0.045391540974378586\n",
            "35600: 0.041366346180438995\n",
            "35600: 0.0363195538520813\n",
            "35700: 0.040354155004024506\n",
            "35700: 0.043775178492069244\n",
            "35800: 0.04704871401190758\n",
            "35800: 0.046259112656116486\n",
            "35900: 0.04170799255371094\n",
            "35900: 0.045149266719818115\n",
            "36000: 0.04882865399122238\n",
            "36000: 0.041005004197359085\n",
            "Mean of last 36000: 0.04372914531058841\n",
            "36100: 0.04579832777380943\n",
            "36100: 0.042222630232572556\n",
            "36200: 0.04230664670467377\n",
            "36200: 0.04438266158103943\n",
            "36300: 0.06060716509819031\n",
            "36300: 0.047384947538375854\n",
            "36400: 0.046168796718120575\n",
            "36400: 0.03791988641023636\n",
            "36500: 0.03916650265455246\n",
            "36500: 0.04456223547458649\n",
            "36600: 0.039115890860557556\n",
            "36600: 0.05060657113790512\n",
            "36700: 0.04083636403083801\n",
            "36700: 0.044136326760053635\n",
            "36800: 0.04709811508655548\n",
            "36800: 0.03669238090515137\n",
            "36900: 0.054802507162094116\n",
            "36900: 0.041034355759620667\n",
            "37000: 0.04205166921019554\n",
            "37000: 0.039699405431747437\n",
            "Mean of last 37000: 0.04375438114161139\n",
            "37100: 0.03804803639650345\n",
            "37100: 0.04284548759460449\n",
            "37200: 0.045212410390377045\n",
            "37200: 0.048785239458084106\n",
            "37300: 0.042674094438552856\n",
            "37300: 0.04180629178881645\n",
            "37400: 0.036556556820869446\n",
            "37400: 0.04399171471595764\n",
            "37500: 0.04510524123907089\n",
            "37500: 0.04317884147167206\n",
            "37600: 0.054536473006010056\n",
            "37600: 0.044823646545410156\n",
            "37700: 0.04209741950035095\n",
            "37700: 0.04779750108718872\n",
            "37800: 0.04653250426054001\n",
            "37800: 0.045583706349134445\n",
            "37900: 0.038027554750442505\n",
            "37900: 0.04080987721681595\n",
            "38000: 0.04108082503080368\n",
            "38000: 0.03982962667942047\n",
            "Mean of last 38000: 0.04358192298237558\n",
            "38100: 0.050624679774045944\n",
            "38100: 0.04794221371412277\n",
            "38200: 0.040478333830833435\n",
            "38200: 0.034827739000320435\n",
            "38300: 0.04071982949972153\n",
            "38300: 0.046555787324905396\n",
            "38400: 0.04556041210889816\n",
            "38400: 0.04522141069173813\n",
            "38500: 0.03725552186369896\n",
            "38500: 0.04083320498466492\n",
            "38600: 0.05082608014345169\n",
            "38600: 0.03767740726470947\n",
            "38700: 0.03797968477010727\n",
            "38700: 0.04543163627386093\n",
            "38800: 0.042966704815626144\n",
            "38800: 0.04663225635886192\n",
            "38900: 0.04082421585917473\n",
            "38900: 0.04255213961005211\n",
            "39000: 0.04133615642786026\n",
            "39000: 0.042532145977020264\n",
            "Mean of last 39000: 0.043475866507549026\n",
            "39100: 0.039482053369283676\n",
            "39100: 0.0439533069729805\n",
            "39200: 0.03940589353442192\n",
            "39200: 0.04234977066516876\n",
            "39300: 0.038896288722753525\n",
            "39300: 0.04125046357512474\n",
            "39400: 0.03933924809098244\n",
            "39400: 0.03851602226495743\n",
            "39500: 0.04082952067255974\n",
            "39500: 0.049153026193380356\n",
            "39600: 0.040383562445640564\n",
            "39600: 0.049285512417554855\n",
            "39700: 0.045400165021419525\n",
            "39700: 0.0408509336411953\n",
            "39800: 0.037932153791189194\n",
            "39800: 0.04639089107513428\n",
            "39900: 0.03456369414925575\n",
            "39900: 0.045732058584690094\n",
            "40000: 0.03920827805995941\n",
            "40000: 0.04524261876940727\n",
            "Mean of last 40000: 0.04338206589542009\n",
            "40100: 0.04546908661723137\n",
            "40100: 0.041120320558547974\n",
            "40200: 0.04105662554502487\n",
            "40200: 0.03623610734939575\n",
            "40300: 0.03718702495098114\n",
            "40300: 0.03780059888958931\n",
            "40400: 0.03796057030558586\n",
            "40400: 0.04218095541000366\n",
            "40500: 0.036792486906051636\n",
            "40500: 0.043682098388671875\n",
            "40600: 0.044897422194480896\n",
            "40600: 0.04476196691393852\n",
            "40700: 0.04684349521994591\n",
            "40700: 0.036648258566856384\n",
            "40800: 0.03830252215266228\n",
            "40800: 0.05536236613988876\n",
            "40900: 0.04089666157960892\n",
            "40900: 0.046875789761543274\n",
            "41000: 0.04104781523346901\n",
            "41000: 0.04873695224523544\n",
            "Mean of last 41000: 0.043539622061691444\n",
            "41100: 0.04751260206103325\n",
            "41100: 0.036563996225595474\n",
            "41200: 0.044490210711956024\n",
            "41200: 0.044175487011671066\n",
            "41300: 0.04547286033630371\n",
            "41300: 0.05061745643615723\n",
            "41400: 0.04669446870684624\n",
            "41400: 0.04561835527420044\n",
            "41500: 0.04996694251894951\n",
            "41500: 0.04374232888221741\n",
            "41600: 0.04283394664525986\n",
            "41600: 0.03983274847269058\n",
            "41700: 0.04014524072408676\n",
            "41700: 0.035653457045555115\n",
            "41800: 0.046052854508161545\n",
            "41800: 0.042595505714416504\n",
            "41900: 0.04493575543165207\n",
            "41900: 0.047800175845623016\n",
            "42000: 0.05333144590258598\n",
            "42000: 0.04660118743777275\n",
            "Mean of last 42000: 0.04343217748638752\n",
            "42100: 0.04845332354307175\n",
            "42100: 0.05125191807746887\n",
            "42200: 0.04189830273389816\n",
            "42200: 0.041487302631139755\n",
            "42300: 0.04758298397064209\n",
            "42300: 0.04533214867115021\n",
            "42400: 0.04340675473213196\n",
            "42400: 0.03809577226638794\n",
            "42500: 0.03807409852743149\n",
            "42500: 0.040138229727745056\n",
            "42600: 0.04176328703761101\n",
            "42600: 0.039423804730176926\n",
            "42700: 0.037184230983257294\n",
            "42700: 0.042939525097608566\n",
            "42800: 0.04572686553001404\n",
            "42800: 0.04117170348763466\n",
            "42900: 0.04249880835413933\n",
            "42900: 0.03922110050916672\n",
            "43000: 0.033542193472385406\n",
            "43000: 0.04382640868425369\n",
            "Mean of last 43000: 0.04314727954134777\n",
            "43100: 0.044984571635723114\n",
            "43100: 0.041120853275060654\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "43200: 0.048375602811574936\n",
            "43200: 0.04078299179673195\n",
            "43300: 0.03891393542289734\n",
            "43300: 0.04559410735964775\n",
            "43400: 0.03880658745765686\n",
            "43400: 0.04282661899924278\n",
            "43500: 0.039144158363342285\n",
            "43500: 0.03855293244123459\n",
            "43600: 0.04133503884077072\n",
            "43600: 0.03647581860423088\n",
            "43700: 0.039140261709690094\n",
            "43700: 0.036876194179058075\n",
            "43800: 0.03949260711669922\n",
            "43800: 0.04499339684844017\n",
            "43900: 0.04264819622039795\n",
            "43900: 0.05605338141322136\n",
            "44000: 0.051222063601017\n",
            "44000: 0.04623272269964218\n",
            "Mean of last 44000: 0.04322804361544587\n",
            "44100: 0.03743475675582886\n",
            "44100: 0.04219222068786621\n",
            "44200: 0.04319668561220169\n",
            "44200: 0.048497892916202545\n",
            "44300: 0.046653877943754196\n",
            "44300: 0.04439524561166763\n",
            "44400: 0.04401528090238571\n",
            "44400: 0.04435097426176071\n",
            "44500: 0.05134763941168785\n",
            "44500: 0.04746728390455246\n",
            "44600: 0.04301762580871582\n",
            "44600: 0.04310932382941246\n",
            "44700: 0.043589260429143906\n",
            "44700: 0.043167583644390106\n",
            "44800: 0.05542754754424095\n",
            "44800: 0.040143925696611404\n",
            "44900: 0.046076737344264984\n",
            "44900: 0.0458415225148201\n",
            "45000: 0.04157392308115959\n",
            "45000: 0.041617557406425476\n",
            "Mean of last 45000: 0.04312971897132985\n",
            "45100: 0.04671701043844223\n",
            "45100: 0.04207727313041687\n",
            "45200: 0.042753107845783234\n",
            "45200: 0.046062689274549484\n",
            "45300: 0.03506037965416908\n",
            "45300: 0.04111675173044205\n",
            "45400: 0.04243496060371399\n",
            "45400: 0.0448220819234848\n",
            "45500: 0.04294630140066147\n",
            "45500: 0.03840208053588867\n",
            "45600: 0.05044001340866089\n",
            "45600: 0.04450657591223717\n",
            "45700: 0.047168485820293427\n",
            "45700: 0.04364551603794098\n",
            "45800: 0.04282621666789055\n",
            "45800: 0.04073205217719078\n",
            "45900: 0.03636125847697258\n",
            "45900: 0.04197691008448601\n",
            "46000: 0.04130607470870018\n",
            "46000: 0.04026199132204056\n",
            "Mean of last 46000: 0.043117749675006777\n",
            "46100: 0.039701372385025024\n",
            "46100: 0.04756588861346245\n",
            "46200: 0.04125116765499115\n",
            "46200: 0.04227640479803085\n",
            "46300: 0.048311516642570496\n",
            "46300: 0.041287291795015335\n",
            "46400: 0.037309128791093826\n",
            "46400: 0.04128256067633629\n",
            "46500: 0.04453288018703461\n",
            "46500: 0.03848462551832199\n",
            "46600: 0.039058834314346313\n",
            "46600: 0.04273456335067749\n",
            "46700: 0.039903994649648666\n",
            "46700: 0.039319831877946854\n",
            "46800: 0.0395384207367897\n",
            "46800: 0.04433804750442505\n",
            "46900: 0.054454248398542404\n",
            "46900: 0.04117391258478165\n",
            "47000: 0.0456710159778595\n",
            "47000: 0.0538557767868042\n",
            "Mean of last 47000: 0.04306137595292214\n",
            "47100: 0.04051680117845535\n",
            "47100: 0.04059575870633125\n",
            "47200: 0.04297412559390068\n",
            "47200: 0.044048309326171875\n",
            "47300: 0.03784424066543579\n",
            "47300: 0.03853309899568558\n",
            "47400: 0.03909968584775925\n",
            "47400: 0.052978575229644775\n",
            "47500: 0.039573341608047485\n",
            "47500: 0.039350129663944244\n",
            "47600: 0.04100257158279419\n",
            "47600: 0.03717687726020813\n",
            "47700: 0.04495909810066223\n",
            "47700: 0.04006356745958328\n",
            "47800: 0.042917631566524506\n",
            "47800: 0.05061271786689758\n",
            "47900: 0.04848433658480644\n",
            "47900: 0.04053416848182678\n",
            "48000: 0.04664139449596405\n",
            "48000: 0.03756874054670334\n",
            "Mean of last 48000: 0.04311316304809445\n",
            "48100: 0.04084949940443039\n",
            "48100: 0.03972003608942032\n",
            "48200: 0.04051949828863144\n",
            "48200: 0.04741228371858597\n",
            "48300: 0.04128973186016083\n",
            "48300: 0.04071586951613426\n",
            "48400: 0.0620296411216259\n",
            "48400: 0.0557720884680748\n",
            "48500: 0.054171837866306305\n",
            "48500: 0.04621770977973938\n",
            "48600: 0.04703449457883835\n",
            "48600: 0.041346512734889984\n",
            "48700: 0.04267754405736923\n",
            "48700: 0.04848933219909668\n",
            "48800: 0.03985550254583359\n",
            "48800: 0.050497204065322876\n",
            "48900: 0.03950614482164383\n",
            "48900: 0.04999598488211632\n",
            "49000: 0.0405026338994503\n",
            "49000: 0.04336315020918846\n",
            "Mean of last 49000: 0.043092915109106594\n",
            "49100: 0.05642099305987358\n",
            "49100: 0.042483411729335785\n",
            "49200: 0.04195155203342438\n",
            "49200: 0.04037168622016907\n",
            "49300: 0.03731125220656395\n",
            "49300: 0.04193795844912529\n",
            "49400: 0.038861922919750214\n",
            "49400: 0.040631022304296494\n",
            "49500: 0.04667378216981888\n",
            "49500: 0.04024682193994522\n",
            "49600: 0.03881511092185974\n",
            "49600: 0.04728873819112778\n",
            "49700: 0.03993358463048935\n",
            "49700: 0.036556463688611984\n",
            "49800: 0.04663752019405365\n",
            "49800: 0.044686209410429\n",
            "49900: 0.04209384322166443\n",
            "49900: 0.04233831167221069\n",
            "50000: 0.0495317280292511\n",
            "50000: 0.05603068321943283\n",
            "Mean of last 50000: 0.04286969293255013\n",
            "50100: 0.04327340051531792\n",
            "50100: 0.048662491142749786\n",
            "50200: 0.0476938895881176\n",
            "50200: 0.03844856470823288\n",
            "50300: 0.03815408796072006\n",
            "50300: 0.037869490683078766\n",
            "50400: 0.040737733244895935\n",
            "50400: 0.046339523047208786\n",
            "50500: 0.039973095059394836\n",
            "50500: 0.03984694927930832\n",
            "50600: 0.034199222922325134\n",
            "50600: 0.045760028064250946\n",
            "50700: 0.039283864200115204\n",
            "50700: 0.04588943347334862\n",
            "50800: 0.03840490058064461\n",
            "50800: 0.04256579279899597\n",
            "50900: 0.040347881615161896\n",
            "50900: 0.04226868972182274\n",
            "51000: 0.04856642335653305\n",
            "51000: 0.040828585624694824\n",
            "Mean of last 51000: 0.04281952734162043\n",
            "51100: 0.042749159038066864\n",
            "51100: 0.04785006493330002\n",
            "51200: 0.03602905943989754\n",
            "51200: 0.04040446877479553\n",
            "51300: 0.04058147594332695\n",
            "51300: 0.040854111313819885\n",
            "51400: 0.04395680874586105\n",
            "51400: 0.0360296294093132\n",
            "51500: 0.043525587767362595\n",
            "51500: 0.04036993905901909\n",
            "51600: 0.042988091707229614\n",
            "51600: 0.05545241758227348\n",
            "51700: 0.04551054537296295\n",
            "51700: 0.039587777107954025\n",
            "51800: 0.04697800800204277\n",
            "51800: 0.04223058745265007\n",
            "51900: 0.043409183621406555\n",
            "51900: 0.04516316577792168\n",
            "52000: 0.046739839017391205\n",
            "52000: 0.043484851717948914\n",
            "Mean of last 52000: 0.0430684095317429\n",
            "52100: 0.04143271967768669\n",
            "52100: 0.04723479598760605\n",
            "52200: 0.04436836391687393\n",
            "52200: 0.04217445105314255\n",
            "52300: 0.039301007986068726\n",
            "52300: 0.03751753270626068\n",
            "52400: 0.03970905765891075\n",
            "52400: 0.04216703772544861\n",
            "52500: 0.04471289739012718\n",
            "52500: 0.040694668889045715\n",
            "52600: 0.03463493287563324\n",
            "52600: 0.03868374973535538\n",
            "52700: 0.04274480789899826\n",
            "52700: 0.040454618632793427\n",
            "52800: 0.04008836671710014\n",
            "52800: 0.042936019599437714\n",
            "52900: 0.040974896401166916\n",
            "52900: 0.03915829956531525\n",
            "53000: 0.03657058626413345\n",
            "53000: 0.04361220449209213\n",
            "Mean of last 53000: 0.0426881590097041\n",
            "53100: 0.041069578379392624\n",
            "53100: 0.03923026844859123\n",
            "53200: 0.042236607521772385\n",
            "53200: 0.04797142744064331\n",
            "53300: 0.046021513640880585\n",
            "53300: 0.040355052798986435\n",
            "53400: 0.04615244269371033\n",
            "53400: 0.03802851587533951\n",
            "53500: 0.037456199526786804\n",
            "53500: 0.04157084971666336\n",
            "53600: 0.04513636231422424\n",
            "53600: 0.03542792797088623\n",
            "53700: 0.04284801706671715\n",
            "53700: 0.04890169948339462\n",
            "53800: 0.04528834670782089\n",
            "53800: 0.04047268256545067\n",
            "53900: 0.036254748702049255\n",
            "53900: 0.03836788609623909\n",
            "54000: 0.047587715089321136\n",
            "54000: 0.041698940098285675\n",
            "Mean of last 54000: 0.04250072107671739\n",
            "54100: 0.04243658483028412\n",
            "54100: 0.03919455409049988\n",
            "54200: 0.03701312094926834\n",
            "54200: 0.03623969852924347\n",
            "54300: 0.043389540165662766\n",
            "54300: 0.03857240080833435\n",
            "54400: 0.04177789390087128\n",
            "54400: 0.03905492275953293\n",
            "54500: 0.04002158343791962\n",
            "54500: 0.04370110481977463\n",
            "54600: 0.042752884328365326\n",
            "54600: 0.041215796023607254\n",
            "54700: 0.03648603707551956\n",
            "54700: 0.04533946514129639\n",
            "54800: 0.04630116745829582\n",
            "54800: 0.04216048866510391\n",
            "54900: 0.05347694084048271\n",
            "54900: 0.037846729159355164\n",
            "55000: 0.05423013120889664\n",
            "55000: 0.038582943379879\n",
            "Mean of last 55000: 0.04275688545203411\n",
            "55100: 0.04081925004720688\n",
            "55100: 0.04578104242682457\n",
            "55200: 0.04219309613108635\n",
            "55200: 0.040531985461711884\n",
            "55300: 0.047269947826862335\n",
            "55300: 0.05004855990409851\n",
            "55400: 0.04203981161117554\n",
            "55400: 0.04598846659064293\n",
            "55500: 0.03818703070282936\n",
            "55500: 0.04266945645213127\n",
            "55600: 0.04076635092496872\n",
            "55600: 0.04760138317942619\n",
            "55700: 0.03932806849479675\n",
            "55700: 0.04352729022502899\n",
            "55800: 0.040690526366233826\n",
            "55800: 0.04479358717799187\n",
            "55900: 0.04507776349782944\n",
            "55900: 0.051901787519454956\n",
            "56000: 0.045352812856435776\n",
            "56000: 0.03531574457883835\n",
            "Mean of last 56000: 0.04254985901040512\n",
            "56100: 0.042447399348020554\n",
            "56100: 0.04007802903652191\n",
            "56200: 0.04298800230026245\n",
            "56200: 0.04076804220676422\n",
            "56300: 0.03818212449550629\n",
            "56300: 0.04440910741686821\n",
            "56400: 0.049432069063186646\n",
            "56400: 0.039052244275808334\n",
            "56500: 0.03935781121253967\n",
            "56500: 0.04416938126087189\n",
            "56600: 0.041530318558216095\n",
            "56600: 0.056002579629421234\n",
            "56700: 0.04389534145593643\n",
            "56700: 0.04484479874372482\n",
            "56800: 0.03973683342337608\n",
            "56800: 0.04499461501836777\n",
            "56900: 0.050229236483573914\n",
            "56900: 0.038682784885168076\n",
            "57000: 0.03968556970357895\n",
            "57000: 0.038679711520671844\n",
            "Mean of last 57000: 0.04248474246555275\n",
            "57100: 0.04637351632118225\n",
            "57100: 0.04595954343676567\n",
            "57200: 0.037458647042512894\n",
            "57200: 0.03705698996782303\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "57300: 0.036548350006341934\n",
            "57300: 0.04327637702226639\n",
            "57400: 0.048130523413419724\n",
            "57400: 0.047706566751003265\n",
            "57500: 0.03916775807738304\n",
            "57500: 0.0502464734017849\n",
            "57600: 0.047367360442876816\n",
            "57600: 0.04050356149673462\n",
            "57700: 0.03922739252448082\n",
            "57700: 0.043508999049663544\n",
            "58100: 0.05173758789896965\n",
            "58100: 0.039007559418678284\n",
            "58200: 0.0402698740363121\n",
            "58200: 0.04493585228919983\n",
            "58300: 0.03909634053707123\n",
            "58300: 0.04257278889417648\n",
            "58400: 0.04305840656161308\n",
            "58400: 0.04503994807600975\n",
            "58500: 0.04477165266871452\n",
            "58500: 0.03887239098548889\n",
            "58600: 0.04351875185966492\n",
            "58600: 0.041660115122795105\n",
            "58700: 0.03865491971373558\n",
            "58700: 0.04249454662203789\n",
            "58800: 0.04291243106126785\n",
            "58800: 0.043771497905254364\n",
            "58900: 0.04173463582992554\n",
            "58900: 0.03862719237804413\n",
            "59000: 0.040892891585826874\n",
            "59000: 0.04160512238740921\n",
            "Mean of last 59000: 0.04232784289193082\n",
            "59100: 0.03914821147918701\n",
            "59100: 0.040736980736255646\n",
            "59200: 0.038565218448638916\n",
            "59200: 0.04168006032705307\n",
            "59300: 0.048246294260025024\n",
            "59300: 0.03752507269382477\n",
            "59400: 0.04124308004975319\n",
            "59400: 0.03504941612482071\n",
            "59500: 0.041425202041864395\n",
            "59500: 0.03459213301539421\n",
            "59600: 0.041119735687971115\n",
            "59600: 0.042302265763282776\n",
            "59700: 0.04291398450732231\n",
            "59700: 0.04840628430247307\n",
            "59800: 0.03828129172325134\n",
            "59800: 0.041201382875442505\n",
            "59900: 0.0399312824010849\n",
            "59900: 0.04544643685221672\n",
            "60000: 0.04078075289726257\n",
            "60000: 0.036714106798172\n",
            "Mean of last 60000: 0.042150049597828775\n",
            "60100: 0.03621133416891098\n",
            "60100: 0.03933458775281906\n",
            "60200: 0.04327184706926346\n",
            "60200: 0.041913703083992004\n",
            "60300: 0.047926269471645355\n",
            "60300: 0.03890562802553177\n",
            "60400: 0.04267323017120361\n",
            "60400: 0.038547415286302567\n",
            "60500: 0.043394770473241806\n",
            "60500: 0.04482473060488701\n",
            "60600: 0.04516454041004181\n",
            "60600: 0.04874011129140854\n",
            "60700: 0.04403117299079895\n",
            "60700: 0.04705817624926567\n",
            "60800: 0.03796262666583061\n",
            "60800: 0.046182386577129364\n",
            "60900: 0.04154115542769432\n",
            "60900: 0.040070101618766785\n",
            "61000: 0.03855482488870621\n",
            "61000: 0.055438440293073654\n",
            "Mean of last 61000: 0.04223807049463024\n",
            "61100: 0.04054652526974678\n",
            "61100: 0.04675929993391037\n",
            "61200: 0.045224107801914215\n",
            "61200: 0.041573911905288696\n",
            "61300: 0.041823238134384155\n",
            "61300: 0.040535591542720795\n",
            "61400: 0.04329254478216171\n",
            "61400: 0.044122129678726196\n",
            "61500: 0.04302043467760086\n",
            "61500: 0.043661199510097504\n",
            "61600: 0.04038626700639725\n",
            "61600: 0.04107429459691048\n",
            "61700: 0.04863440617918968\n",
            "61700: 0.03708324953913689\n",
            "61800: 0.041611433029174805\n",
            "61800: 0.035355523228645325\n",
            "61900: 0.0411820113658905\n",
            "61900: 0.047471385449171066\n",
            "62000: 0.051851071417331696\n",
            "62000: 0.04410536587238312\n",
            "Mean of last 62000: 0.04224999077975393\n",
            "62100: 0.04267143830657005\n",
            "62100: 0.04548165202140808\n",
            "62200: 0.0348639152944088\n",
            "62200: 0.045151080936193466\n",
            "62300: 0.05163110792636871\n",
            "62300: 0.05999094247817993\n",
            "62400: 0.04294833540916443\n",
            "62400: 0.047460220754146576\n",
            "62500: 0.03548143059015274\n",
            "62500: 0.036160409450531006\n",
            "62600: 0.03973414748907089\n",
            "62600: 0.040293604135513306\n",
            "62700: 0.04461740702390671\n",
            "62700: 0.035865575075149536\n",
            "62800: 0.047361694276332855\n",
            "62800: 0.04059198126196861\n",
            "62900: 0.04060764238238335\n",
            "62900: 0.04082319885492325\n",
            "63000: 0.036561768501996994\n",
            "63000: 0.043379247188568115\n",
            "Mean of last 63000: 0.04206290543935337\n",
            "63100: 0.04493090510368347\n",
            "63100: 0.04622446000576019\n",
            "63200: 0.04022744297981262\n",
            "63200: 0.03935810551047325\n",
            "63300: 0.040949128568172455\n",
            "63300: 0.04458140581846237\n",
            "63400: 0.040311869233846664\n",
            "63400: 0.05124744027853012\n",
            "63500: 0.0429215282201767\n",
            "63500: 0.04580856114625931\n",
            "63600: 0.044074177742004395\n",
            "63600: 0.042178429663181305\n",
            "63700: 0.041528262197971344\n",
            "63700: 0.04003627598285675\n",
            "63800: 0.03851798176765442\n",
            "63800: 0.04776845499873161\n",
            "63900: 0.040561504662036896\n",
            "63900: 0.0398067831993103\n",
            "64000: 0.04172798618674278\n",
            "64000: 0.043473951518535614\n",
            "Mean of last 64000: 0.04222100211882389\n",
            "64100: 0.041373372077941895\n",
            "64100: 0.0453401654958725\n",
            "64200: 0.0394161120057106\n",
            "64200: 0.03985278308391571\n",
            "64300: 0.03870231658220291\n",
            "64300: 0.04755747318267822\n",
            "64400: 0.05992795526981354\n",
            "64400: 0.04806050658226013\n",
            "64500: 0.04221639782190323\n",
            "64500: 0.038146376609802246\n",
            "64600: 0.0429542176425457\n",
            "64600: 0.037789009511470795\n",
            "64700: 0.04622980207204819\n",
            "64700: 0.04297902435064316\n",
            "64800: 0.036607712507247925\n",
            "64800: 0.03929387778043747\n",
            "64900: 0.03578329086303711\n",
            "64900: 0.04038272798061371\n",
            "65000: 0.046262942254543304\n",
            "65000: 0.04000958055257797\n",
            "Mean of last 65000: 0.04217274927466244\n",
            "65100: 0.03721629083156586\n",
            "65100: 0.047987110912799835\n",
            "65200: 0.04587039351463318\n",
            "65200: 0.047950416803359985\n",
            "65300: 0.0361630842089653\n",
            "65300: 0.039701223373413086\n",
            "65400: 0.04096074774861336\n",
            "65400: 0.03928172588348389\n",
            "65500: 0.04239354655146599\n",
            "65500: 0.045014142990112305\n",
            "65600: 0.03776226565241814\n",
            "65600: 0.03943305462598801\n",
            "65700: 0.0398678332567215\n",
            "65700: 0.05000552162528038\n",
            "65800: 0.03693000227212906\n",
            "65800: 0.03669250011444092\n",
            "65900: 0.042679768055677414\n",
            "65900: 0.04575139284133911\n",
            "66000: 0.047856077551841736\n",
            "66000: 0.034519013017416\n",
            "Mean of last 66000: 0.04218685962110907\n",
            "66100: 0.04227995499968529\n",
            "66100: 0.05029585212469101\n",
            "66200: 0.04105009883642197\n",
            "66200: 0.04122290760278702\n",
            "66300: 0.04205232113599777\n",
            "66300: 0.04131133854389191\n",
            "66400: 0.038381367921829224\n",
            "66400: 0.03561371564865112\n",
            "66500: 0.046097755432128906\n",
            "66500: 0.05020618438720703\n",
            "66600: 0.041748933494091034\n",
            "66600: 0.05346016213297844\n",
            "66700: 0.03744160756468773\n",
            "66700: 0.03791608661413193\n",
            "66800: 0.0412919707596302\n",
            "66800: 0.04003973305225372\n",
            "66900: 0.03712746500968933\n",
            "66900: 0.037936918437480927\n",
            "67000: 0.04398370906710625\n",
            "67000: 0.04517541080713272\n",
            "Mean of last 67000: 0.041949761236881045\n",
            "67100: 0.045269787311553955\n",
            "67100: 0.04132687300443649\n",
            "67200: 0.0457373708486557\n",
            "67200: 0.04388970136642456\n",
            "67300: 0.036165785044431686\n",
            "67300: 0.03693976253271103\n",
            "67400: 0.03691492974758148\n",
            "67400: 0.04308488219976425\n",
            "67500: 0.04302743077278137\n",
            "67500: 0.039961036294698715\n",
            "67600: 0.043907251209020615\n",
            "67600: 0.03863689675927162\n",
            "67700: 0.039026159793138504\n",
            "67700: 0.04087460786104202\n",
            "67800: 0.03816855698823929\n",
            "67800: 0.044144224375486374\n",
            "67900: 0.035143207758665085\n",
            "67900: 0.04507991299033165\n",
            "68000: 0.039115093648433685\n",
            "68000: 0.04036566615104675\n",
            "Mean of last 68000: 0.04191302772347148\n",
            "68100: 0.04346144199371338\n",
            "68100: 0.0438159815967083\n",
            "68200: 0.043007127940654755\n",
            "68200: 0.04245623201131821\n",
            "68300: 0.04543878138065338\n",
            "68300: 0.03544379398226738\n",
            "68400: 0.04400557279586792\n",
            "68400: 0.04046670347452164\n",
            "68500: 0.047703664749860764\n",
            "68500: 0.040990523993968964\n",
            "68600: 0.04029560834169388\n",
            "68600: 0.0447312593460083\n",
            "68700: 0.03836611285805702\n",
            "68700: 0.04248049110174179\n",
            "68800: 0.04893174767494202\n",
            "68800: 0.04885765165090561\n",
            "68900: 0.03842552751302719\n",
            "68900: 0.037541694939136505\n",
            "69000: 0.03898206725716591\n",
            "69000: 0.04626374691724777\n",
            "Mean of last 69000: 0.041890125340232245\n",
            "69100: 0.03812076896429062\n",
            "69100: 0.03853745386004448\n",
            "69200: 0.0397992841899395\n",
            "69200: 0.050581224262714386\n",
            "69300: 0.04083871841430664\n",
            "69300: 0.040422238409519196\n",
            "69400: 0.03534520044922829\n",
            "69400: 0.041561491787433624\n",
            "69500: 0.036664821207523346\n",
            "69500: 0.04104769974946976\n",
            "69600: 0.041047707200050354\n",
            "69600: 0.045366473495960236\n",
            "69700: 0.04698625206947327\n",
            "69700: 0.04542851448059082\n",
            "69800: 0.04653159901499748\n",
            "69800: 0.03782712295651436\n",
            "69900: 0.04118248075246811\n",
            "69900: 0.04147296026349068\n",
            "70000: 0.04122793301939964\n",
            "70000: 0.04121766984462738\n",
            "Mean of last 70000: 0.04197815733661244\n",
            "70100: 0.045001935213804245\n",
            "70100: 0.04842541366815567\n",
            "70200: 0.03894733637571335\n",
            "70200: 0.0408841073513031\n",
            "70300: 0.039487291127443314\n",
            "70300: 0.04232420772314072\n",
            "70400: 0.04009444639086723\n",
            "70400: 0.046560198068618774\n",
            "70500: 0.03745508939027786\n",
            "70500: 0.040196843445301056\n",
            "70600: 0.04589112848043442\n",
            "70600: 0.04408062621951103\n",
            "70700: 0.04803603142499924\n",
            "70700: 0.037230685353279114\n",
            "70800: 0.047695353627204895\n",
            "70800: 0.04354257881641388\n",
            "70900: 0.04356120154261589\n",
            "70900: 0.0406152680516243\n",
            "71000: 0.04149556905031204\n",
            "71000: 0.04436109960079193\n",
            "Mean of last 71000: 0.04190840676880919\n",
            "71100: 0.04200373589992523\n",
            "71100: 0.04265935346484184\n",
            "71200: 0.044395625591278076\n",
            "71200: 0.04604722186923027\n",
            "71300: 0.03923393040895462\n",
            "71300: 0.038532789796590805\n",
            "71400: 0.03411127254366875\n",
            "71400: 0.037483133375644684\n",
            "71500: 0.03962138295173645\n",
            "71500: 0.04256248474121094\n",
            "71600: 0.04119192436337471\n",
            "71600: 0.03663364052772522\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71700: 0.03998732939362526\n",
            "71700: 0.05640733242034912\n",
            "71800: 0.04493117332458496\n",
            "71800: 0.04642355442047119\n",
            "71900: 0.044130027294158936\n",
            "71900: 0.03934445232152939\n",
            "72000: 0.04522664099931717\n",
            "72000: 0.034887876361608505\n",
            "Mean of last 72000: 0.041894849159054226\n",
            "72100: 0.03615324944257736\n",
            "72100: 0.04079451784491539\n",
            "72200: 0.0483122281730175\n",
            "72200: 0.058027759194374084\n",
            "72300: 0.04136694222688675\n",
            "72300: 0.035613905638456345\n",
            "72400: 0.03817145526409149\n",
            "72400: 0.03691723942756653\n",
            "72500: 0.03999300301074982\n",
            "72500: 0.04361904785037041\n",
            "72600: 0.04346136748790741\n",
            "72600: 0.04288853704929352\n",
            "72700: 0.04171181842684746\n",
            "72700: 0.048093073070049286\n",
            "72800: 0.038578882813453674\n",
            "72800: 0.048310648649930954\n",
            "72900: 0.03906113654375076\n",
            "72900: 0.04264020547270775\n",
            "73000: 0.03784326836466789\n",
            "73000: 0.04161208122968674\n",
            "Mean of last 73000: 0.04191347465782494\n",
            "73100: 0.04872047156095505\n",
            "73100: 0.04935401678085327\n",
            "73200: 0.037520281970500946\n",
            "73200: 0.041390709578990936\n",
            "73300: 0.05042598396539688\n",
            "73300: 0.03598737716674805\n",
            "73400: 0.050655778497457504\n",
            "73400: 0.047944359481334686\n",
            "73500: 0.040369682013988495\n",
            "73500: 0.04175123572349548\n",
            "73600: 0.038353294134140015\n",
            "73600: 0.04898166283965111\n",
            "73700: 0.0405365526676178\n",
            "73700: 0.03622520714998245\n",
            "73800: 0.0400729663670063\n",
            "73800: 0.04625667631626129\n",
            "73900: 0.039779745042324066\n",
            "73900: 0.03691898658871651\n",
            "74000: 0.04280230402946472\n",
            "74000: 0.0439349040389061\n",
            "Mean of last 74000: 0.041646909279438045\n",
            "74100: 0.04125825688242912\n",
            "74100: 0.038298387080430984\n",
            "74200: 0.03998779505491257\n",
            "74200: 0.04413416236639023\n",
            "74300: 0.04301512986421585\n",
            "74300: 0.04159338027238846\n",
            "74400: 0.044455356895923615\n",
            "74400: 0.03279073163866997\n",
            "74500: 0.041312091052532196\n",
            "74500: 0.03792477026581764\n",
            "74600: 0.035521939396858215\n",
            "74600: 0.04202473163604736\n",
            "74700: 0.047899942845106125\n",
            "74700: 0.0441279336810112\n",
            "74800: 0.042012881487607956\n",
            "74800: 0.04076163470745087\n",
            "74900: 0.038413021713495255\n",
            "74900: 0.039866432547569275\n",
            "75000: 0.03676910325884819\n",
            "75000: 0.047049593180418015\n",
            "Mean of last 75000: 0.042045428137574996\n",
            "75100: 0.03965971618890762\n",
            "75100: 0.0453665517270565\n",
            "75200: 0.04370689019560814\n",
            "75200: 0.04172854870557785\n",
            "75300: 0.04846857488155365\n",
            "75300: 0.046965353190898895\n",
            "75400: 0.042108118534088135\n",
            "75400: 0.05762828141450882\n",
            "75500: 0.04862368106842041\n",
            "75500: 0.04224210977554321\n",
            "75600: 0.046217095106840134\n",
            "75600: 0.04356304928660393\n",
            "75700: 0.047766368836164474\n",
            "75700: 0.04099445790052414\n",
            "75800: 0.0547548346221447\n",
            "75800: 0.03586825728416443\n",
            "75900: 0.03901907429099083\n",
            "75900: 0.03909990191459656\n",
            "76000: 0.039351433515548706\n",
            "76000: 0.04326590895652771\n",
            "Mean of last 76000: 0.04203947534883296\n",
            "76100: 0.04245535656809807\n",
            "76100: 0.03929287940263748\n",
            "76200: 0.04437108337879181\n",
            "76200: 0.04166360944509506\n",
            "76300: 0.041380979120731354\n",
            "76300: 0.04206260293722153\n",
            "76400: 0.04140627011656761\n",
            "76400: 0.044990092515945435\n",
            "76500: 0.04246736690402031\n",
            "76500: 0.0379343181848526\n",
            "76600: 0.046218328177928925\n",
            "76600: 0.03756170719861984\n",
            "76700: 0.03485795482993126\n",
            "76700: 0.050858478993177414\n",
            "76800: 0.048788882791996\n",
            "76800: 0.04607610031962395\n",
            "76900: 0.04124445468187332\n",
            "76900: 0.0423814058303833\n",
            "77000: 0.03984849154949188\n",
            "77000: 0.0425436794757843\n",
            "Mean of last 77000: 0.041784194109218936\n",
            "77100: 0.03755117207765579\n",
            "77100: 0.04060765728354454\n",
            "77200: 0.04291334003210068\n",
            "77200: 0.04071599245071411\n",
            "77300: 0.044335078448057175\n",
            "77300: 0.04349302500486374\n",
            "77400: 0.042762964963912964\n",
            "77400: 0.04279044270515442\n",
            "77500: 0.04361296445131302\n",
            "77500: 0.05036316439509392\n",
            "77600: 0.03582921251654625\n",
            "77600: 0.04193459451198578\n",
            "77700: 0.04055970907211304\n",
            "77700: 0.052194178104400635\n",
            "77800: 0.04755547270178795\n",
            "77800: 0.04739835485816002\n",
            "77900: 0.042442113161087036\n",
            "77900: 0.03680506348609924\n",
            "78000: 0.04649655148386955\n",
            "78000: 0.04537088796496391\n",
            "Mean of last 78000: 0.04176878761295434\n",
            "78100: 0.041692040860652924\n",
            "78100: 0.03859315067529678\n",
            "78200: 0.04221638664603233\n",
            "78200: 0.04469258710741997\n",
            "78300: 0.03784932196140289\n",
            "78300: 0.03781920298933983\n",
            "78400: 0.036505311727523804\n",
            "78400: 0.03667162358760834\n",
            "78500: 0.033162858337163925\n",
            "78500: 0.0343405120074749\n",
            "78600: 0.041522569954395294\n",
            "78600: 0.048774369060993195\n",
            "78700: 0.04871084913611412\n",
            "78700: 0.038367047905921936\n",
            "78800: 0.04242422804236412\n",
            "78800: 0.04372408986091614\n",
            "78900: 0.04559434577822685\n",
            "78900: 0.038876913487911224\n",
            "79000: 0.03819306194782257\n",
            "79000: 0.046718087047338486\n",
            "Mean of last 79000: 0.04169422543359237\n",
            "79100: 0.046649020165205\n",
            "79100: 0.03783746063709259\n",
            "79200: 0.05031690001487732\n",
            "79200: 0.041460175067186356\n",
            "79300: 0.03860575333237648\n",
            "79300: 0.03895334526896477\n",
            "79400: 0.04499334841966629\n",
            "79400: 0.05277156084775925\n",
            "79500: 0.04774285480380058\n",
            "79500: 0.03760664910078049\n",
            "79600: 0.036510907113552094\n",
            "79600: 0.05222119018435478\n",
            "79700: 0.03799618035554886\n",
            "79700: 0.03793974965810776\n",
            "79800: 0.046219564974308014\n",
            "79800: 0.04975332319736481\n",
            "79900: 0.036581363528966904\n",
            "79900: 0.04309725761413574\n",
            "80000: 0.046597670763731\n",
            "80000: 0.050591468811035156\n",
            "Mean of last 80000: 0.04158482719938476\n",
            "80100: 0.05695899575948715\n",
            "80100: 0.03879700228571892\n",
            "80200: 0.04016590490937233\n",
            "80200: 0.04059043154120445\n",
            "80300: 0.037339720875024796\n",
            "80300: 0.04615970700979233\n",
            "80400: 0.04872358962893486\n",
            "80400: 0.04070424661040306\n",
            "80500: 0.044864214956760406\n",
            "80500: 0.03659715875983238\n",
            "80600: 0.03578954562544823\n",
            "80600: 0.03811264783143997\n",
            "80700: 0.047536127269268036\n",
            "80700: 0.04555017873644829\n",
            "80800: 0.037393730133771896\n",
            "80800: 0.04358555004000664\n",
            "80900: 0.039694644510746\n",
            "80900: 0.03773429989814758\n",
            "81000: 0.03983708471059799\n",
            "81000: 0.04082212597131729\n",
            "Mean of last 81000: 0.04153625775206756\n",
            "81100: 0.05150752514600754\n",
            "81100: 0.04186665266752243\n",
            "81200: 0.042382292449474335\n",
            "81200: 0.04336918890476227\n",
            "81300: 0.03753642365336418\n",
            "81300: 0.03712133690714836\n",
            "81400: 0.04001593217253685\n",
            "81400: 0.04473895579576492\n",
            "81500: 0.04302000254392624\n",
            "81500: 0.037783749401569366\n",
            "81600: 0.03926412761211395\n",
            "81600: 0.03880726546049118\n",
            "81700: 0.04249759018421173\n",
            "81700: 0.043475471436977386\n",
            "81800: 0.04345818608999252\n",
            "81800: 0.04105842113494873\n",
            "81900: 0.039896003901958466\n",
            "81900: 0.03662030026316643\n",
            "82000: 0.04500056430697441\n",
            "82000: 0.03822410851716995\n",
            "Mean of last 82000: 0.04148986306484346\n",
            "82100: 0.03650800511240959\n",
            "82100: 0.03766436129808426\n",
            "82200: 0.04099491238594055\n",
            "82200: 0.038815706968307495\n",
            "82300: 0.047423481941223145\n",
            "82300: 0.038892507553100586\n",
            "82400: 0.035495463758707047\n",
            "82400: 0.040288522839546204\n",
            "82500: 0.036653660237789154\n",
            "82500: 0.038123637437820435\n",
            "82600: 0.041269611567258835\n",
            "82600: 0.03997332602739334\n",
            "82700: 0.0454990491271019\n",
            "82700: 0.04515355825424194\n",
            "82800: 0.038046419620513916\n",
            "82800: 0.033357199281454086\n",
            "82900: 0.048874303698539734\n",
            "82900: 0.04439663141965866\n",
            "83000: 0.03764123469591141\n",
            "83000: 0.03958019241690636\n",
            "Mean of last 83000: 0.04151248511533578\n",
            "83100: 0.043343838304281235\n",
            "83100: 0.04113750159740448\n",
            "83200: 0.03695577755570412\n",
            "83200: 0.04160498082637787\n",
            "83300: 0.047179706394672394\n",
            "83300: 0.04250548034906387\n",
            "83400: 0.03431949019432068\n",
            "83400: 0.037575431168079376\n",
            "83500: 0.04011286422610283\n",
            "83500: 0.044307779520750046\n",
            "83600: 0.041688453406095505\n",
            "83600: 0.040802016854286194\n",
            "83700: 0.03977029025554657\n",
            "83700: 0.03973723202943802\n",
            "83800: 0.04051534831523895\n",
            "83800: 0.03844650462269783\n",
            "83900: 0.04089277610182762\n",
            "83900: 0.04806452989578247\n",
            "84000: 0.040373653173446655\n",
            "84000: 0.04544976353645325\n",
            "Mean of last 84000: 0.041431512118881936\n",
            "84100: 0.03764081746339798\n",
            "84100: 0.04043065756559372\n",
            "84200: 0.04111484810709953\n",
            "84200: 0.038014017045497894\n",
            "84300: 0.03751327842473984\n",
            "84300: 0.04175654053688049\n",
            "84400: 0.039601538330316544\n",
            "84400: 0.04278259724378586\n",
            "84500: 0.03869456425309181\n",
            "84500: 0.039103563874959946\n",
            "84600: 0.045585643500089645\n",
            "84600: 0.04405061900615692\n",
            "84700: 0.042938828468322754\n",
            "84700: 0.04518501088023186\n",
            "84800: 0.05174417793750763\n",
            "84800: 0.045768044888973236\n",
            "84900: 0.04137386009097099\n",
            "84900: 0.03851957619190216\n",
            "85000: 0.03903675824403763\n",
            "85000: 0.04142320156097412\n",
            "Mean of last 85000: 0.04155657093387682\n",
            "85100: 0.035904280841350555\n",
            "85100: 0.04197707399725914\n",
            "85200: 0.044900279492139816\n",
            "85200: 0.03869776055216789\n",
            "85300: 0.04007329046726227\n",
            "85300: 0.049694426357746124\n",
            "85400: 0.04331289976835251\n",
            "85400: 0.042027175426483154\n",
            "85500: 0.041999347507953644\n",
            "85500: 0.04189646244049072\n",
            "85600: 0.045829594135284424\n",
            "85600: 0.03576924651861191\n",
            "85700: 0.035861752927303314\n",
            "85700: 0.036621566861867905\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "85800: 0.03326431289315224\n",
            "85800: 0.04512758180499077\n",
            "85900: 0.034437745809555054\n",
            "85900: 0.04355596750974655\n",
            "86000: 0.03724216669797897\n",
            "86000: 0.04579445719718933\n",
            "Mean of last 86000: 0.041554419821561814\n",
            "86100: 0.0388522706925869\n",
            "86100: 0.0407099723815918\n",
            "86200: 0.03784947842359543\n",
            "86200: 0.05796688795089722\n",
            "86300: 0.0362306609749794\n",
            "86300: 0.04025007039308548\n",
            "86400: 0.04108315706253052\n",
            "86400: 0.035265617072582245\n",
            "86500: 0.04416891932487488\n",
            "86500: 0.034894831478595734\n",
            "86600: 0.039418209344148636\n",
            "86600: 0.04877134785056114\n",
            "86700: 0.049496255815029144\n",
            "86700: 0.0418495237827301\n",
            "86800: 0.04081186652183533\n",
            "86800: 0.035793669521808624\n",
            "86900: 0.04969065636396408\n",
            "86900: 0.044868528842926025\n",
            "87000: 0.040691077709198\n",
            "87000: 0.04545207321643829\n",
            "Mean of last 87000: 0.04155821562628378\n",
            "87100: 0.04081927239894867\n",
            "87100: 0.04278729483485222\n",
            "87200: 0.03816024214029312\n",
            "87200: 0.042331263422966\n",
            "87300: 0.04338386282324791\n",
            "87300: 0.05105944722890854\n",
            "87400: 0.033949099481105804\n",
            "87400: 0.04171554371714592\n",
            "87500: 0.0376395657658577\n",
            "87500: 0.045303504914045334\n",
            "87600: 0.05211485177278519\n",
            "87600: 0.041913941502571106\n",
            "87700: 0.03965088725090027\n",
            "87700: 0.03812924027442932\n",
            "87800: 0.047941893339157104\n",
            "87800: 0.049041297286748886\n",
            "87900: 0.04226981848478317\n",
            "87900: 0.04359002038836479\n",
            "88000: 0.04307549446821213\n",
            "88000: 0.044649116694927216\n",
            "Mean of last 88000: 0.04136649764084316\n",
            "88100: 0.041589509695768356\n",
            "88100: 0.03767500817775726\n",
            "88200: 0.03891550749540329\n",
            "88200: 0.04652643948793411\n",
            "88300: 0.04210960865020752\n",
            "88300: 0.04121864587068558\n",
            "88400: 0.034476395696401596\n",
            "88400: 0.03790063410997391\n",
            "88500: 0.03760170191526413\n",
            "88500: 0.0396769642829895\n",
            "88600: 0.0474291667342186\n",
            "88600: 0.039133813232183456\n",
            "88700: 0.04329507797956467\n",
            "88700: 0.041041597723960876\n",
            "88800: 0.04150015860795975\n",
            "88800: 0.038473498076200485\n",
            "88900: 0.04325105994939804\n",
            "88900: 0.04564140364527702\n",
            "89000: 0.039466436952352524\n",
            "89000: 0.03724249452352524\n",
            "Mean of last 89000: 0.04132057306962413\n",
            "89100: 0.041921667754650116\n",
            "89100: 0.04150427132844925\n",
            "89200: 0.03468259423971176\n",
            "89200: 0.049346186220645905\n",
            "89300: 0.04811215028166771\n",
            "89300: 0.04202339053153992\n",
            "89400: 0.033934082835912704\n",
            "89400: 0.03908173367381096\n",
            "89500: 0.04030190035700798\n",
            "89500: 0.03928602486848831\n",
            "89600: 0.04322337731719017\n",
            "89600: 0.03719521686434746\n",
            "89700: 0.0474836491048336\n",
            "89700: 0.04134342819452286\n",
            "89800: 0.0433516651391983\n",
            "89800: 0.03967845439910889\n",
            "89900: 0.03922617435455322\n",
            "89900: 0.03891916573047638\n",
            "90000: 0.0365755520761013\n",
            "90000: 0.04558493196964264\n",
            "Mean of last 90000: 0.04127843466240328\n",
            "90100: 0.04005153104662895\n",
            "90100: 0.042587973177433014\n",
            "90200: 0.036764614284038544\n",
            "90200: 0.04346150904893875\n",
            "90300: 0.04122965410351753\n",
            "90300: 0.04775289446115494\n",
            "90400: 0.0381314754486084\n",
            "90400: 0.039003655314445496\n",
            "90500: 0.035804979503154755\n",
            "90500: 0.035783179104328156\n",
            "90600: 0.04024462774395943\n",
            "90600: 0.044850677251815796\n",
            "90700: 0.04211528226733208\n",
            "90700: 0.04112223535776138\n",
            "91100: 0.03882452845573425\n",
            "91100: 0.04073301702737808\n",
            "91200: 0.034202173352241516\n",
            "91200: 0.03687242045998573\n",
            "91300: 0.05067725479602814\n",
            "91300: 0.03696288913488388\n",
            "91400: 0.039159487932920456\n",
            "91400: 0.03974149376153946\n",
            "91500: 0.041069284081459045\n",
            "91500: 0.03832794725894928\n",
            "91600: 0.03906773775815964\n",
            "91600: 0.03982438147068024\n",
            "91700: 0.03940688818693161\n",
            "91700: 0.0409022718667984\n",
            "91800: 0.04201814532279968\n",
            "91800: 0.05477618798613548\n",
            "91900: 0.042458586394786835\n",
            "91900: 0.05250408872961998\n",
            "92000: 0.0394677072763443\n",
            "92000: 0.03925659507513046\n",
            "Mean of last 92000: 0.0413162960558311\n",
            "92100: 0.039442576467990875\n",
            "92100: 0.04830637574195862\n",
            "92200: 0.04203911870718002\n",
            "92200: 0.04716262221336365\n",
            "92300: 0.05131281912326813\n",
            "92300: 0.04848974198102951\n",
            "92400: 0.03873448818922043\n",
            "92400: 0.05067289620637894\n",
            "92500: 0.039355967193841934\n",
            "92500: 0.03814053535461426\n",
            "92600: 0.04167520999908447\n",
            "92600: 0.03646727651357651\n",
            "92700: 0.04264470189809799\n",
            "92700: 0.03060740977525711\n",
            "92800: 0.03728875890374184\n",
            "92800: 0.03874175250530243\n",
            "92900: 0.03932167962193489\n",
            "92900: 0.03842456638813019\n",
            "93000: 0.05002626031637192\n",
            "93000: 0.05304741486907005\n",
            "Mean of last 93000: 0.0414256616332731\n",
            "93100: 0.04591897875070572\n",
            "93100: 0.04407673329114914\n",
            "93200: 0.042367562651634216\n",
            "93200: 0.04119409620761871\n",
            "93300: 0.04106411337852478\n",
            "93300: 0.037740349769592285\n",
            "93400: 0.04688377305865288\n",
            "93400: 0.04181265830993652\n",
            "93500: 0.045658450573682785\n",
            "93500: 0.04906916618347168\n",
            "93600: 0.037324707955121994\n",
            "93600: 0.046981096267700195\n",
            "93700: 0.037132397294044495\n",
            "93700: 0.03620527684688568\n",
            "93800: 0.04442957043647766\n",
            "93800: 0.04846053943037987\n",
            "93900: 0.0349070243537426\n",
            "93900: 0.03929172828793526\n",
            "94000: 0.043123140931129456\n",
            "94000: 0.03243476152420044\n",
            "Mean of last 94000: 0.041312425645751195\n",
            "94100: 0.049348920583724976\n",
            "94100: 0.03955754637718201\n",
            "94200: 0.04378107935190201\n",
            "94200: 0.045381274074316025\n",
            "94300: 0.03605446219444275\n",
            "94300: 0.03429495915770531\n",
            "94700: 0.05068998783826828\n",
            "94700: 0.034785039722919464\n",
            "94800: 0.03951442241668701\n",
            "94800: 0.041085775941610336\n",
            "94900: 0.037837158888578415\n",
            "94900: 0.037320442497730255\n",
            "95000: 0.03436008840799332\n",
            "95000: 0.04186328873038292\n",
            "Mean of last 95000: 0.04105833099111096\n",
            "95100: 0.04761345311999321\n",
            "95100: 0.0459168404340744\n",
            "95200: 0.03769058734178543\n",
            "95200: 0.03937098756432533\n",
            "95300: 0.03444686159491539\n",
            "95300: 0.03954564034938812\n",
            "95400: 0.03915448486804962\n",
            "95400: 0.041750218719244\n",
            "95500: 0.03984051197767258\n",
            "95500: 0.04027843102812767\n",
            "95600: 0.038228943943977356\n",
            "95600: 0.04150623083114624\n",
            "95700: 0.035424407571554184\n",
            "95700: 0.04009024798870087\n",
            "95800: 0.04272052273154259\n",
            "95800: 0.05003352090716362\n",
            "95900: 0.03406735509634018\n",
            "95900: 0.03341296315193176\n",
            "96000: 0.03759027644991875\n",
            "96000: 0.049545787274837494\n",
            "Mean of last 96000: 0.04129626513547176\n",
            "96100: 0.041516538709402084\n",
            "96100: 0.04339287802577019\n",
            "96200: 0.041577357798814774\n",
            "96200: 0.03753548488020897\n",
            "96300: 0.03764897584915161\n",
            "96300: 0.03651653975248337\n",
            "96400: 0.038258396089076996\n",
            "96400: 0.03634781390428543\n",
            "96500: 0.035071905702352524\n",
            "96500: 0.041641540825366974\n",
            "96600: 0.04363274201750755\n",
            "96600: 0.046901628375053406\n",
            "96700: 0.040141090750694275\n",
            "96700: 0.040305979549884796\n",
            "96800: 0.043863069266080856\n",
            "96800: 0.047310829162597656\n",
            "96900: 0.04112177714705467\n",
            "96900: 0.039855845272541046\n",
            "97000: 0.039700575172901154\n",
            "97000: 0.03800372779369354\n",
            "Mean of last 97000: 0.04118442849965988\n",
            "97100: 0.04952332377433777\n",
            "97100: 0.035540804266929626\n",
            "97200: 0.04017631709575653\n",
            "97200: 0.03791927546262741\n",
            "97300: 0.04184549301862717\n",
            "97300: 0.0403512567281723\n",
            "97400: 0.040033310651779175\n",
            "97400: 0.038584645837545395\n",
            "97500: 0.03581700474023819\n",
            "97500: 0.04187103360891342\n",
            "97600: 0.03846157342195511\n",
            "97600: 0.037547290325164795\n",
            "97700: 0.03953264653682709\n",
            "97700: 0.04747696965932846\n",
            "97800: 0.055773839354515076\n",
            "97800: 0.04878772422671318\n",
            "97900: 0.04561886191368103\n",
            "97900: 0.04022984206676483\n",
            "98000: 0.03984718397259712\n",
            "98000: 0.043634962290525436\n",
            "Mean of last 98000: 0.04120183828566874\n",
            "98100: 0.040544990450143814\n",
            "98100: 0.04321911931037903\n",
            "98200: 0.04209655523300171\n",
            "98200: 0.04656834155321121\n",
            "98300: 0.040127985179424286\n",
            "98300: 0.04248422384262085\n",
            "98400: 0.04097385331988335\n",
            "98400: 0.0430779866874218\n",
            "98500: 0.0516098253428936\n",
            "98500: 0.04224678501486778\n",
            "98600: 0.04125206544995308\n",
            "98600: 0.04482901841402054\n",
            "98700: 0.0356714129447937\n",
            "98700: 0.03968827426433563\n",
            "98800: 0.040509458631277084\n",
            "98800: 0.04096517711877823\n",
            "98900: 0.04155345261096954\n",
            "98900: 0.04838286340236664\n",
            "99000: 0.044119253754615784\n",
            "99000: 0.03932882100343704\n",
            "Mean of last 99000: 0.04117291297979437\n",
            "99100: 0.04126521199941635\n",
            "99100: 0.041276559233665466\n",
            "99200: 0.038534849882125854\n",
            "99200: 0.0409969836473465\n",
            "99300: 0.03864479809999466\n",
            "99300: 0.04172387719154358\n",
            "99400: 0.04079557955265045\n",
            "99400: 0.05641673505306244\n",
            "99500: 0.04550669714808464\n",
            "99500: 0.04157353937625885\n",
            "99600: 0.041846226900815964\n",
            "99600: 0.03533674031496048\n",
            "99700: 0.034450922161340714\n",
            "99700: 0.042888253927230835\n",
            "99800: 0.03975524753332138\n",
            "99800: 0.04587031900882721\n",
            "99900: 0.03947394713759422\n",
            "99900: 0.04106865078210831\n",
            "100000: 0.03888397291302681\n",
            "100000: 0.039778389036655426\n",
            "Mean of last 100000: 0.041183293701245356\n",
            "100100: 0.035634350031614304\n",
            "100100: 0.04898982495069504\n",
            "100200: 0.03672541677951813\n",
            "100200: 0.038218092173337936\n",
            "100300: 0.040232717990875244\n",
            "100300: 0.03679614141583443\n",
            "100400: 0.04585560783743858\n",
            "100400: 0.041582126170396805\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100500: 0.03494954854249954\n",
            "100500: 0.04040433093905449\n",
            "100600: 0.04577050358057022\n",
            "100600: 0.04381513595581055\n",
            "100700: 0.05156686156988144\n",
            "100700: 0.049895159900188446\n",
            "100800: 0.048911094665527344\n",
            "100800: 0.03792187571525574\n",
            "100900: 0.0382809042930603\n",
            "100900: 0.035622864961624146\n",
            "101000: 0.04447757452726364\n",
            "101000: 0.041030362248420715\n",
            "Mean of last 101000: 0.04110143710110154\n",
            "101100: 0.04050730913877487\n",
            "101100: 0.041403766721487045\n",
            "101200: 0.03829832375049591\n",
            "101200: 0.04134899377822876\n",
            "101300: 0.04109054431319237\n",
            "101300: 0.047782063484191895\n",
            "101400: 0.04373609647154808\n",
            "101400: 0.04005802422761917\n",
            "101500: 0.03694038838148117\n",
            "101500: 0.04234614595770836\n",
            "101600: 0.03551391512155533\n",
            "101600: 0.034221094101667404\n",
            "101700: 0.04248926788568497\n",
            "101700: 0.03916361182928085\n",
            "101800: 0.04534037038683891\n",
            "101800: 0.03731479495763779\n",
            "101900: 0.0396357998251915\n",
            "101900: 0.042358383536338806\n",
            "102000: 0.04359518736600876\n",
            "102000: 0.0447317436337471\n",
            "Mean of last 102000: 0.04108330721015131\n",
            "102100: 0.0358763188123703\n",
            "102100: 0.03696538135409355\n",
            "102200: 0.04319293424487114\n",
            "102200: 0.04199826717376709\n",
            "102300: 0.036511167883872986\n",
            "102300: 0.037677425891160965\n",
            "102400: 0.04002578929066658\n",
            "102400: 0.038228120654821396\n",
            "102500: 0.035321809351444244\n",
            "102500: 0.04285556077957153\n",
            "102600: 0.03631974011659622\n",
            "102600: 0.046329304575920105\n",
            "102700: 0.03789781779050827\n",
            "102700: 0.037619199603796005\n",
            "102800: 0.03824961930513382\n",
            "102800: 0.040762126445770264\n",
            "102900: 0.037788957357406616\n",
            "102900: 0.04837115854024887\n",
            "103000: 0.0432194285094738\n",
            "103000: 0.034648507833480835\n",
            "Mean of last 103000: 0.041251600215715785\n",
            "103100: 0.037805721163749695\n",
            "103100: 0.04357104003429413\n",
            "103200: 0.04172750562429428\n",
            "103200: 0.05024970695376396\n",
            "103300: 0.04622107744216919\n",
            "103300: 0.03722524642944336\n",
            "103400: 0.04225270077586174\n",
            "103400: 0.040936462581157684\n",
            "103500: 0.03492739051580429\n",
            "103500: 0.05000386759638786\n",
            "103600: 0.04045085236430168\n",
            "103600: 0.04965677857398987\n",
            "103700: 0.0462692491710186\n",
            "103700: 0.041287463158369064\n",
            "103800: 0.03455459699034691\n",
            "103800: 0.03563782200217247\n",
            "103900: 0.03876052796840668\n",
            "103900: 0.03824598342180252\n",
            "104000: 0.04103482887148857\n",
            "104000: 0.04357506334781647\n",
            "Mean of last 104000: 0.04123813650020948\n",
            "104100: 0.054195813834667206\n",
            "104100: 0.04230542108416557\n",
            "104200: 0.044871196150779724\n",
            "104200: 0.043000660836696625\n",
            "104300: 0.04192502051591873\n",
            "104300: 0.03659813106060028\n",
            "104400: 0.048968590795993805\n",
            "104400: 0.04033326357603073\n",
            "104500: 0.03794100508093834\n",
            "104500: 0.04187127202749252\n",
            "104600: 0.03545180708169937\n",
            "104600: 0.03834398090839386\n",
            "104700: 0.048782091587781906\n",
            "104700: 0.04121709614992142\n",
            "104800: 0.034845151007175446\n",
            "104800: 0.03524021431803703\n",
            "104900: 0.03940150886774063\n",
            "104900: 0.03789512440562248\n",
            "105000: 0.042294036597013474\n",
            "105000: 0.0599265992641449\n",
            "Mean of last 105000: 0.04120385818942622\n",
            "105100: 0.05135329067707062\n",
            "105100: 0.0465676449239254\n",
            "105200: 0.04891055449843407\n",
            "105200: 0.04646926373243332\n",
            "105300: 0.0415395051240921\n",
            "105300: 0.04139820486307144\n",
            "105400: 0.04159562289714813\n",
            "105400: 0.03638005629181862\n",
            "105500: 0.04673345014452934\n",
            "105500: 0.0328003354370594\n",
            "105600: 0.038441501557826996\n",
            "105600: 0.04689587652683258\n",
            "105700: 0.05041606351733208\n",
            "105700: 0.0395665317773819\n",
            "105800: 0.038303546607494354\n",
            "105800: 0.03915874660015106\n",
            "105900: 0.03997231647372246\n",
            "105900: 0.035261474549770355\n",
            "106000: 0.047230564057826996\n",
            "106000: 0.04005824774503708\n",
            "Mean of last 106000: 0.04115531910731868\n",
            "106100: 0.03686874359846115\n",
            "106100: 0.043793611228466034\n",
            "106200: 0.04108361899852753\n",
            "106200: 0.041370511054992676\n",
            "106300: 0.04452474042773247\n",
            "106300: 0.04126056656241417\n",
            "106400: 0.038664303719997406\n",
            "106400: 0.03809710592031479\n",
            "106500: 0.03725982829928398\n",
            "106500: 0.05659836158156395\n",
            "106600: 0.0364062637090683\n",
            "106600: 0.041890740394592285\n",
            "106700: 0.05187654495239258\n",
            "106700: 0.04109954833984375\n",
            "106800: 0.04512559622526169\n",
            "106800: 0.051381152123212814\n",
            "106900: 0.044092025607824326\n",
            "106900: 0.037340398877859116\n",
            "107000: 0.0405215322971344\n",
            "107000: 0.054063212126493454\n",
            "Mean of last 107000: 0.041000682035355\n",
            "107100: 0.03457913175225258\n",
            "107100: 0.04221564158797264\n",
            "107200: 0.04081893712282181\n",
            "107200: 0.034220024943351746\n",
            "107300: 0.04878246411681175\n",
            "107300: 0.035974450409412384\n",
            "107400: 0.03577693551778793\n",
            "107400: 0.044534459710121155\n",
            "107500: 0.0482223778963089\n",
            "107500: 0.033452101051807404\n",
            "107600: 0.03723271191120148\n",
            "107600: 0.040554095059633255\n",
            "107700: 0.03837921842932701\n",
            "107700: 0.038229312747716904\n",
            "107800: 0.03964166343212128\n",
            "107800: 0.03824114054441452\n",
            "107900: 0.038023531436920166\n",
            "107900: 0.03419801592826843\n",
            "108000: 0.054107915610075\n",
            "108000: 0.040471699088811874\n",
            "Mean of last 108000: 0.04118366379450847\n",
            "108100: 0.038566287606954575\n",
            "108100: 0.03932984918355942\n",
            "108200: 0.04104118049144745\n",
            "108200: 0.034226592630147934\n",
            "108300: 0.04140105098485947\n",
            "108300: 0.03790774568915367\n",
            "108400: 0.03871692717075348\n",
            "108400: 0.042626895010471344\n",
            "108500: 0.03870793804526329\n",
            "108500: 0.04185497388243675\n"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea2f94f",
      "metadata": {
        "id": "4ea2f94f",
        "outputId": "ac4f6178-a0f7-40d4-f63c-b4157a776794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is Time embed used ?  False\n",
            "HH\n",
            "Loading :  ./results_celebA/model_100000.pt\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "create_folder(\"./results_celebA_testHH_new\")\n",
        "\n",
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA_testHH_new\"\n",
        "data_path=\"./testdata/\"\n",
        "load_path=\"./results_celebA/model_100000.pt\"\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "test_type = 'train_paper_showing_diffusion_images_cover_page'\n",
        " \n",
        "img_path = data_path\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine = train_routine,\n",
        "    sampling_routine = sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    img_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps = train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder = save_folder,\n",
        "    load_path = load_path,\n",
        "    dataset = 'HH',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_type == 'train_data':\n",
        "    trainer.test_from_data('train', s_times=time_steps)\n",
        "\n",
        "elif test_type == 'test_data':\n",
        "    trainer.test_from_data('test', s_times=time_steps)\n",
        "\n",
        "#### for FID and noise ablation ##\n",
        "elif test_type == 'test_sample_and_save_for_fid':\n",
        "    trainer.sample_and_save_for_fid()\n",
        "\n",
        "########## for paper ##########\n",
        "\n",
        "elif test_type == 'train_paper_showing_diffusion_images_cover_page':\n",
        "    trainer.paper_showing_diffusion_images_cover_page()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36311ac",
      "metadata": {
        "id": "d36311ac"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}