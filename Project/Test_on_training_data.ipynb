{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPM7VvuRdiJssIAVZZP1xVX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/econdatatech/AIML425/blob/main/Project/Test_on_training_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get all the pre-trained diffusion models for LL,LH,HL,HH and then doing a foward + backward process on the training images in each band"
      ],
      "metadata": {
        "id": "e10EbWjWUzIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Authenticate and create the PyDrive client\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1g7fO-dHYNUDuNdjV3IIqWrQ7MHYlylN9\"})   \n",
        "downloaded.GetContentFile('model_100000LL.pt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1YWtUG0-S8BcWVOFowfEkd05-WPhX60ze\"})   \n",
        "downloaded.GetContentFile('model_100000LH.pt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1k0aVtu0lE9APo-4H_PuRZ0X-BRZti_wv\"})   \n",
        "downloaded.GetContentFile('model_100000HL.pt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"13nkO4OOCd62fBv949VCeyVZ-RePhHhPd\"})   \n",
        "downloaded.GetContentFile('model_100000HH.pt')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"107vh6Tibfs1p8pbc3gql-eVwxiqCD2o4\"})   \n",
        "downloaded.GetContentFile('data128x128.zip')       \n"
      ],
      "metadata": {
        "id": "-LsVplfrTrZH"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/arpitbansal297/Cold-Diffusion-Models.git\n",
        "!apt-get install unzip\n",
        "!unzip -q -j data128x128.zip -d ./root_celebA_128_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6SZ_kPpCkfd",
        "outputId": "4bb22d0c-8959-4c84-d4fd-7ffc2b61a99a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Cold-Diffusion-Models'...\n",
            "remote: Enumerating objects: 262, done.\u001b[K\n",
            "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 262 (delta 47), reused 38 (delta 33), pack-reused 196\u001b[K\n",
            "Receiving objects: 100% (262/262), 2.65 MiB | 30.86 MiB/s, done.\n",
            "Resolving deltas: 100% (152/152), done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install comet_ml einops tqdm torchgeometry matplotlib einops scikit-image sklearn pywavelets opencv-python --quiet\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, color\n",
        "import pywt\n",
        "import sys\n",
        "import numpy as np\n",
        "sys.path.append('Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/')\n",
        "from comet_ml import Experiment\n",
        "import torchvision\n",
        "import os\n",
        "import errno\n",
        "import shutil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XY_8tqmDCsVY",
        "outputId": "cf15369a-4624-4de2-f2c1-efac25c39d19"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 412 kB 35.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 495 kB 69.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 1.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 74.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 73.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 166 kB 81.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 81.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 162 kB 77.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 158 kB 79.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 82.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 78.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 81.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 80.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 77.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 68.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 157 kB 66.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 156 kB 45.1 MB/s \n",
            "\u001b[?25h  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for configobj (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# %load 'Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py'\n",
        "from comet_ml import Experiment\n",
        "import math\n",
        "import copy\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from inspect import isfunction\n",
        "from functools import partial\n",
        "\n",
        "from torch.utils import data\n",
        "from pathlib import Path\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from einops import rearrange\n",
        "\n",
        "import torchgeometry as tgm\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torch import linalg as LA\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "try:\n",
        "    from apex import amp\n",
        "    APEX_AVAILABLE = True\n",
        "except:\n",
        "    APEX_AVAILABLE = False\n",
        "\n",
        "# helpers functions\n",
        "\n",
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if isfunction(d) else d\n",
        "\n",
        "def cycle(dl):\n",
        "    while True:\n",
        "        for data in dl:\n",
        "            yield data\n",
        "\n",
        "def num_to_groups(num, divisor):\n",
        "    groups = num // divisor\n",
        "    remainder = num % divisor\n",
        "    arr = [divisor] * groups\n",
        "    if remainder > 0:\n",
        "        arr.append(remainder)\n",
        "    return arr\n",
        "\n",
        "def loss_backwards(fp16, loss, optimizer, **kwargs):\n",
        "    if fp16:\n",
        "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "            scaled_loss.backward(**kwargs)\n",
        "    else:\n",
        "        loss.backward(**kwargs)\n",
        "\n",
        "# small helper modules\n",
        "\n",
        "class EMA():\n",
        "    def __init__(self, beta):\n",
        "        super().__init__()\n",
        "        self.beta = beta\n",
        "\n",
        "    def update_model_average(self, ma_model, current_model):\n",
        "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
        "            old_weight, up_weight = ma_params.data, current_params.data\n",
        "            ma_params.data = self.update_average(old_weight, up_weight)\n",
        "\n",
        "    def update_average(self, old, new):\n",
        "        if old is None:\n",
        "            return new\n",
        "        return old * self.beta + (1 - self.beta) * new\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "def Upsample(dim):\n",
        "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "def Downsample(dim):\n",
        "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim, eps = 1e-5):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
        "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
        "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
        "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)\n",
        "\n",
        "# building block modules\n",
        "\n",
        "class ConvNextBlock(nn.Module):\n",
        "    \"\"\" https://arxiv.org/abs/2201.03545 \"\"\"\n",
        "\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim = None, mult = 2, norm = True):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_emb_dim, dim)\n",
        "        ) if exists(time_emb_dim) else None\n",
        "\n",
        "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding = 3, groups = dim)\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            LayerNorm(dim) if norm else nn.Identity(),\n",
        "            nn.Conv2d(dim, dim_out * mult, 3, padding = 1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv2d(dim_out * mult, dim_out, 3, padding = 1)\n",
        "        )\n",
        "\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb = None):\n",
        "        h = self.ds_conv(x)\n",
        "\n",
        "        if exists(self.mlp):\n",
        "            assert exists(time_emb), 'time emb must be passed in'\n",
        "            condition = self.mlp(time_emb)\n",
        "            h = h + rearrange(condition, 'b c -> b c 1 1')\n",
        "\n",
        "        h = self.net(h)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
        "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
        "        q = q * self.scale\n",
        "\n",
        "        k = k.softmax(dim = -1)\n",
        "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
        "\n",
        "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
        "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "# model\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 3,\n",
        "        with_time_emb = True,\n",
        "        residual = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.residual = residual\n",
        "        print(\"Is Time embed used ? \", with_time_emb)\n",
        "\n",
        "        dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        if with_time_emb:\n",
        "            time_dim = dim\n",
        "            self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPosEmb(dim),\n",
        "                nn.Linear(dim, dim * 4),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(dim * 4, dim)\n",
        "            )\n",
        "        else:\n",
        "            time_dim = None\n",
        "            self.time_mlp = None\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_in, dim_out, time_emb_dim = time_dim, norm = ind != 0),\n",
        "                ConvNextBlock(dim_out, dim_out, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                Downsample(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim)))\n",
        "        self.mid_block2 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                ConvNextBlock(dim_out * 2, dim_in, time_emb_dim = time_dim),\n",
        "                ConvNextBlock(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                Upsample(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        out_dim = default(out_dim, channels)\n",
        "        self.final_conv = nn.Sequential(\n",
        "            ConvNextBlock(dim, dim),\n",
        "            nn.Conv2d(dim, out_dim, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        orig_x = x\n",
        "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
        "\n",
        "        h = []\n",
        "\n",
        "        for convnext, convnext2, attn, downsample in self.downs:\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        for convnext, convnext2, attn, upsample in self.ups:\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = convnext(x, t)\n",
        "            x = convnext2(x, t)\n",
        "            x = attn(x)\n",
        "            x = upsample(x)\n",
        "        if self.residual:\n",
        "            return self.final_conv(x) + orig_x\n",
        "\n",
        "        return self.final_conv(x)\n",
        "\n",
        "# gaussian diffusion trainer class\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "def noise_like(shape, device, repeat=False):\n",
        "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n",
        "    noise = lambda: torch.randn(shape, device=device)\n",
        "    return repeat_noise() if repeat else noise()\n",
        "\n",
        "def cosine_beta_schedule(timesteps, s = 0.008):\n",
        "    \"\"\"\n",
        "    cosine schedule\n",
        "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
        "    \"\"\"\n",
        "    steps = timesteps + 1\n",
        "    x = torch.linspace(0, steps, steps)\n",
        "    alphas_cumprod = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
        "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
        "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
        "    return torch.clip(betas, 0, 0.999)\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "class GaussianDiffusion(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        denoise_fn,\n",
        "        *,\n",
        "        image_size,\n",
        "        channels = 3,\n",
        "        timesteps = 1000,\n",
        "        loss_type = 'l1',\n",
        "        train_routine = 'Final',\n",
        "        sampling_routine='default',\n",
        "        discrete=False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.image_size = image_size\n",
        "        self.denoise_fn = denoise_fn\n",
        "\n",
        "        self.num_timesteps = int(timesteps)\n",
        "        self.loss_type = loss_type\n",
        "\n",
        "        betas = cosine_beta_schedule(timesteps)\n",
        "        alphas = 1. - betas\n",
        "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "\n",
        "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
        "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
        "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
        "\n",
        "        self.train_routine = train_routine\n",
        "        self.sampling_routine = sampling_routine\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def sample(self, batch_size = 16, img=None, t=None):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        xt = img\n",
        "        direct_recons = None\n",
        "\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            if direct_recons is None:\n",
        "                direct_recons = x1_bar\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        self.denoise_fn.train()\n",
        "\n",
        "        return xt, direct_recons, img\n",
        "\n",
        "    def get_x2_bar_from_xt(self, x1_bar, xt, t):\n",
        "        return (\n",
        "                (xt - extract(self.sqrt_alphas_cumprod, t, x1_bar.shape) * x1_bar) /\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x1_bar.shape)\n",
        "        )\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def gen_sample(self, batch_size=16, img=None, t=None):\n",
        "        self.denoise_fn.eval()\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        noise = img\n",
        "        direct_recons = None\n",
        "\n",
        "        if self.sampling_routine == 'ddim':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        elif self.sampling_routine == 'x0_step_down':\n",
        "            while (t):\n",
        "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "                x1_bar = self.denoise_fn(img, step)\n",
        "                x2_bar = noise\n",
        "                if direct_recons == None:\n",
        "                    direct_recons = x1_bar\n",
        "\n",
        "                xt_bar = x1_bar\n",
        "                if t != 0:\n",
        "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "                xt_sub1_bar = x1_bar\n",
        "                if t - 1 != 0:\n",
        "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "                x = img - xt_bar + xt_sub1_bar\n",
        "                img = x\n",
        "                t = t - 1\n",
        "\n",
        "        return noise, direct_recons, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def forward_and_backward(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        Forward = []\n",
        "        Forward.append(img)\n",
        "\n",
        "        noise = torch.randn_like(img)\n",
        "\n",
        "        for i in range(t):\n",
        "            with torch.no_grad():\n",
        "                step = torch.full((batch_size,), i, dtype=torch.long, device=img.device)\n",
        "                n_img = self.q_sample(x_start=img, x_end=noise, t=step)\n",
        "                Forward.append(n_img)\n",
        "\n",
        "        Backward = []\n",
        "        img = n_img\n",
        "        while (t):\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = noise #self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "            Backward.append(img)\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return Forward, Backward, img\n",
        "\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def all_sample(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
        "\n",
        "        if eval:\n",
        "            self.denoise_fn.eval()\n",
        "\n",
        "        if t == None:\n",
        "            t = self.num_timesteps\n",
        "\n",
        "        X1_0s, X2_0s, X_ts = [], [], []\n",
        "        while (t):\n",
        "\n",
        "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
        "            x1_bar = self.denoise_fn(img, step)\n",
        "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
        "\n",
        "\n",
        "            X1_0s.append(x1_bar.detach().cpu())\n",
        "            X2_0s.append(x2_bar.detach().cpu())\n",
        "            X_ts.append(img.detach().cpu())\n",
        "\n",
        "            xt_bar = x1_bar\n",
        "            if t != 0:\n",
        "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
        "\n",
        "            xt_sub1_bar = x1_bar\n",
        "            if t - 1 != 0:\n",
        "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
        "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
        "\n",
        "            x = img - xt_bar + xt_sub1_bar\n",
        "            img = x\n",
        "            t = t - 1\n",
        "\n",
        "        return X1_0s, X2_0s, X_ts\n",
        "\n",
        "    def q_sample(self, x_start, x_end, t):\n",
        "        # simply use the alphas to interpolate\n",
        "        return (\n",
        "                extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
        "                extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * x_end\n",
        "        )\n",
        "\n",
        "    def p_losses(self, x_start, x_end, t):\n",
        "        b, c, h, w = x_start.shape\n",
        "        if self.train_routine == 'Final':\n",
        "            x_mix = self.q_sample(x_start=x_start, x_end=x_end, t=t)\n",
        "            x_recon = self.denoise_fn(x_mix, t)\n",
        "            if self.loss_type == 'l1':\n",
        "                loss = (x_start - x_recon).abs().mean()\n",
        "            elif self.loss_type == 'l2':\n",
        "                loss = F.mse_loss(x_start, x_recon)\n",
        "            else:\n",
        "                raise NotImplementedError()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def forward(self, x1, x2, *args, **kwargs):\n",
        "        b, c, h, w, device, img_size, = *x1.shape, x1.device, self.image_size\n",
        "        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n",
        "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
        "        return self.p_losses(x1, x2, t, *args, **kwargs)\n",
        "\n",
        "class Dataset_Aug1(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts = ['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.RandomCrop(image_size),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "\n",
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, folder, image_size, exts=['jpg', 'jpeg', 'png','bmp']):\n",
        "        super().__init__()\n",
        "        self.folder = folder\n",
        "        self.image_size = image_size\n",
        "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
        "            transforms.CenterCrop(image_size),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.paths[index]\n",
        "        img = Image.open(path)\n",
        "        img = img.convert('RGB')\n",
        "        return self.transform(img)\n",
        "# trainer class\n",
        "import os\n",
        "import errno\n",
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "from collections import OrderedDict\n",
        "def remove_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('.module', '')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "def adjust_data_parallel(old_state_dict):\n",
        "    new_state_dict = OrderedDict()\n",
        "\n",
        "    for k, v in old_state_dict.items():\n",
        "        name = k.replace('denoise_fn.module', 'module.denoise_fn')  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    return new_state_dict\n",
        "\n",
        "class Trainer(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        diffusion_model,\n",
        "        folder,\n",
        "        *,\n",
        "        ema_decay = 0.995,\n",
        "        image_size = 128,\n",
        "        train_batch_size = 32,\n",
        "        train_lr = 2e-5,\n",
        "        train_num_steps = 100000,\n",
        "        gradient_accumulate_every = 2,\n",
        "        fp16 = False,\n",
        "        step_start_ema = 2000,\n",
        "        update_ema_every = 10,\n",
        "        save_and_sample_every = 1000,\n",
        "        results_folder = './results',\n",
        "        load_path = None,\n",
        "        dataset = None,\n",
        "        shuffle=True\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.model = diffusion_model\n",
        "        self.ema = EMA(ema_decay)\n",
        "        self.ema_model = copy.deepcopy(self.model)\n",
        "        self.update_ema_every = update_ema_every\n",
        "\n",
        "        self.step_start_ema = step_start_ema\n",
        "        self.save_and_sample_every = save_and_sample_every\n",
        "\n",
        "        self.batch_size = train_batch_size\n",
        "        self.image_size = image_size\n",
        "        self.gradient_accumulate_every = gradient_accumulate_every\n",
        "        self.train_num_steps = train_num_steps\n",
        "\n",
        "        if dataset == 'train':\n",
        "            print(dataset, \"DA used\")\n",
        "            self.ds = Dataset_Aug1(folder, image_size)\n",
        "        else:\n",
        "            print(dataset)\n",
        "            self.ds = Dataset(folder, image_size)\n",
        "\n",
        "        self.dl = cycle(data.DataLoader(self.ds, batch_size = train_batch_size, shuffle=shuffle, pin_memory=True, num_workers=16, drop_last=True))\n",
        "\n",
        "        self.opt = Adam(diffusion_model.parameters(), lr=train_lr)\n",
        "        self.step = 0\n",
        "\n",
        "        self.results_folder = Path(results_folder)\n",
        "        self.results_folder.mkdir(exist_ok = True)\n",
        "\n",
        "        self.fp16 = fp16\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "        if load_path != None:\n",
        "            self.load(load_path)\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.ema_model.load_state_dict(self.model.state_dict())\n",
        "\n",
        "    def step_ema(self):\n",
        "        if self.step < self.step_start_ema:\n",
        "            self.reset_parameters()\n",
        "            return\n",
        "        self.ema.update_model_average(self.ema_model, self.model)\n",
        "\n",
        "    def save(self, itrs=None):\n",
        "        data = {\n",
        "            'step': self.step,\n",
        "            'model': self.model.state_dict(),\n",
        "            'ema': self.ema_model.state_dict()\n",
        "        }\n",
        "        if itrs is None:\n",
        "            torch.save(data, str(self.results_folder / f'model.pt'))\n",
        "        else:\n",
        "            torch.save(data, str(self.results_folder / f'model_{itrs}.pt'))\n",
        "\n",
        "    def load(self, load_path):\n",
        "        print(\"Loading : \", load_path)\n",
        "        data = torch.load(load_path)\n",
        "\n",
        "        self.step = data['step']\n",
        "        self.model.load_state_dict(data['model'])\n",
        "        self.ema_model.load_state_dict(data['ema'])\n",
        "\n",
        "\n",
        "    def add_title(self, path, title):\n",
        "\n",
        "        import cv2\n",
        "        import numpy as np\n",
        "\n",
        "        img1 = cv2.imread(path)\n",
        "\n",
        "        # --- Here I am creating the border---\n",
        "        black = [0, 0, 0]  # ---Color of the border---\n",
        "        constant = cv2.copyMakeBorder(img1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "        height = 20\n",
        "        violet = np.zeros((height, constant.shape[1], 3), np.uint8)\n",
        "        violet[:] = (255, 0, 180)\n",
        "\n",
        "        vcat = cv2.vconcat((violet, constant))\n",
        "\n",
        "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "\n",
        "        cv2.putText(vcat, str(title), (violet.shape[1] // 2, height-2), font, 0.5, (0, 0, 0), 1, 0)\n",
        "        cv2.imwrite(path, vcat)\n",
        "\n",
        "\n",
        "\n",
        "    def train(self):\n",
        "\n",
        "        backwards = partial(loss_backwards, self.fp16)\n",
        "\n",
        "        acc_loss = 0\n",
        "        while self.step < self.train_num_steps:\n",
        "            u_loss = 0\n",
        "            for i in range(self.gradient_accumulate_every):\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "\n",
        "                data_1, data_2 = data_1.cuda(), data_2.cuda()\n",
        "                loss = torch.mean(self.model(data_1, data_2))\n",
        "                if self.step % 100 == 0:\n",
        "                    print(f'{self.step}: {loss.item()}')\n",
        "                u_loss += loss.item()\n",
        "                backwards(loss / self.gradient_accumulate_every, self.opt)\n",
        "\n",
        "            acc_loss = acc_loss + (u_loss/self.gradient_accumulate_every)\n",
        "\n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "            if self.step % self.update_ema_every == 0:\n",
        "                self.step_ema()\n",
        "\n",
        "            if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
        "                milestone = self.step // self.save_and_sample_every\n",
        "                batches = self.batch_size\n",
        "\n",
        "                data_1 = next(self.dl)\n",
        "                data_2 = torch.randn_like(data_1)\n",
        "                og_img = data_2.cuda()\n",
        "\n",
        "                xt, direct_recons, all_images = self.ema_model.module.sample(batch_size=batches, img=og_img)\n",
        "\n",
        "                og_img = (og_img + 1) * 0.5\n",
        "                utils.save_image(og_img, str(self.results_folder / f'sample-og-{milestone}.png'), nrow=6)\n",
        "\n",
        "                all_images = (all_images + 1) * 0.5\n",
        "                utils.save_image(all_images, str(self.results_folder / f'sample-recon-{milestone}.png'), nrow = 6)\n",
        "\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'sample-direct_recons-{milestone}.png'), nrow=6)\n",
        "\n",
        "                xt = (xt + 1) * 0.5\n",
        "                utils.save_image(xt, str(self.results_folder / f'sample-xt-{milestone}.png'),\n",
        "                                 nrow=6)\n",
        "\n",
        "                acc_loss = acc_loss/(self.save_and_sample_every+1)\n",
        "                print(f'Mean of last {self.step}: {acc_loss}')\n",
        "                acc_loss=0\n",
        "\n",
        "                self.save()\n",
        "                if self.step % (self.save_and_sample_every * 100) == 0:\n",
        "                    self.save(self.step)\n",
        "\n",
        "            self.step += 1\n",
        "\n",
        "        print('training completed')\n",
        "\n",
        "    def test_from_data(self, extra_path, s_times=None):\n",
        "        batches = self.batch_size\n",
        "        og_img = next(self.dl).cuda()\n",
        "        a, X_0s, X_ts = self.ema_model.module.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images, str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "    def sample_and_save_for_fid(self, noise=0):\n",
        "\n",
        "        # xt_folder = f'{self.results_folder}_xt'\n",
        "        # create_folder(xt_folder)\n",
        "\n",
        "        out_folder = f'{self.results_folder}_out'\n",
        "        create_folder(out_folder)\n",
        "\n",
        "        # direct_recons_folder = f'{self.results_folder}_dir_recons'\n",
        "        # create_folder(direct_recons_folder)\n",
        "\n",
        "        # data_1 = next(self.dl)\n",
        "\n",
        "        cnt = 0\n",
        "        bs = 128\n",
        "        for j in range(int(6400/bs)):\n",
        "\n",
        "            data_2 = torch.randn(bs, 3, 64, 64)\n",
        "            og_img = data_2.cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            xt, direct_recons, all_images = self.ema_model.module.gen_sample(batch_size=bs, img=og_img)\n",
        "\n",
        "            for i in range(all_images.shape[0]):\n",
        "                utils.save_image((all_images[i] + 1) * 0.5,\n",
        "                                 str(f'{out_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                # utils.save_image((xt[i] + 1) * 0.5,\n",
        "                #                  str(f'{xt_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                #\n",
        "                # utils.save_image((direct_recons[i] + 1) * 0.5,\n",
        "                #                  str(f'{direct_recons_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images_cover_page(self):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # for 200 steps\n",
        "        # to_show = [2, 4, 8, 16, 32, 64, 128, 192]\n",
        "        to_show = [2, 4, 16, 64, 128, 256, 384, 448, 480]\n",
        "\n",
        "        for i in range(5):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            Forward, Backward, final_all = self.ema_model.module.forward_and_backward(batch_size=batches, img=og_img)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            final_all = (final_all + 1) * 0.5\n",
        "\n",
        "\n",
        "\n",
        "            for k in range(Forward[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                utils.save_image(og_img[k], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "                start = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "                l.append(start)\n",
        "\n",
        "                for j in range(len(Forward)):\n",
        "                    x_t = Forward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "                for j in range(len(Backward)):\n",
        "                    x_t = Backward[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
        "                    if (len(Backward) - j) in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                utils.save_image(final_all[k], str(self.results_folder / f'final_{cnt}.png'), nrow=1)\n",
        "                final = cv2.imread(f'{self.results_folder}/final_{cnt}.png')\n",
        "                l.append(final)\n",
        "\n",
        "\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_invert_section_images(self, s_times=None):\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for j in range(og_img.shape[0]//3):\n",
        "                original = og_img[j: j + 1]\n",
        "                utils.save_image(original, str(self.results_folder / f'original_{cnt}.png'), nrow=3)\n",
        "\n",
        "                direct_recons = X_0s[0][j: j + 1]\n",
        "                direct_recons = (direct_recons + 1) * 0.5\n",
        "                utils.save_image(direct_recons, str(self.results_folder / f'direct_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                sampling_recons = X_0s[-1][j: j + 1]\n",
        "                sampling_recons = (sampling_recons + 1) * 0.5\n",
        "                utils.save_image(sampling_recons, str(self.results_folder / f'sampling_recons_{cnt}.png'), nrow=3)\n",
        "\n",
        "                blurry_image = X_ts[0][j: j + 1]\n",
        "                blurry_image = (blurry_image + 1) * 0.5\n",
        "                utils.save_image(blurry_image, str(self.results_folder / f'blurry_image_{cnt}.png'), nrow=3)\n",
        "\n",
        "\n",
        "\n",
        "                import cv2\n",
        "\n",
        "                blurry_image = cv2.imread(f'{self.results_folder}/blurry_image_{cnt}.png')\n",
        "                direct_recons = cv2.imread(f'{self.results_folder}/direct_recons_{cnt}.png')\n",
        "                sampling_recons = cv2.imread(f'{self.results_folder}/sampling_recons_{cnt}.png')\n",
        "                original = cv2.imread(f'{self.results_folder}/original_{cnt}.png')\n",
        "\n",
        "                black = [0, 0, 0]\n",
        "                blurry_image = cv2.copyMakeBorder(blurry_image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                direct_recons = cv2.copyMakeBorder(direct_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                sampling_recons = cv2.copyMakeBorder(sampling_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                original = cv2.copyMakeBorder(original, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([blurry_image, direct_recons, sampling_recons, original])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def paper_showing_diffusion_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        # to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "        # to_show = [0, 1, 2, 4, 8, 16, 24, 32, 40, 44, 46, 48, 49]\n",
        "        to_show = [0, 2, 4, 8, 16, 32, 64, 80, 88, 92, 96, 98, 99]\n",
        "\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            for k in range(X_ts[0].shape[0]):\n",
        "                l = []\n",
        "\n",
        "                for j in range(len(X_ts)):\n",
        "                    x_t = X_ts[j][k]\n",
        "                    x_t = (x_t + 1) * 0.5\n",
        "                    utils.save_image(x_t, str(self.results_folder / f'x_{len(X_ts)-j}_{cnt}.png'), nrow=1)\n",
        "                    x_t = cv2.imread(f'{self.results_folder}/x_{len(X_ts)-j}_{cnt}.png')\n",
        "                    if j in to_show:\n",
        "                        l.append(x_t)\n",
        "\n",
        "\n",
        "                x_0 = X_0s[-1][k]\n",
        "                x_0 = (x_0 + 1) * 0.5\n",
        "                utils.save_image(x_0, str(self.results_folder / f'x_best_{cnt}.png'), nrow=1)\n",
        "                x_0 = cv2.imread(f'{self.results_folder}/x_best_{cnt}.png')\n",
        "                l.append(x_0)\n",
        "                im_h = cv2.hconcat(l)\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt+=1\n",
        "\n",
        "\n",
        "    def paper_showing_diffusion_images_diff(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        for i in range(50):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, X_ts_alg2 = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "            X_0s_alg1, X_ts_alg1 = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "            alg2 = []\n",
        "            alg1 = []\n",
        "\n",
        "            #to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
        "            to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
        "\n",
        "            for j in range(len(X_ts_alg2)):\n",
        "                x_t = X_ts_alg2[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg2)-j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg2)-j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg2.append(x_t)\n",
        "\n",
        "                x_t = X_ts_alg1[j][0]\n",
        "                x_t = (x_t + 1) * 0.5\n",
        "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg1) - j}_{i}.png'), nrow=1)\n",
        "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg1) - j}_{i}.png')\n",
        "                if j in to_show:\n",
        "                    alg1.append(x_t)\n",
        "\n",
        "\n",
        "            x_0 = X_0s_alg2[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg2_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg2_{i}.png')\n",
        "            alg2.append(x_0)\n",
        "            im_h = cv2.hconcat(alg2)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg2_{i}.png', im_h)\n",
        "\n",
        "            x_0 = X_0s_alg1[-1][0]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg1_{i}.png'), nrow=1)\n",
        "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg1_{i}.png')\n",
        "            alg1.append(x_0)\n",
        "            im_h = cv2.hconcat(alg1)\n",
        "            cv2.imwrite(f'{self.results_folder}/all_alg1_{i}.png', im_h)\n",
        "\n",
        "\n",
        "    def paper_showing_sampling_diff_images(self, s_times=None):\n",
        "\n",
        "        import cv2\n",
        "        cnt = 0\n",
        "        for i in range(10):\n",
        "            batches = self.batch_size\n",
        "            og_img = next(self.dl).cuda()\n",
        "            print(og_img.shape)\n",
        "\n",
        "            X_0s_alg2, _ = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches, img=og_img, times=s_times)\n",
        "            X_0s_alg1, _ = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
        "                                                                 img=og_img, times=s_times)\n",
        "\n",
        "            x0_alg1 = (X_0s_alg1[-1] + 1) * 0.5\n",
        "            x0_alg2 = (X_0s_alg2[-1] + 1) * 0.5\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "\n",
        "\n",
        "            for j in range(og_img.shape[0]):\n",
        "                utils.save_image(x0_alg1[j], str(self.results_folder / f'x0_alg1_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(x0_alg2[j], str(self.results_folder / f'x0_alg2_{cnt}.png'), nrow=1)\n",
        "                utils.save_image(og_img[j], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
        "\n",
        "\n",
        "\n",
        "                alg1 = cv2.imread(f'{self.results_folder}/x0_alg1_{cnt}.png')\n",
        "                alg2 = cv2.imread(f'{self.results_folder}/x0_alg2_{cnt}.png')\n",
        "                og = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
        "\n",
        "\n",
        "                black = [255, 255, 255]\n",
        "                alg1 = cv2.copyMakeBorder(alg1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                alg2 = cv2.copyMakeBorder(alg2, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "                og = cv2.copyMakeBorder(og, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
        "\n",
        "                im_h = cv2.hconcat([og, alg1, alg2])\n",
        "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "    def sample_as_a_vector_gmm(self, start=0, end=1000, siz=64, ch=3, clusters=10):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "\n",
        "        num_samples = 100\n",
        "\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "        og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "        og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "        og_x = torch.from_numpy(og_x).cuda()\n",
        "        og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "        print(og_x.shape)\n",
        "        og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "\n",
        "\n",
        "        X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "        extra_path = 'vec'\n",
        "        og_img = (og_img + 1) * 0.5\n",
        "        utils.save_image(og_img, str(self.results_folder / f'og-{start}-{end}-{siz}-{clusters}-{extra_path}.png'), nrow=6)\n",
        "\n",
        "        import imageio\n",
        "        frames_t = []\n",
        "        frames_0 = []\n",
        "\n",
        "        for i in range(len(X_0s)):\n",
        "            print(i)\n",
        "\n",
        "            x_0 = X_0s[i]\n",
        "            x_0 = (x_0 + 1) * 0.5\n",
        "            utils.save_image(x_0, str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'),\n",
        "                             nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'), str(i))\n",
        "            frames_0.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png')))\n",
        "\n",
        "            x_t = X_ts[i]\n",
        "            all_images = (x_t + 1) * 0.5\n",
        "            utils.save_image(all_images,\n",
        "                             str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), nrow=6)\n",
        "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), str(i))\n",
        "            frames_t.append(\n",
        "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png')))\n",
        "\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-x0.gif'), frames_0)\n",
        "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-xt.gif'), frames_t)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_gmm_and_save(self, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "        all_samples = []\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img)\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        all_samples = all_samples.cpu().detach().numpy()\n",
        "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 10000\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x, og_y = gm.sample(n_samples=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "            og_x = torch.from_numpy(og_x).cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "\n",
        "    def sample_as_a_vector_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "\n",
        "\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "        all_samples = None\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "\n",
        "        #all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num / num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/')\n",
        "\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            #og_x, _ = model.sample(n=num_samples)\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            blurs = X_ts[0]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((blurs[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/' + f'sample-blur-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "            print(it)\n",
        "\n",
        "    def sample_as_a_vector_from_blur_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
        "        flatten = nn.Flatten()\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "\n",
        "        #sample_at = self.ema_model.num_timesteps // 2\n",
        "        sample_at = self.ema_model.num_timesteps // 2\n",
        "        all_samples = None\n",
        "\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0)\n",
        "            img = self.ema_model.opt(img.cuda(), t=sample_at)\n",
        "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
        "            img = flatten(img).cuda()\n",
        "\n",
        "            if idx > start:\n",
        "                if all_samples is None:\n",
        "                    all_samples = img\n",
        "                else:\n",
        "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
        "                #all_samples.append(img[0])\n",
        "\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        # all_samples = torch.stack(all_samples)\n",
        "        print(all_samples.shape)\n",
        "\n",
        "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
        "                          convergence_tolerance=0.001, batch_size=1000)\n",
        "        model.fit(all_samples)\n",
        "\n",
        "\n",
        "\n",
        "        all_num = n_sample\n",
        "        num_samples = 100\n",
        "        it = int(all_num/num_samples)\n",
        "\n",
        "        create_folder(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/')\n",
        "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}_{sample_at}/')\n",
        "\n",
        "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(it):\n",
        "            og_x = model.sample(num_datapoints=num_samples)\n",
        "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
        "\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            print(og_x.shape)\n",
        "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
        "            X_0s, X_ts = self.ema_model.all_sample_from_blur(batch_size=og_img.shape[0], img=og_img, start_times=sample_at)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/' + f'sample-x0-{cnt}.png'))\n",
        "\n",
        "                utils.save_image((og_img[i] + 1) * 0.5,\n",
        "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/' + f'sample-{cnt}.png'))\n",
        "\n",
        "                cnt += 1\n",
        "\n",
        "            it = it - 1\n",
        "\n",
        "\n",
        "\n",
        "    def sample_from_data_save(self, start=0, end=1000):\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 1000]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            x0s = X_0s[-1]\n",
        "            for i in range(x0s.shape[0]):\n",
        "                utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "                cnt += 1\n",
        "\n",
        "    def fid_distance_decrease_from_manifold(self, fid_func, start=0, end=1000):\n",
        "\n",
        "        #from skimage.metrics import structural_similarity as ssim\n",
        "        from pytorch_msssim import ssim\n",
        "\n",
        "        all_samples = []\n",
        "        dataset = self.ds\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = torch.unsqueeze(img, 0).cuda()\n",
        "            if idx > start:\n",
        "                all_samples.append(img[0])\n",
        "            if idx % 1000 == 0:\n",
        "                print(idx)\n",
        "            if end != None:\n",
        "                if idx == end:\n",
        "                    print(idx)\n",
        "                    break\n",
        "\n",
        "        all_samples = torch.stack(all_samples)\n",
        "        # create_folder(f'{self.results_folder}/')\n",
        "        blurred_samples = None\n",
        "        original_sample = None\n",
        "        deblurred_samples = None\n",
        "        direct_deblurred_samples = None\n",
        "\n",
        "        sanity_check = 1\n",
        "\n",
        "\n",
        "        cnt=0\n",
        "        while(cnt < all_samples.shape[0]):\n",
        "            og_x = all_samples[cnt: cnt + 100]\n",
        "            og_x = og_x.cuda()\n",
        "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
        "            og_img = og_x\n",
        "            print(og_img.shape)\n",
        "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
        "\n",
        "            og_img = og_img.to('cpu')\n",
        "            blurry_imgs = X_ts[0].to('cpu')\n",
        "            deblurry_imgs = X_0s[-1].to('cpu')\n",
        "            direct_deblurry_imgs = X_0s[0].to('cpu')\n",
        "\n",
        "            og_img = og_img.repeat(1, 3 // og_img.shape[1], 1, 1)\n",
        "            blurry_imgs = blurry_imgs.repeat(1, 3 // blurry_imgs.shape[1], 1, 1)\n",
        "            deblurry_imgs = deblurry_imgs.repeat(1, 3 // deblurry_imgs.shape[1], 1, 1)\n",
        "            direct_deblurry_imgs = direct_deblurry_imgs.repeat(1, 3 // direct_deblurry_imgs.shape[1], 1, 1)\n",
        "\n",
        "\n",
        "\n",
        "            og_img = (og_img + 1) * 0.5\n",
        "            blurry_imgs = (blurry_imgs + 1) * 0.5\n",
        "            deblurry_imgs = (deblurry_imgs + 1) * 0.5\n",
        "            direct_deblurry_imgs = (direct_deblurry_imgs + 1) * 0.5\n",
        "\n",
        "            if cnt == 0:\n",
        "                print(og_img.shape)\n",
        "                print(blurry_imgs.shape)\n",
        "                print(deblurry_imgs.shape)\n",
        "                print(direct_deblurry_imgs.shape)\n",
        "\n",
        "                if sanity_check:\n",
        "                    folder = './sanity_check/'\n",
        "                    create_folder(folder)\n",
        "\n",
        "                    san_imgs = og_img[0: 32]\n",
        "                    utils.save_image(san_imgs,str(folder + f'sample-og.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = blurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-xt.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-recons.png'), nrow=6)\n",
        "\n",
        "                    san_imgs = direct_deblurry_imgs[0: 32]\n",
        "                    utils.save_image(san_imgs, str(folder + f'sample-direct-recons.png'), nrow=6)\n",
        "\n",
        "\n",
        "            if blurred_samples is None:\n",
        "                blurred_samples = blurry_imgs\n",
        "            else:\n",
        "                blurred_samples = torch.cat((blurred_samples, blurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if original_sample is None:\n",
        "                original_sample = og_img\n",
        "            else:\n",
        "                original_sample = torch.cat((original_sample, og_img), dim=0)\n",
        "\n",
        "\n",
        "            if deblurred_samples is None:\n",
        "                deblurred_samples = deblurry_imgs\n",
        "            else:\n",
        "                deblurred_samples = torch.cat((deblurred_samples, deblurry_imgs), dim=0)\n",
        "\n",
        "\n",
        "            if direct_deblurred_samples is None:\n",
        "                direct_deblurred_samples = direct_deblurry_imgs\n",
        "            else:\n",
        "                direct_deblurred_samples = torch.cat((direct_deblurred_samples, direct_deblurry_imgs), dim=0)\n",
        "\n",
        "            cnt += og_img.shape[0]\n",
        "\n",
        "        print(blurred_samples.shape)\n",
        "        print(original_sample.shape)\n",
        "        print(deblurred_samples.shape)\n",
        "        print(direct_deblurred_samples.shape)\n",
        "\n",
        "        fid_blur = fid_func(samples=[original_sample, blurred_samples])\n",
        "        rmse_blur = torch.sqrt(torch.mean( (original_sample - blurred_samples)**2 ))\n",
        "        ssim_blur = ssim(original_sample, blurred_samples, data_range=1, size_average=True)\n",
        "        # n_og = original_sample.cpu().detach().numpy()\n",
        "        # n_bs = blurred_samples.cpu().detach().numpy()\n",
        "        # ssim_blur = ssim(n_og, n_bs, data_range=n_og.max() - n_og.min(), multichannel=True)\n",
        "        print(f'The FID of blurry images with original image is {fid_blur}')\n",
        "        print(f'The RMSE of blurry images with original image is {rmse_blur}')\n",
        "        print(f'The SSIM of blurry images with original image is {ssim_blur}')\n",
        "\n",
        "\n",
        "        fid_deblur = fid_func(samples=[original_sample, deblurred_samples])\n",
        "        rmse_deblur = torch.sqrt(torch.mean((original_sample - deblurred_samples) ** 2))\n",
        "        ssim_deblur = ssim(original_sample, deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of deblurred images with original image is {fid_deblur}')\n",
        "        print(f'The RMSE of deblurred images with original image is {rmse_deblur}')\n",
        "        print(f'The SSIM of deblurred images with original image is {ssim_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using sampling is {fid_blur - fid_deblur}')\n",
        "\n",
        "        fid_direct_deblur = fid_func(samples=[original_sample, direct_deblurred_samples])\n",
        "        rmse_direct_deblur = torch.sqrt(torch.mean((original_sample - direct_deblurred_samples) ** 2))\n",
        "        ssim_direct_deblur = ssim(original_sample, direct_deblurred_samples, data_range=1, size_average=True)\n",
        "        print(f'The FID of direct deblurred images with original image is {fid_direct_deblur}')\n",
        "        print(f'The RMSE of direct deblurred images with original image is {rmse_direct_deblur}')\n",
        "        print(f'The SSIM of direct deblurred images with original image is {ssim_direct_deblur}')\n",
        "\n",
        "        print(f'Hence the improvement in FID using direct sampling is {fid_blur - fid_direct_deblur}')\n",
        "\n",
        "\n",
        "            # x0s = X_0s[-1]\n",
        "            # for i in range(x0s.shape[0]):\n",
        "            #     utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
        "            #     cnt += 1\n",
        "\n",
        "    def save_training_data(self):\n",
        "        dataset = self.ds\n",
        "        create_folder(f'{self.results_folder}/')\n",
        "\n",
        "        print(len(dataset))\n",
        "        for idx in range(len(dataset)):\n",
        "            img = dataset[idx]\n",
        "            img = (img + 1) * 0.5\n",
        "            utils.save_image(img, str(f'{self.results_folder}/' + f'{idx}.png'))\n",
        "            if idx%1000 == 0:\n",
        "                print(idx)\n"
      ],
      "metadata": {
        "id": "4hgyDc1rCw48"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_folder(path):\n",
        "    try:\n",
        "        os.mkdir(path)\n",
        "    except OSError as exc:\n",
        "        if exc.errno != errno.EEXIST:\n",
        "            raise\n",
        "        pass\n",
        "\n",
        "def del_folder(path):\n",
        "    try:\n",
        "        shutil.rmtree(path)\n",
        "    except OSError as exc:\n",
        "        pass"
      ],
      "metadata": {
        "id": "-19g6V5vCzAZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg --configure -a\n",
        "!apt-get update\n",
        "!apt-get install ffmpeg libsm6 libxext6  -y\n",
        "!pip install opencv-python --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIhrTmzpDZ2y",
        "outputId": "564780f2-373e-4a15-e44e-a5507d89e4bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [985 kB]\n",
            "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,554 kB]\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,332 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,035 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,467 kB]\n",
            "Fetched 11.6 MB in 3s (3,589 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsm6 is already the newest version (2:1.2.2-1).\n",
            "libxext6 is already the newest version (2:1.3.3-1).\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19TZEOKBCjqF",
        "outputId": "53567463-5bfc-4c88-a963-dcfa1feb9df1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Time embed used ?  False\n",
            "HH\n",
            "Loading :  model_100000HH.pt\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "create_folder(\"./results_celebA_testHH_new\")\n",
        "\n",
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA_testHH_new\"\n",
        "data_path=\"./root_celebA_128_train/\"\n",
        "load_path=\"model_100000HH.pt\"\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "test_type = 'train_paper_showing_diffusion_images_cover_page'\n",
        " \n",
        "img_path = data_path\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine = train_routine,\n",
        "    sampling_routine = sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    img_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps = train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder = save_folder,\n",
        "    load_path = load_path,\n",
        "    dataset = 'HH',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_type == 'train_data':\n",
        "    trainer.test_from_data('train', s_times=time_steps)\n",
        "\n",
        "elif test_type == 'test_data':\n",
        "    trainer.test_from_data('test', s_times=time_steps)\n",
        "\n",
        "#### for FID and noise ablation ##\n",
        "elif test_type == 'test_sample_and_save_for_fid':\n",
        "    trainer.sample_and_save_for_fid()\n",
        "\n",
        "########## for paper ##########\n",
        "\n",
        "elif test_type == 'train_paper_showing_diffusion_images_cover_page':\n",
        "    trainer.paper_showing_diffusion_images_cover_page()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(\"./results_celebA_testHL_new\")\n",
        "\n",
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA_testHL_new\"\n",
        "data_path=\"./root_celebA_128_train/\"\n",
        "load_path=\"model_100000HL.pt\"\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "test_type = 'train_paper_showing_diffusion_images_cover_page'\n",
        " \n",
        "img_path = data_path\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine = train_routine,\n",
        "    sampling_routine = sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    img_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps = train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder = save_folder,\n",
        "    load_path = load_path,\n",
        "    dataset = 'HL',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_type == 'train_data':\n",
        "    trainer.test_from_data('train', s_times=time_steps)\n",
        "\n",
        "elif test_type == 'test_data':\n",
        "    trainer.test_from_data('test', s_times=time_steps)\n",
        "\n",
        "#### for FID and noise ablation ##\n",
        "elif test_type == 'test_sample_and_save_for_fid':\n",
        "    trainer.sample_and_save_for_fid()\n",
        "\n",
        "########## for paper ##########\n",
        "\n",
        "elif test_type == 'train_paper_showing_diffusion_images_cover_page':\n",
        "    trainer.paper_showing_diffusion_images_cover_page()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zlk7d_HB2pC7",
        "outputId": "dced4539-4868-48f1-fa19-05fa21e6fba2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Time embed used ?  False\n",
            "HL\n",
            "Loading :  model_100000HL.pt\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(\"./results_celebA_testLH_new\")\n",
        "\n",
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA_testLH_new\"\n",
        "data_path=\"./root_celebA_128_train/\"\n",
        "load_path=\"model_100000LH.pt\"\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "test_type = 'train_paper_showing_diffusion_images_cover_page'\n",
        " \n",
        "img_path = data_path\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine = train_routine,\n",
        "    sampling_routine = sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    img_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps = train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder = save_folder,\n",
        "    load_path = load_path,\n",
        "    dataset = 'LH',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_type == 'train_data':\n",
        "    trainer.test_from_data('train', s_times=time_steps)\n",
        "\n",
        "elif test_type == 'test_data':\n",
        "    trainer.test_from_data('test', s_times=time_steps)\n",
        "\n",
        "#### for FID and noise ablation ##\n",
        "elif test_type == 'test_sample_and_save_for_fid':\n",
        "    trainer.sample_and_save_for_fid()\n",
        "\n",
        "########## for paper ##########\n",
        "\n",
        "elif test_type == 'train_paper_showing_diffusion_images_cover_page':\n",
        "    trainer.paper_showing_diffusion_images_cover_page()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iVr7q8P2uj3",
        "outputId": "0d7e1e30-9db3-4339-f39b-420006b2235c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Time embed used ?  False\n",
            "LH\n",
            "Loading :  model_100000LH.pt\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "create_folder(\"./results_celebA_testLL_new\")\n",
        "\n",
        "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
        "train_steps=200000 #\"The number of iterations for training\"\n",
        "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
        "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
        "save_folder=\"./results_celebA_testLL_new\"\n",
        "data_path=\"./root_celebA_128_train/\"\n",
        "load_path=\"model_100000LL.pt\"\n",
        "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
        "train_routine='Final'\n",
        "#resolution_routine='Incremental_factor_2'\n",
        "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
        "discrete=\"store_true\"\n",
        "image_size=32\n",
        "batch_size=32\n",
        "remove_time_embed=\"store_true\"\n",
        "residual=\"store_true\"\n",
        "da='celebA'\n",
        "test_type = 'train_paper_showing_diffusion_images_cover_page'\n",
        " \n",
        "img_path = data_path\n",
        "\n",
        "model = Unet(\n",
        "    dim = 64,\n",
        "    dim_mults = (1, 2, 4, 8),\n",
        "    channels=3,\n",
        "    with_time_emb=not(remove_time_embed),\n",
        "    residual=residual\n",
        ").cuda()\n",
        "\n",
        "diffusion = GaussianDiffusion(\n",
        "    model,\n",
        "    image_size = 64,\n",
        "    channels = 3,\n",
        "    timesteps = time_steps,   # number of steps\n",
        "    loss_type = 'l1',    # L1 or L2\n",
        "    train_routine = train_routine,\n",
        "    sampling_routine = sampling_routine\n",
        ").cuda()\n",
        "\n",
        "import torch\n",
        "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    diffusion,\n",
        "    img_path,\n",
        "    image_size = 64,\n",
        "    train_batch_size = 32,\n",
        "    train_lr = 2e-5,\n",
        "    train_num_steps = train_steps,         # total training steps\n",
        "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
        "    ema_decay = 0.995,                # exponential moving average decay\n",
        "    fp16 = False,                       # turn on mixed precision training with apex\n",
        "    results_folder = save_folder,\n",
        "    load_path = load_path,\n",
        "    dataset = 'LL',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "if test_type == 'train_data':\n",
        "    trainer.test_from_data('train', s_times=time_steps)\n",
        "\n",
        "elif test_type == 'test_data':\n",
        "    trainer.test_from_data('test', s_times=time_steps)\n",
        "\n",
        "#### for FID and noise ablation ##\n",
        "elif test_type == 'test_sample_and_save_for_fid':\n",
        "    trainer.sample_and_save_for_fid()\n",
        "\n",
        "########## for paper ##########\n",
        "\n",
        "elif test_type == 'train_paper_showing_diffusion_images_cover_page':\n",
        "    trainer.paper_showing_diffusion_images_cover_page()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKs0JzpR23aR",
        "outputId": "fcb11da9-febf-400c-9d1c-b0183b6d906d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Time embed used ?  False\n",
            "LL\n",
            "Loading :  model_100000LL.pt\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n",
            "torch.Size([32, 3, 64, 64])\n"
          ]
        }
      ]
    }
  ]
}