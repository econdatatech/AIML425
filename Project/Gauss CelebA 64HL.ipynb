{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145012dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Cold-Diffusion-Models'...\n",
      "remote: Enumerating objects: 262, done.\u001b[K\n",
      "remote: Counting objects: 100% (66/66), done.\u001b[K\n",
      "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
      "remote: Total 262 (delta 47), reused 38 (delta 33), pack-reused 196\u001b[K\n",
      "Receiving objects: 100% (262/262), 2.65 MiB | 20.27 MiB/s, done.\n",
      "Resolving deltas: 100% (152/152), done.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 40 not upgraded.\n",
      "Need to get 168 kB of archives.\n",
      "After this operation, 567 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 unzip amd64 6.0-21ubuntu1.2 [168 kB]\n",
      "Fetched 168 kB in 0s (352 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 12682 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-21ubuntu1.2_amd64.deb ...\n",
      "Unpacking unzip (6.0-21ubuntu1.2) ...\n",
      "Setting up unzip (6.0-21ubuntu1.2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/arpitbansal297/Cold-Diffusion-Models.git\n",
    "!apt-get install unzip\n",
    "!unzip -q -j HL.zip -d ./root_celebA_128_train_new_HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22708788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install comet_ml einops tqdm torchgeometry matplotlib einops scikit-image sklearn pywavelets --quiet\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "import pywt\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/')\n",
    "from comet_ml import Experiment\n",
    "import torchvision\n",
    "import os\n",
    "import errno\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c9d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load 'Cold-Diffusion-Models/denoising-diffusion-pytorch/denoising_diffusion_pytorch/denoising_diffusion_pytorch.py'\n",
    "from comet_ml import Experiment\n",
    "import math\n",
    "import copy\n",
    "import torch\n",
    "from torch import nn, einsum\n",
    "import torch.nn.functional as F\n",
    "from inspect import isfunction\n",
    "from functools import partial\n",
    "\n",
    "from torch.utils import data\n",
    "from pathlib import Path\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms, utils\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "import torchgeometry as tgm\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch import linalg as LA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "    APEX_AVAILABLE = True\n",
    "except:\n",
    "    APEX_AVAILABLE = False\n",
    "\n",
    "# helpers functions\n",
    "\n",
    "def exists(x):\n",
    "    return x is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def cycle(dl):\n",
    "    while True:\n",
    "        for data in dl:\n",
    "            yield data\n",
    "\n",
    "def num_to_groups(num, divisor):\n",
    "    groups = num // divisor\n",
    "    remainder = num % divisor\n",
    "    arr = [divisor] * groups\n",
    "    if remainder > 0:\n",
    "        arr.append(remainder)\n",
    "    return arr\n",
    "\n",
    "def loss_backwards(fp16, loss, optimizer, **kwargs):\n",
    "    if fp16:\n",
    "        with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward(**kwargs)\n",
    "    else:\n",
    "        loss.backward(**kwargs)\n",
    "\n",
    "# small helper modules\n",
    "\n",
    "class EMA():\n",
    "    def __init__(self, beta):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "\n",
    "    def update_model_average(self, ma_model, current_model):\n",
    "        for current_params, ma_params in zip(current_model.parameters(), ma_model.parameters()):\n",
    "            old_weight, up_weight = ma_params.data, current_params.data\n",
    "            ma_params.data = self.update_average(old_weight, up_weight)\n",
    "\n",
    "    def update_average(self, old, new):\n",
    "        if old is None:\n",
    "            return new\n",
    "        return old * self.beta + (1 - self.beta) * new\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, *args, **kwargs):\n",
    "        return self.fn(x, *args, **kwargs) + x\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb\n",
    "\n",
    "def Upsample(dim):\n",
    "    return nn.ConvTranspose2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "def Downsample(dim):\n",
    "    return nn.Conv2d(dim, dim, 4, 2, 1)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, dim, eps = 1e-5):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
    "        self.b = nn.Parameter(torch.zeros(1, dim, 1, 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
    "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
    "        return (x - mean) / (var + self.eps).sqrt() * self.g + self.b\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "        self.norm = LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "        return self.fn(x)\n",
    "\n",
    "# building block modules\n",
    "\n",
    "class ConvNextBlock(nn.Module):\n",
    "    \"\"\" https://arxiv.org/abs/2201.03545 \"\"\"\n",
    "\n",
    "    def __init__(self, dim, dim_out, *, time_emb_dim = None, mult = 2, norm = True):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.GELU(),\n",
    "            nn.Linear(time_emb_dim, dim)\n",
    "        ) if exists(time_emb_dim) else None\n",
    "\n",
    "        self.ds_conv = nn.Conv2d(dim, dim, 7, padding = 3, groups = dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            LayerNorm(dim) if norm else nn.Identity(),\n",
    "            nn.Conv2d(dim, dim_out * mult, 3, padding = 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dim_out * mult, dim_out, 3, padding = 1)\n",
    "        )\n",
    "\n",
    "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x, time_emb = None):\n",
    "        h = self.ds_conv(x)\n",
    "\n",
    "        if exists(self.mlp):\n",
    "            assert exists(time_emb), 'time emb must be passed in'\n",
    "            condition = self.mlp(time_emb)\n",
    "            h = h + rearrange(condition, 'b c -> b c 1 1')\n",
    "\n",
    "        h = self.net(h)\n",
    "        return h + self.res_conv(x)\n",
    "\n",
    "class LinearAttention(nn.Module):\n",
    "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
    "        super().__init__()\n",
    "        self.scale = dim_head ** -0.5\n",
    "        self.heads = heads\n",
    "        hidden_dim = dim_head * heads\n",
    "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
    "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
    "        q = q * self.scale\n",
    "\n",
    "        k = k.softmax(dim = -1)\n",
    "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
    "\n",
    "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
    "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
    "        return self.to_out(out)\n",
    "\n",
    "# model\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        out_dim = None,\n",
    "        dim_mults=(1, 2, 4, 8),\n",
    "        channels = 3,\n",
    "        with_time_emb = True,\n",
    "        residual = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.residual = residual\n",
    "        print(\"Is Time embed used ? \", with_time_emb)\n",
    "\n",
    "        dims = [channels, *map(lambda m: dim * m, dim_mults)]\n",
    "        in_out = list(zip(dims[:-1], dims[1:]))\n",
    "\n",
    "        if with_time_emb:\n",
    "            time_dim = dim\n",
    "            self.time_mlp = nn.Sequential(\n",
    "                SinusoidalPosEmb(dim),\n",
    "                nn.Linear(dim, dim * 4),\n",
    "                nn.GELU(),\n",
    "                nn.Linear(dim * 4, dim)\n",
    "            )\n",
    "        else:\n",
    "            time_dim = None\n",
    "            self.time_mlp = None\n",
    "\n",
    "        self.downs = nn.ModuleList([])\n",
    "        self.ups = nn.ModuleList([])\n",
    "        num_resolutions = len(in_out)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.downs.append(nn.ModuleList([\n",
    "                ConvNextBlock(dim_in, dim_out, time_emb_dim = time_dim, norm = ind != 0),\n",
    "                ConvNextBlock(dim_out, dim_out, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
    "                Downsample(dim_out) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        mid_dim = dims[-1]\n",
    "        self.mid_block1 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "        self.mid_attn = Residual(PreNorm(mid_dim, LinearAttention(mid_dim)))\n",
    "        self.mid_block2 = ConvNextBlock(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
    "\n",
    "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
    "            is_last = ind >= (num_resolutions - 1)\n",
    "\n",
    "            self.ups.append(nn.ModuleList([\n",
    "                ConvNextBlock(dim_out * 2, dim_in, time_emb_dim = time_dim),\n",
    "                ConvNextBlock(dim_in, dim_in, time_emb_dim = time_dim),\n",
    "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
    "                Upsample(dim_in) if not is_last else nn.Identity()\n",
    "            ]))\n",
    "\n",
    "        out_dim = default(out_dim, channels)\n",
    "        self.final_conv = nn.Sequential(\n",
    "            ConvNextBlock(dim, dim),\n",
    "            nn.Conv2d(dim, out_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, time):\n",
    "        orig_x = x\n",
    "        t = self.time_mlp(time) if exists(self.time_mlp) else None\n",
    "\n",
    "        h = []\n",
    "\n",
    "        for convnext, convnext2, attn, downsample in self.downs:\n",
    "            x = convnext(x, t)\n",
    "            x = convnext2(x, t)\n",
    "            x = attn(x)\n",
    "            h.append(x)\n",
    "            x = downsample(x)\n",
    "\n",
    "        x = self.mid_block1(x, t)\n",
    "        x = self.mid_attn(x)\n",
    "        x = self.mid_block2(x, t)\n",
    "\n",
    "        for convnext, convnext2, attn, upsample in self.ups:\n",
    "            x = torch.cat((x, h.pop()), dim=1)\n",
    "            x = convnext(x, t)\n",
    "            x = convnext2(x, t)\n",
    "            x = attn(x)\n",
    "            x = upsample(x)\n",
    "        if self.residual:\n",
    "            return self.final_conv(x) + orig_x\n",
    "\n",
    "        return self.final_conv(x)\n",
    "\n",
    "# gaussian diffusion trainer class\n",
    "\n",
    "def extract(a, t, x_shape):\n",
    "    b, *_ = t.shape\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "def noise_like(shape, device, repeat=False):\n",
    "    repeat_noise = lambda: torch.randn((1, *shape[1:]), device=device).repeat(shape[0], *((1,) * (len(shape) - 1)))\n",
    "    noise = lambda: torch.randn(shape, device=device)\n",
    "    return repeat_noise() if repeat else noise()\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s = 0.008):\n",
    "    \"\"\"\n",
    "    cosine schedule\n",
    "    as proposed in https://openreview.net/forum?id=-NEXDKk8gZ\n",
    "    \"\"\"\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, steps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / steps) + s) / (1 + s) * torch.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0, 0.999)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "class GaussianDiffusion(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        denoise_fn,\n",
    "        *,\n",
    "        image_size,\n",
    "        channels = 3,\n",
    "        timesteps = 1000,\n",
    "        loss_type = 'l1',\n",
    "        train_routine = 'Final',\n",
    "        sampling_routine='default',\n",
    "        discrete=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.image_size = image_size\n",
    "        self.denoise_fn = denoise_fn\n",
    "\n",
    "        self.num_timesteps = int(timesteps)\n",
    "        self.loss_type = loss_type\n",
    "\n",
    "        betas = cosine_beta_schedule(timesteps)\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "\n",
    "        self.register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "\n",
    "        self.train_routine = train_routine\n",
    "        self.sampling_routine = sampling_routine\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size = 16, img=None, t=None):\n",
    "\n",
    "        self.denoise_fn.eval()\n",
    "        if t == None:\n",
    "            t = self.num_timesteps\n",
    "\n",
    "        xt = img\n",
    "        direct_recons = None\n",
    "\n",
    "        while (t):\n",
    "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
    "            x1_bar = self.denoise_fn(img, step)\n",
    "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
    "\n",
    "            if direct_recons is None:\n",
    "                direct_recons = x1_bar\n",
    "\n",
    "            xt_bar = x1_bar\n",
    "            if t != 0:\n",
    "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
    "\n",
    "            xt_sub1_bar = x1_bar\n",
    "            if t - 1 != 0:\n",
    "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
    "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
    "\n",
    "            x = img - xt_bar + xt_sub1_bar\n",
    "            img = x\n",
    "            t = t - 1\n",
    "\n",
    "        self.denoise_fn.train()\n",
    "\n",
    "        return xt, direct_recons, img\n",
    "\n",
    "    def get_x2_bar_from_xt(self, x1_bar, xt, t):\n",
    "        return (\n",
    "                (xt - extract(self.sqrt_alphas_cumprod, t, x1_bar.shape) * x1_bar) /\n",
    "                extract(self.sqrt_one_minus_alphas_cumprod, t, x1_bar.shape)\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def gen_sample(self, batch_size=16, img=None, t=None):\n",
    "        self.denoise_fn.eval()\n",
    "        if t == None:\n",
    "            t = self.num_timesteps\n",
    "\n",
    "        noise = img\n",
    "        direct_recons = None\n",
    "\n",
    "        if self.sampling_routine == 'ddim':\n",
    "            while (t):\n",
    "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
    "                x1_bar = self.denoise_fn(img, step)\n",
    "                x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
    "                if direct_recons == None:\n",
    "                    direct_recons = x1_bar\n",
    "\n",
    "                xt_bar = x1_bar\n",
    "                if t != 0:\n",
    "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
    "\n",
    "                xt_sub1_bar = x1_bar\n",
    "                if t - 1 != 0:\n",
    "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
    "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
    "\n",
    "                x = img - xt_bar + xt_sub1_bar\n",
    "                img = x\n",
    "                t = t - 1\n",
    "\n",
    "        elif self.sampling_routine == 'x0_step_down':\n",
    "            while (t):\n",
    "                step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
    "                x1_bar = self.denoise_fn(img, step)\n",
    "                x2_bar = noise\n",
    "                if direct_recons == None:\n",
    "                    direct_recons = x1_bar\n",
    "\n",
    "                xt_bar = x1_bar\n",
    "                if t != 0:\n",
    "                    xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
    "\n",
    "                xt_sub1_bar = x1_bar\n",
    "                if t - 1 != 0:\n",
    "                    step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
    "                    xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
    "\n",
    "                x = img - xt_bar + xt_sub1_bar\n",
    "                img = x\n",
    "                t = t - 1\n",
    "\n",
    "        return noise, direct_recons, img\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward_and_backward(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
    "\n",
    "        self.denoise_fn.eval()\n",
    "\n",
    "        if t == None:\n",
    "            t = self.num_timesteps\n",
    "\n",
    "        Forward = []\n",
    "        Forward.append(img)\n",
    "\n",
    "        noise = torch.randn_like(img)\n",
    "\n",
    "        for i in range(t):\n",
    "            with torch.no_grad():\n",
    "                step = torch.full((batch_size,), i, dtype=torch.long, device=img.device)\n",
    "                n_img = self.q_sample(x_start=img, x_end=noise, t=step)\n",
    "                Forward.append(n_img)\n",
    "\n",
    "        Backward = []\n",
    "        img = n_img\n",
    "        while (t):\n",
    "            step = torch.full((batch_size,), t - 1, dtype=torch.long, device=img.device)\n",
    "            x1_bar = self.denoise_fn(img, step)\n",
    "            x2_bar = noise #self.get_x2_bar_from_xt(x1_bar, img, step)\n",
    "\n",
    "            Backward.append(img)\n",
    "\n",
    "            xt_bar = x1_bar\n",
    "            if t != 0:\n",
    "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
    "\n",
    "            xt_sub1_bar = x1_bar\n",
    "            if t - 1 != 0:\n",
    "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long, device=img.device)\n",
    "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
    "\n",
    "            x = img - xt_bar + xt_sub1_bar\n",
    "            img = x\n",
    "            t = t - 1\n",
    "\n",
    "        return Forward, Backward, img\n",
    "\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def all_sample(self, batch_size=16, img=None, t=None, times=None, eval=True):\n",
    "\n",
    "        if eval:\n",
    "            self.denoise_fn.eval()\n",
    "\n",
    "        if t == None:\n",
    "            t = self.num_timesteps\n",
    "\n",
    "        X1_0s, X2_0s, X_ts = [], [], []\n",
    "        while (t):\n",
    "\n",
    "            step = torch.full((batch_size,), t - 1, dtype=torch.long).cuda()\n",
    "            x1_bar = self.denoise_fn(img, step)\n",
    "            x2_bar = self.get_x2_bar_from_xt(x1_bar, img, step)\n",
    "\n",
    "\n",
    "            X1_0s.append(x1_bar.detach().cpu())\n",
    "            X2_0s.append(x2_bar.detach().cpu())\n",
    "            X_ts.append(img.detach().cpu())\n",
    "\n",
    "            xt_bar = x1_bar\n",
    "            if t != 0:\n",
    "                xt_bar = self.q_sample(x_start=xt_bar, x_end=x2_bar, t=step)\n",
    "\n",
    "            xt_sub1_bar = x1_bar\n",
    "            if t - 1 != 0:\n",
    "                step2 = torch.full((batch_size,), t - 2, dtype=torch.long).cuda()\n",
    "                xt_sub1_bar = self.q_sample(x_start=xt_sub1_bar, x_end=x2_bar, t=step2)\n",
    "\n",
    "            x = img - xt_bar + xt_sub1_bar\n",
    "            img = x\n",
    "            t = t - 1\n",
    "\n",
    "        return X1_0s, X2_0s, X_ts\n",
    "\n",
    "    def q_sample(self, x_start, x_end, t):\n",
    "        # simply use the alphas to interpolate\n",
    "        return (\n",
    "                extract(self.sqrt_alphas_cumprod, t, x_start.shape) * x_start +\n",
    "                extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * x_end\n",
    "        )\n",
    "\n",
    "    def p_losses(self, x_start, x_end, t):\n",
    "        b, c, h, w = x_start.shape\n",
    "        if self.train_routine == 'Final':\n",
    "            x_mix = self.q_sample(x_start=x_start, x_end=x_end, t=t)\n",
    "            x_recon = self.denoise_fn(x_mix, t)\n",
    "            if self.loss_type == 'l1':\n",
    "                loss = (x_start - x_recon).abs().mean()\n",
    "            elif self.loss_type == 'l2':\n",
    "                loss = F.mse_loss(x_start, x_recon)\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def forward(self, x1, x2, *args, **kwargs):\n",
    "        b, c, h, w, device, img_size, = *x1.shape, x1.device, self.image_size\n",
    "        assert h == img_size and w == img_size, f'height and width of image must be {img_size}'\n",
    "        t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n",
    "        return self.p_losses(x1, x2, t, *args, **kwargs)\n",
    "\n",
    "class Dataset_Aug1(data.Dataset):\n",
    "    def __init__(self, folder, image_size, exts = ['jpg', 'jpeg', 'png','bmp']):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
    "            transforms.RandomCrop(image_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        return self.transform(img)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, folder, image_size, exts=['jpg', 'jpeg', 'png','bmp']):\n",
    "        super().__init__()\n",
    "        self.folder = folder\n",
    "        self.image_size = image_size\n",
    "        self.paths = [p for ext in exts for p in Path(f'{folder}').glob(f'**/*.{ext}')]\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((int(image_size*1.12), int(image_size*1.12))),\n",
    "            transforms.CenterCrop(image_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.paths[index]\n",
    "        img = Image.open(path)\n",
    "        img = img.convert('RGB')\n",
    "        return self.transform(img)\n",
    "# trainer class\n",
    "import os\n",
    "import errno\n",
    "def create_folder(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "        pass\n",
    "\n",
    "from collections import OrderedDict\n",
    "def remove_data_parallel(old_state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in old_state_dict.items():\n",
    "        name = k.replace('.module', '')  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "def adjust_data_parallel(old_state_dict):\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in old_state_dict.items():\n",
    "        name = k.replace('denoise_fn.module', 'module.denoise_fn')  # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffusion_model,\n",
    "        folder,\n",
    "        *,\n",
    "        ema_decay = 0.995,\n",
    "        image_size = 128,\n",
    "        train_batch_size = 32,\n",
    "        train_lr = 2e-5,\n",
    "        train_num_steps = 100000,\n",
    "        gradient_accumulate_every = 2,\n",
    "        fp16 = False,\n",
    "        step_start_ema = 2000,\n",
    "        update_ema_every = 10,\n",
    "        save_and_sample_every = 1000,\n",
    "        results_folder = './results',\n",
    "        load_path = None,\n",
    "        dataset = None,\n",
    "        shuffle=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = diffusion_model\n",
    "        self.ema = EMA(ema_decay)\n",
    "        self.ema_model = copy.deepcopy(self.model)\n",
    "        self.update_ema_every = update_ema_every\n",
    "\n",
    "        self.step_start_ema = step_start_ema\n",
    "        self.save_and_sample_every = save_and_sample_every\n",
    "\n",
    "        self.batch_size = train_batch_size\n",
    "        self.image_size = image_size\n",
    "        self.gradient_accumulate_every = gradient_accumulate_every\n",
    "        self.train_num_steps = train_num_steps\n",
    "\n",
    "        if dataset == 'train':\n",
    "            print(dataset, \"DA used\")\n",
    "            self.ds = Dataset_Aug1(folder, image_size)\n",
    "        else:\n",
    "            print(dataset)\n",
    "            self.ds = Dataset(folder, image_size)\n",
    "\n",
    "        self.dl = cycle(data.DataLoader(self.ds, batch_size = train_batch_size, shuffle=shuffle, pin_memory=True, num_workers=16, drop_last=True))\n",
    "\n",
    "        self.opt = Adam(diffusion_model.parameters(), lr=train_lr)\n",
    "        self.step = 0\n",
    "\n",
    "        self.results_folder = Path(results_folder)\n",
    "        self.results_folder.mkdir(exist_ok = True)\n",
    "\n",
    "        self.fp16 = fp16\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "        if load_path != None:\n",
    "            self.load(load_path)\n",
    "\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.ema_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "    def step_ema(self):\n",
    "        if self.step < self.step_start_ema:\n",
    "            self.reset_parameters()\n",
    "            return\n",
    "        self.ema.update_model_average(self.ema_model, self.model)\n",
    "\n",
    "    def save(self, itrs=None):\n",
    "        data = {\n",
    "            'step': self.step,\n",
    "            'model': self.model.state_dict(),\n",
    "            'ema': self.ema_model.state_dict()\n",
    "        }\n",
    "        if itrs is None:\n",
    "            torch.save(data, str(self.results_folder / f'model.pt'))\n",
    "        else:\n",
    "            torch.save(data, str(self.results_folder / f'model_{itrs}.pt'))\n",
    "\n",
    "    def load(self, load_path):\n",
    "        print(\"Loading : \", load_path)\n",
    "        data = torch.load(load_path)\n",
    "\n",
    "        self.step = data['step']\n",
    "        self.model.load_state_dict(data['model'])\n",
    "        self.ema_model.load_state_dict(data['ema'])\n",
    "\n",
    "\n",
    "    def add_title(self, path, title):\n",
    "\n",
    "        import cv2\n",
    "        import numpy as np\n",
    "\n",
    "        img1 = cv2.imread(path)\n",
    "\n",
    "        # --- Here I am creating the border---\n",
    "        black = [0, 0, 0]  # ---Color of the border---\n",
    "        constant = cv2.copyMakeBorder(img1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "        height = 20\n",
    "        violet = np.zeros((height, constant.shape[1], 3), np.uint8)\n",
    "        violet[:] = (255, 0, 180)\n",
    "\n",
    "        vcat = cv2.vconcat((violet, constant))\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        cv2.putText(vcat, str(title), (violet.shape[1] // 2, height-2), font, 0.5, (0, 0, 0), 1, 0)\n",
    "        cv2.imwrite(path, vcat)\n",
    "\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        backwards = partial(loss_backwards, self.fp16)\n",
    "\n",
    "        acc_loss = 0\n",
    "        while self.step < self.train_num_steps:\n",
    "            u_loss = 0\n",
    "            for i in range(self.gradient_accumulate_every):\n",
    "                data_1 = next(self.dl)\n",
    "                data_2 = torch.randn_like(data_1)\n",
    "\n",
    "                data_1, data_2 = data_1.cuda(), data_2.cuda()\n",
    "                loss = torch.mean(self.model(data_1, data_2))\n",
    "                if self.step % 100 == 0:\n",
    "                    print(f'{self.step}: {loss.item()}')\n",
    "                u_loss += loss.item()\n",
    "                backwards(loss / self.gradient_accumulate_every, self.opt)\n",
    "\n",
    "            acc_loss = acc_loss + (u_loss/self.gradient_accumulate_every)\n",
    "\n",
    "            self.opt.step()\n",
    "            self.opt.zero_grad()\n",
    "\n",
    "            if self.step % self.update_ema_every == 0:\n",
    "                self.step_ema()\n",
    "\n",
    "            if self.step != 0 and self.step % self.save_and_sample_every == 0:\n",
    "                milestone = self.step // self.save_and_sample_every\n",
    "                batches = self.batch_size\n",
    "\n",
    "                data_1 = next(self.dl)\n",
    "                data_2 = torch.randn_like(data_1)\n",
    "                og_img = data_2.cuda()\n",
    "\n",
    "                xt, direct_recons, all_images = self.ema_model.module.sample(batch_size=batches, img=og_img)\n",
    "\n",
    "                og_img = (og_img + 1) * 0.5\n",
    "                utils.save_image(og_img, str(self.results_folder / f'sample-og-{milestone}.png'), nrow=6)\n",
    "\n",
    "                all_images = (all_images + 1) * 0.5\n",
    "                utils.save_image(all_images, str(self.results_folder / f'sample-recon-{milestone}.png'), nrow = 6)\n",
    "\n",
    "                direct_recons = (direct_recons + 1) * 0.5\n",
    "                utils.save_image(direct_recons, str(self.results_folder / f'sample-direct_recons-{milestone}.png'), nrow=6)\n",
    "\n",
    "                xt = (xt + 1) * 0.5\n",
    "                utils.save_image(xt, str(self.results_folder / f'sample-xt-{milestone}.png'),\n",
    "                                 nrow=6)\n",
    "\n",
    "                acc_loss = acc_loss/(self.save_and_sample_every+1)\n",
    "                print(f'Mean of last {self.step}: {acc_loss}')\n",
    "                acc_loss=0\n",
    "\n",
    "                self.save()\n",
    "                if self.step % (self.save_and_sample_every * 100) == 0:\n",
    "                    self.save(self.step)\n",
    "\n",
    "            self.step += 1\n",
    "\n",
    "        print('training completed')\n",
    "\n",
    "    def test_from_data(self, extra_path, s_times=None):\n",
    "        batches = self.batch_size\n",
    "        og_img = next(self.dl).cuda()\n",
    "        X_0s, X_ts = self.ema_model.module.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
    "\n",
    "        og_img = (og_img + 1) * 0.5\n",
    "        utils.save_image(og_img, str(self.results_folder / f'og-{extra_path}.png'), nrow=6)\n",
    "\n",
    "        import imageio\n",
    "        frames_t = []\n",
    "        frames_0 = []\n",
    "\n",
    "        for i in range(len(X_0s)):\n",
    "            print(i)\n",
    "\n",
    "            x_0 = X_0s[i]\n",
    "            x_0 = (x_0 + 1) * 0.5\n",
    "            utils.save_image(x_0, str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), nrow=6)\n",
    "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png'), str(i))\n",
    "            frames_0.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-x0.png')))\n",
    "\n",
    "            x_t = X_ts[i]\n",
    "            all_images = (x_t + 1) * 0.5\n",
    "            utils.save_image(all_images, str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), nrow=6)\n",
    "            self.add_title(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png'), str(i))\n",
    "            frames_t.append(imageio.imread(str(self.results_folder / f'sample-{i}-{extra_path}-xt.png')))\n",
    "\n",
    "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-x0.gif'), frames_0)\n",
    "        imageio.mimsave(str(self.results_folder / f'Gif-{extra_path}-xt.gif'), frames_t)\n",
    "\n",
    "    def sample_and_save_for_fid(self, noise=0):\n",
    "\n",
    "        # xt_folder = f'{self.results_folder}_xt'\n",
    "        # create_folder(xt_folder)\n",
    "\n",
    "        out_folder = f'{self.results_folder}_out'\n",
    "        create_folder(out_folder)\n",
    "\n",
    "        # direct_recons_folder = f'{self.results_folder}_dir_recons'\n",
    "        # create_folder(direct_recons_folder)\n",
    "\n",
    "        # data_1 = next(self.dl)\n",
    "\n",
    "        cnt = 0\n",
    "        bs = 128\n",
    "        for j in range(int(6400/bs)):\n",
    "\n",
    "            data_2 = torch.randn(bs, 3, 128, 128)\n",
    "            og_img = data_2.cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            xt, direct_recons, all_images = self.ema_model.module.gen_sample(batch_size=bs, img=og_img)\n",
    "\n",
    "            for i in range(all_images.shape[0]):\n",
    "                utils.save_image((all_images[i] + 1) * 0.5,\n",
    "                                 str(f'{out_folder}/' + f'sample-x0-{cnt}.png'))\n",
    "\n",
    "                # utils.save_image((xt[i] + 1) * 0.5,\n",
    "                #                  str(f'{xt_folder}/' + f'sample-x0-{cnt}.png'))\n",
    "                #\n",
    "                # utils.save_image((direct_recons[i] + 1) * 0.5,\n",
    "                #                  str(f'{direct_recons_folder}/' + f'sample-x0-{cnt}.png'))\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "    def paper_showing_diffusion_images_cover_page(self):\n",
    "\n",
    "        import cv2\n",
    "        cnt = 0\n",
    "        # for 200 steps\n",
    "        # to_show = [2, 4, 8, 16, 32, 64, 128, 192]\n",
    "        to_show = [2, 4, 16, 64, 128, 256, 384, 448, 480]\n",
    "\n",
    "        for i in range(5):\n",
    "            batches = self.batch_size\n",
    "            og_img = next(self.dl).cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            Forward, Backward, final_all = self.ema_model.module.forward_and_backward(batch_size=batches, img=og_img)\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "            final_all = (final_all + 1) * 0.5\n",
    "\n",
    "\n",
    "\n",
    "            for k in range(Forward[0].shape[0]):\n",
    "                l = []\n",
    "\n",
    "                utils.save_image(og_img[k], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
    "                start = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
    "                l.append(start)\n",
    "\n",
    "                for j in range(len(Forward)):\n",
    "                    x_t = Forward[j][k]\n",
    "                    x_t = (x_t + 1) * 0.5\n",
    "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
    "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
    "                    if j in to_show:\n",
    "                        l.append(x_t)\n",
    "\n",
    "                for j in range(len(Backward)):\n",
    "                    x_t = Backward[j][k]\n",
    "                    x_t = (x_t + 1) * 0.5\n",
    "                    utils.save_image(x_t, str(self.results_folder / f'temp.png'), nrow=1)\n",
    "                    x_t = cv2.imread(f'{self.results_folder}/temp.png')\n",
    "                    if (len(Backward) - j) in to_show:\n",
    "                        l.append(x_t)\n",
    "\n",
    "\n",
    "                utils.save_image(final_all[k], str(self.results_folder / f'final_{cnt}.png'), nrow=1)\n",
    "                final = cv2.imread(f'{self.results_folder}/final_{cnt}.png')\n",
    "                l.append(final)\n",
    "\n",
    "\n",
    "                im_h = cv2.hconcat(l)\n",
    "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
    "\n",
    "                cnt+=1\n",
    "\n",
    "\n",
    "    def paper_invert_section_images(self, s_times=None):\n",
    "\n",
    "        cnt = 0\n",
    "        for i in range(50):\n",
    "            batches = self.batch_size\n",
    "            og_img = next(self.dl).cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "\n",
    "            for j in range(og_img.shape[0]//3):\n",
    "                original = og_img[j: j + 1]\n",
    "                utils.save_image(original, str(self.results_folder / f'original_{cnt}.png'), nrow=3)\n",
    "\n",
    "                direct_recons = X_0s[0][j: j + 1]\n",
    "                direct_recons = (direct_recons + 1) * 0.5\n",
    "                utils.save_image(direct_recons, str(self.results_folder / f'direct_recons_{cnt}.png'), nrow=3)\n",
    "\n",
    "                sampling_recons = X_0s[-1][j: j + 1]\n",
    "                sampling_recons = (sampling_recons + 1) * 0.5\n",
    "                utils.save_image(sampling_recons, str(self.results_folder / f'sampling_recons_{cnt}.png'), nrow=3)\n",
    "\n",
    "                blurry_image = X_ts[0][j: j + 1]\n",
    "                blurry_image = (blurry_image + 1) * 0.5\n",
    "                utils.save_image(blurry_image, str(self.results_folder / f'blurry_image_{cnt}.png'), nrow=3)\n",
    "\n",
    "\n",
    "\n",
    "                import cv2\n",
    "\n",
    "                blurry_image = cv2.imread(f'{self.results_folder}/blurry_image_{cnt}.png')\n",
    "                direct_recons = cv2.imread(f'{self.results_folder}/direct_recons_{cnt}.png')\n",
    "                sampling_recons = cv2.imread(f'{self.results_folder}/sampling_recons_{cnt}.png')\n",
    "                original = cv2.imread(f'{self.results_folder}/original_{cnt}.png')\n",
    "\n",
    "                black = [0, 0, 0]\n",
    "                blurry_image = cv2.copyMakeBorder(blurry_image, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "                direct_recons = cv2.copyMakeBorder(direct_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "                sampling_recons = cv2.copyMakeBorder(sampling_recons, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "                original = cv2.copyMakeBorder(original, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "\n",
    "                im_h = cv2.hconcat([blurry_image, direct_recons, sampling_recons, original])\n",
    "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "    def paper_showing_diffusion_images(self, s_times=None):\n",
    "\n",
    "        import cv2\n",
    "        cnt = 0\n",
    "        # to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
    "        # to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
    "        # to_show = [0, 1, 2, 4, 8, 16, 24, 32, 40, 44, 46, 48, 49]\n",
    "        to_show = [0, 2, 4, 8, 16, 32, 64, 80, 88, 92, 96, 98, 99]\n",
    "\n",
    "        for i in range(50):\n",
    "            batches = self.batch_size\n",
    "            og_img = next(self.dl).cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=batches, img=og_img, times=s_times)\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "\n",
    "            for k in range(X_ts[0].shape[0]):\n",
    "                l = []\n",
    "\n",
    "                for j in range(len(X_ts)):\n",
    "                    x_t = X_ts[j][k]\n",
    "                    x_t = (x_t + 1) * 0.5\n",
    "                    utils.save_image(x_t, str(self.results_folder / f'x_{len(X_ts)-j}_{cnt}.png'), nrow=1)\n",
    "                    x_t = cv2.imread(f'{self.results_folder}/x_{len(X_ts)-j}_{cnt}.png')\n",
    "                    if j in to_show:\n",
    "                        l.append(x_t)\n",
    "\n",
    "\n",
    "                x_0 = X_0s[-1][k]\n",
    "                x_0 = (x_0 + 1) * 0.5\n",
    "                utils.save_image(x_0, str(self.results_folder / f'x_best_{cnt}.png'), nrow=1)\n",
    "                x_0 = cv2.imread(f'{self.results_folder}/x_best_{cnt}.png')\n",
    "                l.append(x_0)\n",
    "                im_h = cv2.hconcat(l)\n",
    "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
    "\n",
    "                cnt+=1\n",
    "\n",
    "\n",
    "    def paper_showing_diffusion_images_diff(self, s_times=None):\n",
    "\n",
    "        import cv2\n",
    "        for i in range(50):\n",
    "            batches = self.batch_size\n",
    "            og_img = next(self.dl).cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            X_0s_alg2, X_ts_alg2 = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches,\n",
    "                                                                 img=og_img, times=s_times)\n",
    "            X_0s_alg1, X_ts_alg1 = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
    "                                                                 img=og_img, times=s_times)\n",
    "\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "\n",
    "            alg2 = []\n",
    "            alg1 = []\n",
    "\n",
    "            #to_show = [0, 1, 2, 4, 8, 16, 20, 24, 32, 36, 38, 39, 40]\n",
    "            to_show = [0, 1, 2, 4, 8, 10, 12, 16, 17, 18, 19, 20]\n",
    "\n",
    "            for j in range(len(X_ts_alg2)):\n",
    "                x_t = X_ts_alg2[j][0]\n",
    "                x_t = (x_t + 1) * 0.5\n",
    "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg2)-j}_{i}.png'), nrow=1)\n",
    "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg2)-j}_{i}.png')\n",
    "                if j in to_show:\n",
    "                    alg2.append(x_t)\n",
    "\n",
    "                x_t = X_ts_alg1[j][0]\n",
    "                x_t = (x_t + 1) * 0.5\n",
    "                utils.save_image(x_t, str(self.results_folder / f'x_alg2_{len(X_ts_alg1) - j}_{i}.png'), nrow=1)\n",
    "                x_t = cv2.imread(f'{self.results_folder}/x_alg2_{len(X_ts_alg1) - j}_{i}.png')\n",
    "                if j in to_show:\n",
    "                    alg1.append(x_t)\n",
    "\n",
    "\n",
    "            x_0 = X_0s_alg2[-1][0]\n",
    "            x_0 = (x_0 + 1) * 0.5\n",
    "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg2_{i}.png'), nrow=1)\n",
    "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg2_{i}.png')\n",
    "            alg2.append(x_0)\n",
    "            im_h = cv2.hconcat(alg2)\n",
    "            cv2.imwrite(f'{self.results_folder}/all_alg2_{i}.png', im_h)\n",
    "\n",
    "            x_0 = X_0s_alg1[-1][0]\n",
    "            x_0 = (x_0 + 1) * 0.5\n",
    "            utils.save_image(x_0, str(self.results_folder / f'x_best_alg1_{i}.png'), nrow=1)\n",
    "            x_0 = cv2.imread(f'{self.results_folder}/x_best_alg1_{i}.png')\n",
    "            alg1.append(x_0)\n",
    "            im_h = cv2.hconcat(alg1)\n",
    "            cv2.imwrite(f'{self.results_folder}/all_alg1_{i}.png', im_h)\n",
    "\n",
    "\n",
    "    def paper_showing_sampling_diff_images(self, s_times=None):\n",
    "\n",
    "        import cv2\n",
    "        cnt = 0\n",
    "        for i in range(10):\n",
    "            batches = self.batch_size\n",
    "            og_img = next(self.dl).cuda()\n",
    "            print(og_img.shape)\n",
    "\n",
    "            X_0s_alg2, _ = self.ema_model.all_sample_both_sample(sampling_routine='x0_step_down', batch_size=batches, img=og_img, times=s_times)\n",
    "            X_0s_alg1, _ = self.ema_model.all_sample_both_sample(sampling_routine='default', batch_size=batches,\n",
    "                                                                 img=og_img, times=s_times)\n",
    "\n",
    "            x0_alg1 = (X_0s_alg1[-1] + 1) * 0.5\n",
    "            x0_alg2 = (X_0s_alg2[-1] + 1) * 0.5\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "\n",
    "\n",
    "            for j in range(og_img.shape[0]):\n",
    "                utils.save_image(x0_alg1[j], str(self.results_folder / f'x0_alg1_{cnt}.png'), nrow=1)\n",
    "                utils.save_image(x0_alg2[j], str(self.results_folder / f'x0_alg2_{cnt}.png'), nrow=1)\n",
    "                utils.save_image(og_img[j], str(self.results_folder / f'og_img_{cnt}.png'), nrow=1)\n",
    "\n",
    "\n",
    "\n",
    "                alg1 = cv2.imread(f'{self.results_folder}/x0_alg1_{cnt}.png')\n",
    "                alg2 = cv2.imread(f'{self.results_folder}/x0_alg2_{cnt}.png')\n",
    "                og = cv2.imread(f'{self.results_folder}/og_img_{cnt}.png')\n",
    "\n",
    "\n",
    "                black = [255, 255, 255]\n",
    "                alg1 = cv2.copyMakeBorder(alg1, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "                alg2 = cv2.copyMakeBorder(alg2, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "                og = cv2.copyMakeBorder(og, 10, 10, 10, 10, cv2.BORDER_CONSTANT, value=black)\n",
    "\n",
    "                im_h = cv2.hconcat([og, alg1, alg2])\n",
    "                cv2.imwrite(f'{self.results_folder}/all_{cnt}.png', im_h)\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "    def sample_as_a_vector_gmm(self, start=0, end=1000, siz=64, ch=3, clusters=10):\n",
    "\n",
    "        all_samples = []\n",
    "        flatten = nn.Flatten()\n",
    "        dataset = self.ds\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0).cuda()\n",
    "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
    "            img = flatten(img)\n",
    "            if idx > start:\n",
    "                all_samples.append(img[0])\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "        all_samples = torch.stack(all_samples)\n",
    "        print(all_samples.shape)\n",
    "\n",
    "        all_samples = all_samples.cpu().detach().numpy()\n",
    "\n",
    "        num_samples = 100\n",
    "\n",
    "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
    "        og_x, og_y = gm.sample(n_samples=num_samples)\n",
    "        og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
    "        og_x = torch.from_numpy(og_x).cuda()\n",
    "        og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "        print(og_x.shape)\n",
    "        og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
    "\n",
    "\n",
    "        X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
    "\n",
    "        extra_path = 'vec'\n",
    "        og_img = (og_img + 1) * 0.5\n",
    "        utils.save_image(og_img, str(self.results_folder / f'og-{start}-{end}-{siz}-{clusters}-{extra_path}.png'), nrow=6)\n",
    "\n",
    "        import imageio\n",
    "        frames_t = []\n",
    "        frames_0 = []\n",
    "\n",
    "        for i in range(len(X_0s)):\n",
    "            print(i)\n",
    "\n",
    "            x_0 = X_0s[i]\n",
    "            x_0 = (x_0 + 1) * 0.5\n",
    "            utils.save_image(x_0, str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'),\n",
    "                             nrow=6)\n",
    "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png'), str(i))\n",
    "            frames_0.append(\n",
    "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-x0.png')))\n",
    "\n",
    "            x_t = X_ts[i]\n",
    "            all_images = (x_t + 1) * 0.5\n",
    "            utils.save_image(all_images,\n",
    "                             str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), nrow=6)\n",
    "            self.add_title(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png'), str(i))\n",
    "            frames_t.append(\n",
    "                imageio.imread(str(self.results_folder / f'sample-{start}-{end}-{siz}-{clusters}-{i}-{extra_path}-xt.png')))\n",
    "\n",
    "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-x0.gif'), frames_0)\n",
    "        imageio.mimsave(str(self.results_folder / f'Gif-{start}-{end}-{siz}-{clusters}-{extra_path}-xt.gif'), frames_t)\n",
    "\n",
    "\n",
    "    def sample_as_a_vector_gmm_and_save(self, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
    "\n",
    "        all_samples = []\n",
    "        flatten = nn.Flatten()\n",
    "        dataset = self.ds\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
    "            img = flatten(img)\n",
    "            if idx > start:\n",
    "                all_samples.append(img[0])\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "        all_samples = torch.stack(all_samples)\n",
    "        print(all_samples.shape)\n",
    "\n",
    "        all_samples = all_samples.cpu().detach().numpy()\n",
    "        gm = GaussianMixture(n_components=clusters, random_state=0).fit(all_samples)\n",
    "\n",
    "        all_num = n_sample\n",
    "        num_samples = 10000\n",
    "        it = int(all_num/num_samples)\n",
    "\n",
    "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
    "\n",
    "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
    "\n",
    "        cnt=0\n",
    "        while(it):\n",
    "            og_x, og_y = gm.sample(n_samples=num_samples)\n",
    "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
    "            og_x = torch.from_numpy(og_x).cuda()\n",
    "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "            print(og_x.shape)\n",
    "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=1, img=og_img, times=None)\n",
    "\n",
    "            x0s = X_0s[-1]\n",
    "            for i in range(x0s.shape[0]):\n",
    "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
    "                cnt += 1\n",
    "\n",
    "            it = it - 1\n",
    "            print(it)\n",
    "\n",
    "\n",
    "    def sample_as_a_vector_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
    "\n",
    "\n",
    "        flatten = nn.Flatten()\n",
    "        dataset = self.ds\n",
    "        all_samples = None\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
    "            img = flatten(img).cuda()\n",
    "            if idx > start:\n",
    "                if all_samples is None:\n",
    "                    all_samples = img\n",
    "                else:\n",
    "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "\n",
    "        #all_samples = torch.stack(all_samples)\n",
    "        print(all_samples.shape)\n",
    "\n",
    "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
    "                          convergence_tolerance=0.001, batch_size=1000)\n",
    "        model.fit(all_samples)\n",
    "\n",
    "        all_num = n_sample\n",
    "        num_samples = 100\n",
    "        it = int(all_num / num_samples)\n",
    "\n",
    "        create_folder(f'{self.results_folder}_{siz}_{clusters}/')\n",
    "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}/')\n",
    "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/')\n",
    "\n",
    "\n",
    "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
    "\n",
    "        cnt=0\n",
    "        while(it):\n",
    "            #og_x, _ = model.sample(n=num_samples)\n",
    "            og_x = model.sample(num_datapoints=num_samples)\n",
    "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
    "\n",
    "            og_x = og_x.cuda()\n",
    "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "            print(og_x.shape)\n",
    "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
    "\n",
    "            x0s = X_0s[-1]\n",
    "            blurs = X_ts[0]\n",
    "            for i in range(x0s.shape[0]):\n",
    "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}/' + f'sample-x0-{cnt}.png'))\n",
    "\n",
    "                utils.save_image((og_img[i] + 1) * 0.5,\n",
    "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}/' + f'sample-{cnt}.png'))\n",
    "\n",
    "                utils.save_image((blurs[i] + 1) * 0.5,\n",
    "                                 str(f'{self.results_folder}_gmm_blur_{siz}_{clusters}/' + f'sample-blur-{cnt}.png'))\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "            it = it - 1\n",
    "            print(it)\n",
    "\n",
    "    def sample_as_a_vector_from_blur_pytorch_gmm_and_save(self, torch_gmm, start=0, end=1000, siz=64, ch=3, clusters=10, n_sample=10000):\n",
    "        flatten = nn.Flatten()\n",
    "        dataset = self.ds\n",
    "\n",
    "        print(len(dataset))\n",
    "\n",
    "        #sample_at = self.ema_model.num_timesteps // 2\n",
    "        sample_at = self.ema_model.num_timesteps // 2\n",
    "        all_samples = None\n",
    "\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0)\n",
    "            img = self.ema_model.opt(img.cuda(), t=sample_at)\n",
    "            img = F.interpolate(img, size=siz, mode='bilinear')\n",
    "            img = flatten(img).cuda()\n",
    "\n",
    "            if idx > start:\n",
    "                if all_samples is None:\n",
    "                    all_samples = img\n",
    "                else:\n",
    "                    all_samples = torch.cat((all_samples, img), dim=0)\n",
    "                #all_samples.append(img[0])\n",
    "\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "        # all_samples = torch.stack(all_samples)\n",
    "        print(all_samples.shape)\n",
    "\n",
    "        model = torch_gmm(num_components=clusters, trainer_params=dict(gpus=1), covariance_type='full',\n",
    "                          convergence_tolerance=0.001, batch_size=1000)\n",
    "        model.fit(all_samples)\n",
    "\n",
    "\n",
    "\n",
    "        all_num = n_sample\n",
    "        num_samples = 100\n",
    "        it = int(all_num/num_samples)\n",
    "\n",
    "        create_folder(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/')\n",
    "        create_folder(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/')\n",
    "        create_folder(f'{self.results_folder}_gmm_blur_{siz}_{clusters}_{sample_at}/')\n",
    "\n",
    "        print(f'{self.results_folder}_{siz}_{clusters}/')\n",
    "\n",
    "        cnt=0\n",
    "        while(it):\n",
    "            og_x = model.sample(num_datapoints=num_samples)\n",
    "            og_x = og_x.reshape(num_samples, ch, siz, siz)\n",
    "\n",
    "            og_x = og_x.cuda()\n",
    "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "            print(og_x.shape)\n",
    "            og_img = F.interpolate(og_x, size=self.image_size, mode='bilinear')\n",
    "            X_0s, X_ts = self.ema_model.all_sample_from_blur(batch_size=og_img.shape[0], img=og_img, start_times=sample_at)\n",
    "\n",
    "            x0s = X_0s[-1]\n",
    "            for i in range(x0s.shape[0]):\n",
    "                utils.save_image((x0s[i]+1)*0.5, str(f'{self.results_folder}_{siz}_{clusters}_{sample_at}/' + f'sample-x0-{cnt}.png'))\n",
    "\n",
    "                utils.save_image((og_img[i] + 1) * 0.5,\n",
    "                                 str(f'{self.results_folder}_gmm_{siz}_{clusters}_{sample_at}/' + f'sample-{cnt}.png'))\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "            it = it - 1\n",
    "\n",
    "\n",
    "\n",
    "    def sample_from_data_save(self, start=0, end=1000):\n",
    "\n",
    "        all_samples = []\n",
    "        dataset = self.ds\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0).cuda()\n",
    "            if idx > start:\n",
    "                all_samples.append(img[0])\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "        all_samples = torch.stack(all_samples)\n",
    "        create_folder(f'{self.results_folder}/')\n",
    "\n",
    "        cnt=0\n",
    "        while(cnt < all_samples.shape[0]):\n",
    "            og_x = all_samples[cnt: cnt + 1000]\n",
    "            og_x = og_x.cuda()\n",
    "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "            og_img = og_x\n",
    "            print(og_img.shape)\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
    "\n",
    "            x0s = X_0s[-1]\n",
    "            for i in range(x0s.shape[0]):\n",
    "                utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
    "                cnt += 1\n",
    "\n",
    "    def fid_distance_decrease_from_manifold(self, fid_func, start=0, end=1000):\n",
    "\n",
    "        #from skimage.metrics import structural_similarity as ssim\n",
    "        from pytorch_msssim import ssim\n",
    "\n",
    "        all_samples = []\n",
    "        dataset = self.ds\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = torch.unsqueeze(img, 0).cuda()\n",
    "            if idx > start:\n",
    "                all_samples.append(img[0])\n",
    "            if idx % 1000 == 0:\n",
    "                print(idx)\n",
    "            if end != None:\n",
    "                if idx == end:\n",
    "                    print(idx)\n",
    "                    break\n",
    "\n",
    "        all_samples = torch.stack(all_samples)\n",
    "        # create_folder(f'{self.results_folder}/')\n",
    "        blurred_samples = None\n",
    "        original_sample = None\n",
    "        deblurred_samples = None\n",
    "        direct_deblurred_samples = None\n",
    "\n",
    "        sanity_check = 1\n",
    "\n",
    "\n",
    "        cnt=0\n",
    "        while(cnt < all_samples.shape[0]):\n",
    "            og_x = all_samples[cnt: cnt + 100]\n",
    "            og_x = og_x.cuda()\n",
    "            og_x = og_x.type(torch.cuda.FloatTensor)\n",
    "            og_img = og_x\n",
    "            print(og_img.shape)\n",
    "            X_0s, X_ts = self.ema_model.all_sample(batch_size=og_img.shape[0], img=og_img, times=None)\n",
    "\n",
    "            og_img = og_img.to('cpu')\n",
    "            blurry_imgs = X_ts[0].to('cpu')\n",
    "            deblurry_imgs = X_0s[-1].to('cpu')\n",
    "            direct_deblurry_imgs = X_0s[0].to('cpu')\n",
    "\n",
    "            og_img = og_img.repeat(1, 3 // og_img.shape[1], 1, 1)\n",
    "            blurry_imgs = blurry_imgs.repeat(1, 3 // blurry_imgs.shape[1], 1, 1)\n",
    "            deblurry_imgs = deblurry_imgs.repeat(1, 3 // deblurry_imgs.shape[1], 1, 1)\n",
    "            direct_deblurry_imgs = direct_deblurry_imgs.repeat(1, 3 // direct_deblurry_imgs.shape[1], 1, 1)\n",
    "\n",
    "\n",
    "\n",
    "            og_img = (og_img + 1) * 0.5\n",
    "            blurry_imgs = (blurry_imgs + 1) * 0.5\n",
    "            deblurry_imgs = (deblurry_imgs + 1) * 0.5\n",
    "            direct_deblurry_imgs = (direct_deblurry_imgs + 1) * 0.5\n",
    "\n",
    "            if cnt == 0:\n",
    "                print(og_img.shape)\n",
    "                print(blurry_imgs.shape)\n",
    "                print(deblurry_imgs.shape)\n",
    "                print(direct_deblurry_imgs.shape)\n",
    "\n",
    "                if sanity_check:\n",
    "                    folder = './sanity_check/'\n",
    "                    create_folder(folder)\n",
    "\n",
    "                    san_imgs = og_img[0: 32]\n",
    "                    utils.save_image(san_imgs,str(folder + f'sample-og.png'), nrow=6)\n",
    "\n",
    "                    san_imgs = blurry_imgs[0: 32]\n",
    "                    utils.save_image(san_imgs, str(folder + f'sample-xt.png'), nrow=6)\n",
    "\n",
    "                    san_imgs = deblurry_imgs[0: 32]\n",
    "                    utils.save_image(san_imgs, str(folder + f'sample-recons.png'), nrow=6)\n",
    "\n",
    "                    san_imgs = direct_deblurry_imgs[0: 32]\n",
    "                    utils.save_image(san_imgs, str(folder + f'sample-direct-recons.png'), nrow=6)\n",
    "\n",
    "\n",
    "            if blurred_samples is None:\n",
    "                blurred_samples = blurry_imgs\n",
    "            else:\n",
    "                blurred_samples = torch.cat((blurred_samples, blurry_imgs), dim=0)\n",
    "\n",
    "\n",
    "            if original_sample is None:\n",
    "                original_sample = og_img\n",
    "            else:\n",
    "                original_sample = torch.cat((original_sample, og_img), dim=0)\n",
    "\n",
    "\n",
    "            if deblurred_samples is None:\n",
    "                deblurred_samples = deblurry_imgs\n",
    "            else:\n",
    "                deblurred_samples = torch.cat((deblurred_samples, deblurry_imgs), dim=0)\n",
    "\n",
    "\n",
    "            if direct_deblurred_samples is None:\n",
    "                direct_deblurred_samples = direct_deblurry_imgs\n",
    "            else:\n",
    "                direct_deblurred_samples = torch.cat((direct_deblurred_samples, direct_deblurry_imgs), dim=0)\n",
    "\n",
    "            cnt += og_img.shape[0]\n",
    "\n",
    "        print(blurred_samples.shape)\n",
    "        print(original_sample.shape)\n",
    "        print(deblurred_samples.shape)\n",
    "        print(direct_deblurred_samples.shape)\n",
    "\n",
    "        fid_blur = fid_func(samples=[original_sample, blurred_samples])\n",
    "        rmse_blur = torch.sqrt(torch.mean( (original_sample - blurred_samples)**2 ))\n",
    "        ssim_blur = ssim(original_sample, blurred_samples, data_range=1, size_average=True)\n",
    "        # n_og = original_sample.cpu().detach().numpy()\n",
    "        # n_bs = blurred_samples.cpu().detach().numpy()\n",
    "        # ssim_blur = ssim(n_og, n_bs, data_range=n_og.max() - n_og.min(), multichannel=True)\n",
    "        print(f'The FID of blurry images with original image is {fid_blur}')\n",
    "        print(f'The RMSE of blurry images with original image is {rmse_blur}')\n",
    "        print(f'The SSIM of blurry images with original image is {ssim_blur}')\n",
    "\n",
    "\n",
    "        fid_deblur = fid_func(samples=[original_sample, deblurred_samples])\n",
    "        rmse_deblur = torch.sqrt(torch.mean((original_sample - deblurred_samples) ** 2))\n",
    "        ssim_deblur = ssim(original_sample, deblurred_samples, data_range=1, size_average=True)\n",
    "        print(f'The FID of deblurred images with original image is {fid_deblur}')\n",
    "        print(f'The RMSE of deblurred images with original image is {rmse_deblur}')\n",
    "        print(f'The SSIM of deblurred images with original image is {ssim_deblur}')\n",
    "\n",
    "        print(f'Hence the improvement in FID using sampling is {fid_blur - fid_deblur}')\n",
    "\n",
    "        fid_direct_deblur = fid_func(samples=[original_sample, direct_deblurred_samples])\n",
    "        rmse_direct_deblur = torch.sqrt(torch.mean((original_sample - direct_deblurred_samples) ** 2))\n",
    "        ssim_direct_deblur = ssim(original_sample, direct_deblurred_samples, data_range=1, size_average=True)\n",
    "        print(f'The FID of direct deblurred images with original image is {fid_direct_deblur}')\n",
    "        print(f'The RMSE of direct deblurred images with original image is {rmse_direct_deblur}')\n",
    "        print(f'The SSIM of direct deblurred images with original image is {ssim_direct_deblur}')\n",
    "\n",
    "        print(f'Hence the improvement in FID using direct sampling is {fid_blur - fid_direct_deblur}')\n",
    "\n",
    "\n",
    "            # x0s = X_0s[-1]\n",
    "            # for i in range(x0s.shape[0]):\n",
    "            #     utils.save_image( (x0s[i]+1)*0.5, str(f'{self.results_folder}/' + f'sample-x0-{cnt}.png'))\n",
    "            #     cnt += 1\n",
    "\n",
    "    def save_training_data(self):\n",
    "        dataset = self.ds\n",
    "        create_folder(f'{self.results_folder}/')\n",
    "\n",
    "        print(len(dataset))\n",
    "        for idx in range(len(dataset)):\n",
    "            img = dataset[idx]\n",
    "            img = (img + 1) * 0.5\n",
    "            utils.save_image(img, str(f'{self.results_folder}/' + f'{idx}.png'))\n",
    "            if idx%1000 == 0:\n",
    "                print(idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45a033ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d076ce5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as exc:\n",
    "        if exc.errno != errno.EEXIST:\n",
    "            raise\n",
    "        pass\n",
    "\n",
    "def del_folder(path):\n",
    "    try:\n",
    "        shutil.rmtree(path)\n",
    "    except OSError as exc:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafcb743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Time embed used ?  False\n",
      "HL\n"
     ]
    }
   ],
   "source": [
    "time_steps=200 #\"This is the number of steps in which a clean image looses information\"\n",
    "train_steps=200000 #\"The number of iterations for training\"\n",
    "#blur_std=0.1 #\"It sets the standard deviation for blur routines which have different meaning based on blur routine\"\n",
    "#blur_size=3 #\"It sets the size of gaussian blur used in blur routines for each step t\"\n",
    "save_folder=\"./results_celebA\"\n",
    "data_path=\"./root_celebA_128_train_new_HL/\"\n",
    "load_path=None\n",
    "#blur_routine=\"Special_6_routine\" #\"This will set the type of blur routine one can use, check the code for what each one of them does in detail\"\n",
    "train_routine='Final'\n",
    "#resolution_routine='Incremental_factor_2'\n",
    "sampling_routine=\"x0_step_down\" #\"The choice of sampling routine for reversing the diffusion process, when set as default it corresponds to Alg. 1 while when set as x0_step_down it stands for Alg. 2\"\n",
    "discrete=\"store_true\"\n",
    "image_size=32\n",
    "batch_size=32\n",
    "remove_time_embed=\"store_true\"\n",
    "residual=\"store_true\"\n",
    "da='celebA'\n",
    "\n",
    "\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    channels=3,\n",
    "    with_time_emb=not(remove_time_embed),\n",
    "    residual=residual\n",
    ").cuda()\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 64,\n",
    "    channels = 3,\n",
    "    timesteps = time_steps,   # number of steps\n",
    "    loss_type = 'l1',    # L1 or L2\n",
    "    train_routine =  train_routine,\n",
    "    sampling_routine =  sampling_routine\n",
    ").cuda()\n",
    "\n",
    "import torch\n",
    "diffusion = torch.nn.DataParallel(diffusion, device_ids=range(torch.cuda.device_count()))\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    folder=data_path,\n",
    "    image_size = 64,\n",
    "    train_batch_size = 32,\n",
    "    train_lr = 2e-5,\n",
    "    train_num_steps =  train_steps,         # total training steps\n",
    "    gradient_accumulate_every = 2,    # gradient accumulation steps\n",
    "    ema_decay = 0.995,                # exponential moving average decay\n",
    "    fp16 = False,                       # turn on mixed precision training with apex\n",
    "    results_folder =  save_folder,\n",
    "    load_path =  load_path,\n",
    "    dataset = 'HL'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "740da495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.5082042217254639\n",
      "0: 0.5718791484832764\n",
      "100: 0.4031858444213867\n",
      "100: 0.4018497169017792\n",
      "200: 0.33927053213119507\n",
      "200: 0.25085967779159546\n",
      "300: 0.17101101577281952\n",
      "300: 0.20849089324474335\n",
      "400: 0.16194820404052734\n",
      "400: 0.13053391873836517\n",
      "500: 0.1266462504863739\n",
      "500: 0.15300041437149048\n",
      "600: 0.1335461288690567\n",
      "600: 0.1386236846446991\n",
      "700: 0.11045724153518677\n",
      "700: 0.11472904682159424\n",
      "800: 0.10344486683607101\n",
      "800: 0.11557726562023163\n",
      "900: 0.12108413875102997\n",
      "900: 0.11204050481319427\n",
      "1000: 0.13430741429328918\n",
      "1000: 0.11848350614309311\n",
      "Mean of last 1000: 0.20093273082292162\n",
      "1100: 0.11670494079589844\n",
      "1100: 0.11584335565567017\n",
      "1200: 0.10442394018173218\n",
      "1200: 0.10949908941984177\n",
      "1300: 0.11072679609060287\n",
      "1300: 0.1049899160861969\n",
      "1400: 0.10610918700695038\n",
      "1400: 0.08800692856311798\n",
      "1500: 0.10712005198001862\n",
      "1500: 0.09134750813245773\n",
      "2000: 0.10928257554769516\n",
      "2000: 0.09081554412841797\n",
      "Mean of last 2000: 0.10386002480939076\n",
      "2100: 0.09468315541744232\n",
      "2100: 0.10641350597143173\n",
      "2200: 0.1045205220580101\n",
      "2200: 0.10585719347000122\n",
      "2300: 0.09257110208272934\n",
      "2300: 0.08471664041280746\n",
      "2400: 0.08743788301944733\n",
      "2400: 0.09250384569168091\n",
      "2500: 0.08786879479885101\n",
      "2500: 0.0937078595161438\n",
      "2600: 0.09701656550168991\n",
      "2600: 0.0871955007314682\n",
      "2700: 0.08964593708515167\n",
      "2700: 0.09723483771085739\n",
      "2800: 0.09844961017370224\n",
      "2800: 0.08711891621351242\n",
      "2900: 0.08947139978408813\n",
      "2900: 0.09265938401222229\n",
      "3000: 0.08822861313819885\n",
      "3000: 0.09579318761825562\n",
      "Mean of last 3000: 0.09452293067054077\n",
      "3100: 0.08767439424991608\n",
      "3100: 0.08619135618209839\n",
      "3200: 0.0861135721206665\n",
      "3200: 0.09255494922399521\n",
      "3300: 0.08738243579864502\n",
      "3300: 0.08696354925632477\n",
      "3400: 0.08026814460754395\n",
      "3400: 0.08390168845653534\n",
      "3500: 0.08853387832641602\n",
      "3500: 0.08772586286067963\n",
      "3600: 0.08469506353139877\n",
      "3600: 0.08832968771457672\n",
      "3700: 0.0902620404958725\n",
      "3700: 0.08218839764595032\n",
      "3800: 0.0787530243396759\n",
      "3800: 0.07944455742835999\n",
      "3900: 0.07378093153238297\n",
      "3900: 0.08730652183294296\n",
      "4000: 0.09040150046348572\n",
      "4000: 0.08867980539798737\n",
      "Mean of last 4000: 0.08824259769190085\n",
      "4100: 0.0823446661233902\n",
      "4100: 0.08161699026823044\n",
      "4200: 0.08139607310295105\n",
      "4200: 0.08038604259490967\n",
      "4300: 0.08217054605484009\n",
      "4300: 0.09667502343654633\n",
      "4400: 0.08428740501403809\n",
      "4400: 0.08098872005939484\n",
      "4500: 0.08146776258945465\n",
      "4500: 0.08149755001068115\n",
      "4600: 0.07722005993127823\n",
      "4600: 0.0824955403804779\n",
      "4700: 0.07698211073875427\n",
      "4700: 0.09072057902812958\n",
      "4800: 0.07023385912179947\n",
      "4800: 0.08483128249645233\n",
      "4900: 0.0853901356458664\n",
      "4900: 0.07827331125736237\n",
      "5000: 0.0797087773680687\n",
      "5000: 0.0840829610824585\n",
      "Mean of last 5000: 0.08395360881364072\n",
      "5100: 0.07706798613071442\n",
      "5100: 0.07474406063556671\n",
      "5200: 0.08730494976043701\n",
      "5200: 0.07810148596763611\n",
      "5300: 0.09197516739368439\n",
      "5300: 0.07677064836025238\n",
      "5400: 0.08080819994211197\n",
      "5400: 0.0705670714378357\n",
      "5500: 0.0782850980758667\n",
      "5500: 0.08276337385177612\n",
      "5600: 0.07922542840242386\n",
      "5600: 0.0872468575835228\n",
      "5700: 0.06977565586566925\n",
      "5700: 0.07767225056886673\n",
      "5800: 0.08832331001758575\n",
      "5800: 0.07315429300069809\n",
      "5900: 0.07542513310909271\n",
      "5900: 0.06936320662498474\n",
      "6000: 0.07923826575279236\n",
      "6000: 0.07047943025827408\n",
      "Mean of last 6000: 0.07946623584532833\n",
      "6100: 0.07444462925195694\n",
      "6100: 0.07809373736381531\n",
      "6200: 0.07809083163738251\n",
      "6200: 0.0763697624206543\n",
      "6300: 0.07260633260011673\n",
      "6300: 0.07761719077825546\n",
      "6400: 0.07647837698459625\n",
      "6400: 0.07180612534284592\n",
      "6500: 0.06958965957164764\n",
      "6500: 0.08405841886997223\n",
      "6600: 0.07514002174139023\n",
      "6600: 0.07269548624753952\n",
      "6700: 0.07021105289459229\n",
      "6700: 0.06990575045347214\n",
      "6800: 0.07958247512578964\n",
      "6800: 0.06907263398170471\n",
      "6900: 0.07137235254049301\n",
      "6900: 0.07238864153623581\n",
      "7000: 0.07635942846536636\n",
      "7000: 0.07111677527427673\n",
      "Mean of last 7000: 0.07500185415736743\n",
      "7100: 0.06613539159297943\n",
      "7100: 0.06307785958051682\n",
      "7200: 0.06693270057439804\n",
      "7200: 0.07490447163581848\n",
      "7300: 0.06234406679868698\n",
      "7300: 0.07475525885820389\n",
      "7400: 0.07170340418815613\n",
      "7400: 0.0790986716747284\n",
      "7500: 0.07301805168390274\n",
      "7500: 0.07450537383556366\n",
      "7600: 0.06640460342168808\n",
      "7600: 0.06668224930763245\n",
      "7700: 0.07106190919876099\n",
      "7700: 0.06788618862628937\n",
      "7800: 0.07139317691326141\n",
      "7800: 0.06964080780744553\n",
      "7900: 0.06867112219333649\n",
      "7900: 0.07218913733959198\n",
      "8000: 0.08113013207912445\n",
      "8000: 0.07915909588336945\n",
      "Mean of last 8000: 0.0715227353234927\n",
      "8100: 0.06153702363371849\n",
      "8100: 0.08021412789821625\n",
      "8200: 0.06920792162418365\n",
      "8200: 0.06800603866577148\n",
      "8300: 0.06629301607608795\n",
      "8300: 0.06876852363348007\n",
      "8400: 0.08978267014026642\n",
      "8400: 0.07711119949817657\n",
      "8500: 0.07174122333526611\n",
      "8500: 0.07615698873996735\n",
      "8600: 0.0658828467130661\n",
      "8600: 0.06244472786784172\n",
      "8700: 0.06739534437656403\n",
      "8700: 0.07176473736763\n",
      "8800: 0.07926946878433228\n",
      "8800: 0.06469160318374634\n",
      "8900: 0.07067536562681198\n",
      "8900: 0.06168278679251671\n",
      "9000: 0.0676976889371872\n",
      "9000: 0.06603236496448517\n",
      "Mean of last 9000: 0.06877964470241513\n",
      "9100: 0.06479167938232422\n",
      "9100: 0.0630248636007309\n",
      "9200: 0.06394417583942413\n",
      "9200: 0.06709833443164825\n",
      "9300: 0.06720434129238129\n",
      "9300: 0.06708596646785736\n",
      "9400: 0.060992442071437836\n",
      "9400: 0.059762027114629745\n",
      "9500: 0.06355937570333481\n",
      "9500: 0.07228375971317291\n",
      "9600: 0.06717304140329361\n",
      "9600: 0.07314421981573105\n",
      "9700: 0.06043777987360954\n",
      "9700: 0.07416604459285736\n",
      "9800: 0.06501977145671844\n",
      "9800: 0.07008396834135056\n",
      "9900: 0.06441204994916916\n",
      "9900: 0.06271058320999146\n",
      "10000: 0.06062730401754379\n",
      "10000: 0.060545098036527634\n",
      "Mean of last 10000: 0.06697289723080474\n",
      "10100: 0.06240495666861534\n",
      "10100: 0.07203958183526993\n",
      "10200: 0.06271844357252121\n",
      "10200: 0.06398159265518188\n",
      "10300: 0.06258293241262436\n",
      "10300: 0.06604493409395218\n",
      "10400: 0.0746006965637207\n",
      "10400: 0.06407509744167328\n",
      "10500: 0.064449742436409\n",
      "10500: 0.06265359371900558\n",
      "10600: 0.06808021664619446\n",
      "10600: 0.063364677131176\n",
      "10700: 0.05909224599599838\n",
      "10700: 0.06519004702568054\n",
      "10800: 0.06621717661619186\n",
      "10800: 0.06662429869174957\n",
      "10900: 0.05353207141160965\n",
      "10900: 0.06418436020612717\n",
      "11000: 0.06782360374927521\n",
      "11000: 0.07464175671339035\n",
      "Mean of last 11000: 0.06538442740743453\n",
      "11100: 0.06456129252910614\n",
      "11100: 0.060292989015579224\n",
      "11200: 0.071012482047081\n",
      "11200: 0.06072327494621277\n",
      "11300: 0.05885452777147293\n",
      "11300: 0.06027602776885033\n",
      "11400: 0.059884097427129745\n",
      "11400: 0.059686340391635895\n",
      "11500: 0.05740955471992493\n",
      "11500: 0.06760255247354507\n",
      "11600: 0.06334719806909561\n",
      "11600: 0.06936801224946976\n",
      "11700: 0.06392620503902435\n",
      "11700: 0.06352770328521729\n",
      "11800: 0.068453848361969\n",
      "11800: 0.06736274808645248\n",
      "11900: 0.06713724881410599\n",
      "11900: 0.06593077629804611\n",
      "12000: 0.06695673614740372\n",
      "12000: 0.06942787021398544\n",
      "Mean of last 12000: 0.06466301733797247\n",
      "12100: 0.07829420268535614\n",
      "12100: 0.06386586278676987\n",
      "12200: 0.07403931766748428\n",
      "12200: 0.06412803381681442\n",
      "12300: 0.06142396852374077\n",
      "12300: 0.06269248574972153\n",
      "12400: 0.06223246082663536\n",
      "12400: 0.07885968685150146\n",
      "12500: 0.07328443229198456\n",
      "12500: 0.06380140036344528\n",
      "12600: 0.06298106908798218\n",
      "12600: 0.061588600277900696\n",
      "12700: 0.07274525612592697\n",
      "12700: 0.05631290376186371\n",
      "12800: 0.0729881227016449\n",
      "12800: 0.061770595610141754\n",
      "12900: 0.07653526961803436\n",
      "12900: 0.06493183970451355\n",
      "13000: 0.06002981588244438\n",
      "13000: 0.053268566727638245\n",
      "Mean of last 13000: 0.0639197757834202\n",
      "13100: 0.06647579371929169\n",
      "13100: 0.06376570463180542\n",
      "13200: 0.0688779354095459\n",
      "13200: 0.07379023730754852\n",
      "13300: 0.057379648089408875\n",
      "13300: 0.06596441566944122\n",
      "13400: 0.06402315199375153\n",
      "13400: 0.06362099200487137\n",
      "13500: 0.05863061547279358\n",
      "13500: 0.05764586478471756\n",
      "13600: 0.057637374848127365\n",
      "13600: 0.05910190939903259\n",
      "13700: 0.05894205719232559\n",
      "13700: 0.06608971953392029\n",
      "13800: 0.06395849585533142\n",
      "13800: 0.06713898479938507\n",
      "13900: 0.06192712113261223\n",
      "13900: 0.0626268982887268\n",
      "14000: 0.06084844470024109\n",
      "14000: 0.06883072108030319\n",
      "Mean of last 14000: 0.063239328557631\n",
      "14100: 0.0602201446890831\n",
      "14100: 0.06376352906227112\n",
      "14200: 0.07600167393684387\n",
      "14200: 0.06972812116146088\n",
      "14300: 0.060491375625133514\n",
      "14300: 0.062036558985710144\n",
      "14400: 0.060988765209913254\n",
      "14400: 0.06373140215873718\n",
      "14500: 0.06007658690214157\n",
      "14500: 0.05730190873146057\n",
      "14600: 0.05095377191901207\n",
      "14600: 0.06801997125148773\n",
      "14700: 0.06287716329097748\n",
      "14700: 0.07035436481237411\n",
      "14800: 0.05934658646583557\n",
      "14800: 0.05676985904574394\n",
      "14900: 0.0670415461063385\n",
      "14900: 0.05381886288523674\n",
      "15000: 0.063296377658844\n",
      "15000: 0.06505291163921356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 15000: 0.06264397098527445\n",
      "15100: 0.06167807802557945\n",
      "15100: 0.05082758888602257\n",
      "15200: 0.05963820219039917\n",
      "15200: 0.06410329788923264\n",
      "15300: 0.059526797384023666\n",
      "15300: 0.0537647008895874\n",
      "15400: 0.07209956645965576\n",
      "15400: 0.057702552527189255\n",
      "15500: 0.06759548932313919\n",
      "15500: 0.06586490571498871\n",
      "15600: 0.06182844936847687\n",
      "15600: 0.06309249997138977\n",
      "15700: 0.06739474833011627\n",
      "15700: 0.061387043446302414\n",
      "15800: 0.05931582301855087\n",
      "15800: 0.06837859749794006\n",
      "15900: 0.06512768566608429\n",
      "15900: 0.05943218991160393\n",
      "16000: 0.05904126912355423\n",
      "16000: 0.05635931342840195\n",
      "Mean of last 16000: 0.06206882602863616\n",
      "16100: 0.06713463366031647\n",
      "16100: 0.06808741390705109\n",
      "16200: 0.0632307380437851\n",
      "16200: 0.05840841680765152\n",
      "16300: 0.053967591375112534\n",
      "16300: 0.05655226111412048\n",
      "16400: 0.06283986568450928\n",
      "16400: 0.0635983943939209\n",
      "16500: 0.0634908676147461\n",
      "16500: 0.058076903223991394\n",
      "16600: 0.06105794012546539\n",
      "16600: 0.058934640139341354\n",
      "16700: 0.06558447331190109\n",
      "16700: 0.06250790506601334\n",
      "16800: 0.06474373489618301\n",
      "16800: 0.06107309088110924\n",
      "16900: 0.05711163580417633\n",
      "16900: 0.06614869087934494\n",
      "17000: 0.05742441862821579\n",
      "17000: 0.05446445569396019\n",
      "Mean of last 17000: 0.06171614027858435\n",
      "17100: 0.0589527003467083\n",
      "17100: 0.0580982081592083\n",
      "17200: 0.0633297860622406\n",
      "17200: 0.06831169128417969\n",
      "17300: 0.0691676065325737\n",
      "17300: 0.06664307415485382\n",
      "17400: 0.06756539642810822\n",
      "17400: 0.06574689596891403\n",
      "17500: 0.057919666171073914\n",
      "17500: 0.05624966323375702\n",
      "17600: 0.061607152223587036\n",
      "17600: 0.06467153131961823\n",
      "17700: 0.06084635853767395\n",
      "17700: 0.05985335260629654\n",
      "17800: 0.06578847765922546\n",
      "17800: 0.05617547780275345\n",
      "17900: 0.06700228154659271\n",
      "17900: 0.06616293638944626\n",
      "18000: 0.07320411503314972\n",
      "18000: 0.06023184582591057\n",
      "Mean of last 18000: 0.06128152037647876\n",
      "18100: 0.0637265145778656\n",
      "18100: 0.0587308406829834\n",
      "18200: 0.06372211873531342\n",
      "18200: 0.059451110661029816\n",
      "18300: 0.058236248791217804\n",
      "18300: 0.056876637041568756\n",
      "18400: 0.05480587109923363\n",
      "18400: 0.07162244617938995\n",
      "18500: 0.06060870736837387\n",
      "18500: 0.05606917291879654\n",
      "18600: 0.05701891705393791\n",
      "18600: 0.05727526172995567\n",
      "18700: 0.0574505440890789\n",
      "18700: 0.06145718693733215\n",
      "18800: 0.06497585028409958\n",
      "18800: 0.0514015257358551\n",
      "18900: 0.05452752858400345\n",
      "18900: 0.05701681226491928\n",
      "19000: 0.06054752320051193\n",
      "19000: 0.05949120968580246\n",
      "Mean of last 19000: 0.06067476924750712\n",
      "19100: 0.05275066941976547\n",
      "19100: 0.054859913885593414\n",
      "19200: 0.06947460025548935\n",
      "19200: 0.06932425498962402\n",
      "19300: 0.062319111078977585\n",
      "19300: 0.06852487474679947\n",
      "19400: 0.06087253987789154\n",
      "19400: 0.057289570569992065\n",
      "19500: 0.061491768807172775\n",
      "19500: 0.06558152288198471\n",
      "19600: 0.061407800763845444\n",
      "19600: 0.057059045881032944\n",
      "19700: 0.05720242112874985\n",
      "19700: 0.055668555200099945\n",
      "19800: 0.05988375470042229\n",
      "19800: 0.05578232929110527\n",
      "19900: 0.062458526343107224\n",
      "19900: 0.06256745755672455\n",
      "20000: 0.0566929392516613\n",
      "20000: 0.05796593055129051\n",
      "Mean of last 20000: 0.06062790216853867\n",
      "20100: 0.060666125267744064\n",
      "20100: 0.0589914545416832\n",
      "20200: 0.054640911519527435\n",
      "20200: 0.056458812206983566\n",
      "20300: 0.06387609243392944\n",
      "20300: 0.05090450495481491\n",
      "20400: 0.05948252230882645\n",
      "20400: 0.051897745579481125\n",
      "20500: 0.05475446581840515\n",
      "20500: 0.06911899149417877\n",
      "20600: 0.062381356954574585\n",
      "20600: 0.06603795289993286\n",
      "20700: 0.052893366664648056\n",
      "20700: 0.05678177624940872\n",
      "20800: 0.06430152803659439\n",
      "20800: 0.059053950011730194\n",
      "20900: 0.06331528723239899\n",
      "20900: 0.05316675826907158\n",
      "21000: 0.06411132216453552\n",
      "21000: 0.060537051409482956\n",
      "Mean of last 21000: 0.06022096991903715\n",
      "21100: 0.058337971568107605\n",
      "21100: 0.07451644539833069\n",
      "21200: 0.05769888311624527\n",
      "21200: 0.057437267154455185\n",
      "21300: 0.060139887034893036\n",
      "21300: 0.053266286849975586\n",
      "21400: 0.060132913291454315\n",
      "21400: 0.05651205778121948\n",
      "21500: 0.05932021141052246\n",
      "21500: 0.06484602391719818\n",
      "21600: 0.07004910707473755\n",
      "21600: 0.054823245853185654\n",
      "21700: 0.05261298269033432\n",
      "21700: 0.058257415890693665\n",
      "21800: 0.063519686460495\n",
      "21800: 0.05573200434446335\n",
      "21900: 0.05752205103635788\n",
      "21900: 0.06377634406089783\n",
      "22000: 0.05685171112418175\n",
      "22000: 0.06122343987226486\n",
      "Mean of last 22000: 0.06019640366893846\n",
      "22100: 0.05859970301389694\n",
      "22100: 0.07115060836076736\n",
      "22200: 0.05599900335073471\n",
      "22200: 0.06649711728096008\n",
      "22300: 0.06037699431180954\n",
      "22300: 0.05573668330907822\n",
      "22400: 0.055149324238300323\n",
      "22400: 0.059364184737205505\n",
      "22500: 0.052659180015325546\n",
      "22500: 0.05710671842098236\n",
      "22600: 0.05689290165901184\n",
      "22600: 0.059774309396743774\n",
      "22700: 0.0654008612036705\n",
      "22700: 0.057853322476148605\n",
      "22800: 0.05336913466453552\n",
      "22800: 0.05624386668205261\n",
      "22900: 0.06139656528830528\n",
      "22900: 0.06849218904972076\n",
      "23000: 0.06141290068626404\n",
      "23000: 0.057925995439291\n",
      "Mean of last 23000: 0.059643235085504155\n",
      "23100: 0.05883704125881195\n",
      "23100: 0.05832573026418686\n",
      "23200: 0.06782429665327072\n",
      "23200: 0.0605490617454052\n",
      "23300: 0.06045125052332878\n",
      "23300: 0.05872374027967453\n",
      "23400: 0.05813318118453026\n",
      "23400: 0.05364252254366875\n",
      "23500: 0.06235203146934509\n",
      "23500: 0.06597743183374405\n",
      "23600: 0.07723446190357208\n",
      "23600: 0.05772549659013748\n",
      "23700: 0.060613345354795456\n",
      "23700: 0.06697350740432739\n",
      "23800: 0.0585390143096447\n",
      "23800: 0.06739397346973419\n",
      "23900: 0.05442114919424057\n",
      "23900: 0.04859555885195732\n",
      "24000: 0.06405516713857651\n",
      "24000: 0.05968920886516571\n",
      "Mean of last 24000: 0.059484101189942386\n",
      "24100: 0.060254763811826706\n",
      "24100: 0.063352569937706\n",
      "24200: 0.05793334171175957\n",
      "24200: 0.05318177491426468\n",
      "24300: 0.0757228434085846\n",
      "24300: 0.05281014367938042\n",
      "24400: 0.05973632261157036\n",
      "24400: 0.06311086565256119\n",
      "24500: 0.07162134349346161\n",
      "24500: 0.05417050048708916\n",
      "24600: 0.05870754271745682\n",
      "24600: 0.05929601192474365\n",
      "24700: 0.0545724481344223\n",
      "24700: 0.06082920357584953\n",
      "24800: 0.061260536313056946\n",
      "24800: 0.06297934055328369\n",
      "24900: 0.05511721223592758\n",
      "24900: 0.05809679627418518\n",
      "25000: 0.056723013520240784\n",
      "25000: 0.057895727455616\n",
      "Mean of last 25000: 0.059415153788772976\n",
      "25100: 0.05607138201594353\n",
      "25100: 0.05488252639770508\n",
      "25200: 0.055658649653196335\n",
      "25200: 0.06988458335399628\n",
      "25300: 0.05986505746841431\n",
      "25300: 0.05455216020345688\n",
      "25400: 0.052396394312381744\n",
      "25400: 0.05337395519018173\n",
      "25500: 0.054203204810619354\n",
      "25500: 0.06533193588256836\n",
      "25600: 0.05868009850382805\n",
      "25600: 0.056386351585388184\n",
      "25700: 0.061109282076358795\n",
      "25700: 0.05578786879777908\n",
      "25800: 0.05734057351946831\n",
      "25800: 0.05316576361656189\n",
      "25900: 0.06305939704179764\n",
      "25900: 0.05465884506702423\n",
      "26000: 0.05733560770750046\n",
      "26000: 0.058765869587659836\n",
      "Mean of last 26000: 0.05907319149711392\n",
      "26100: 0.0655457079410553\n",
      "26100: 0.06484630703926086\n",
      "26200: 0.06929686665534973\n",
      "26200: 0.05647323653101921\n",
      "26300: 0.0642230287194252\n",
      "26300: 0.06264108419418335\n",
      "26400: 0.06255405396223068\n",
      "26400: 0.0554557740688324\n",
      "26500: 0.0614093542098999\n",
      "26500: 0.05712222680449486\n",
      "26600: 0.06208975613117218\n",
      "26600: 0.05878083035349846\n",
      "26700: 0.051476236432790756\n",
      "26700: 0.05638331174850464\n",
      "26800: 0.059557922184467316\n",
      "26800: 0.057734183967113495\n",
      "26900: 0.05604076385498047\n",
      "26900: 0.05323648452758789\n",
      "27000: 0.06333067268133163\n",
      "27000: 0.07145480811595917\n",
      "Mean of last 27000: 0.059191042901603846\n",
      "27100: 0.05617041513323784\n",
      "27100: 0.0599072091281414\n",
      "27200: 0.07126198709011078\n",
      "27200: 0.05353900045156479\n",
      "27300: 0.060485318303108215\n",
      "27300: 0.06628280133008957\n",
      "27400: 0.059788644313812256\n",
      "27400: 0.05502873659133911\n",
      "27500: 0.06127180904150009\n",
      "27500: 0.053217481821775436\n",
      "27600: 0.06395785510540009\n",
      "27600: 0.07318715751171112\n",
      "27700: 0.05988388881087303\n",
      "27700: 0.05096515268087387\n",
      "27800: 0.06034236401319504\n",
      "27800: 0.05891573429107666\n",
      "27900: 0.06290613114833832\n",
      "27900: 0.06031262129545212\n",
      "28000: 0.05819767713546753\n",
      "28000: 0.062213849276304245\n",
      "Mean of last 28000: 0.058797410539501195\n",
      "28100: 0.05358518287539482\n",
      "28100: 0.05968547612428665\n",
      "28200: 0.0558866411447525\n",
      "28200: 0.05759333819150925\n",
      "28300: 0.05884959548711777\n",
      "28300: 0.059618569910526276\n",
      "28400: 0.05936472862958908\n",
      "28400: 0.0541137270629406\n",
      "28500: 0.05789133906364441\n",
      "28500: 0.057119183242321014\n",
      "28600: 0.05467984825372696\n",
      "28600: 0.05537424609065056\n",
      "28700: 0.0599675290286541\n",
      "28700: 0.0562855564057827\n",
      "28800: 0.06367944926023483\n",
      "28800: 0.06670930236577988\n",
      "28900: 0.049164190888404846\n",
      "28900: 0.06629718840122223\n",
      "29000: 0.07127396762371063\n",
      "29000: 0.05955647677183151\n",
      "Mean of last 29000: 0.05871752176534284\n",
      "29100: 0.0587555468082428\n",
      "29100: 0.05395440757274628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29200: 0.057874999940395355\n",
      "29200: 0.052234943956136703\n",
      "29300: 0.0584593340754509\n",
      "29300: 0.06133373826742172\n",
      "29400: 0.06825041025876999\n",
      "29400: 0.057805370539426804\n",
      "29800: 0.05768348276615143\n",
      "29800: 0.063543401658535\n",
      "29900: 0.05512716621160507\n",
      "29900: 0.05427742004394531\n",
      "30000: 0.06274423003196716\n",
      "30000: 0.05676255747675896\n",
      "Mean of last 30000: 0.05832110224226555\n",
      "30100: 0.06327751278877258\n",
      "30100: 0.04992770403623581\n",
      "30200: 0.06063491851091385\n",
      "30200: 0.06229448318481445\n",
      "30300: 0.0652955025434494\n",
      "30300: 0.06012897193431854\n",
      "30400: 0.05680614709854126\n",
      "30400: 0.06548326462507248\n",
      "30500: 0.05662877857685089\n",
      "30500: 0.05624905973672867\n",
      "30600: 0.05634324997663498\n",
      "30600: 0.052575599402189255\n",
      "30700: 0.054753001779317856\n",
      "30700: 0.05849720165133476\n",
      "30800: 0.05207430571317673\n",
      "30800: 0.06533290445804596\n",
      "30900: 0.0524483323097229\n",
      "30900: 0.05834483727812767\n",
      "31000: 0.05853548273444176\n",
      "31000: 0.05812598392367363\n",
      "Mean of last 31000: 0.058475443486730894\n",
      "31100: 0.06032282114028931\n",
      "31100: 0.05873812735080719\n",
      "31200: 0.05389547348022461\n",
      "31200: 0.06522886455059052\n",
      "31300: 0.06049308925867081\n",
      "31300: 0.05723376199603081\n",
      "31400: 0.05726940929889679\n",
      "31400: 0.057253118604421616\n",
      "31500: 0.06687156856060028\n",
      "31500: 0.06261062622070312\n",
      "31600: 0.06285959482192993\n",
      "31600: 0.060841213911771774\n",
      "31700: 0.054504361003637314\n",
      "31700: 0.05598966404795647\n",
      "31800: 0.06427969038486481\n",
      "31800: 0.06461014598608017\n",
      "31900: 0.05722177028656006\n",
      "31900: 0.07380064576864243\n",
      "32000: 0.05935301631689072\n",
      "32000: 0.05272936075925827\n",
      "Mean of last 32000: 0.05819478271516053\n",
      "32100: 0.057352226227521896\n",
      "32100: 0.05755988880991936\n",
      "32200: 0.055688586086034775\n",
      "32200: 0.05791844055056572\n",
      "32300: 0.055955030024051666\n",
      "32300: 0.05382929742336273\n",
      "32400: 0.06777693331241608\n",
      "32400: 0.07140204310417175\n",
      "32500: 0.05796964466571808\n",
      "32500: 0.05341976508498192\n",
      "32600: 0.053065285086631775\n",
      "32600: 0.05216033384203911\n",
      "32700: 0.06083950400352478\n",
      "32700: 0.05456877499818802\n",
      "32800: 0.059526603668928146\n",
      "32800: 0.06447020173072815\n",
      "32900: 0.05544240400195122\n",
      "32900: 0.059166572988033295\n",
      "33000: 0.06520712375640869\n",
      "33000: 0.0563918761909008\n",
      "Mean of last 33000: 0.05809880941399149\n",
      "33100: 0.06096413731575012\n",
      "33100: 0.05602158233523369\n",
      "33200: 0.05688732862472534\n",
      "33200: 0.054962702095508575\n",
      "33300: 0.05444444343447685\n",
      "33300: 0.055144935846328735\n",
      "33400: 0.05797019600868225\n",
      "33400: 0.05185292288661003\n",
      "33500: 0.05666952580213547\n",
      "33500: 0.0521291121840477\n",
      "33600: 0.06279346346855164\n",
      "33600: 0.06250704079866409\n",
      "33700: 0.051615819334983826\n",
      "33700: 0.06381693482398987\n",
      "33800: 0.057254862040281296\n",
      "33800: 0.051879823207855225\n",
      "33900: 0.05672486871480942\n",
      "33900: 0.06390812993049622\n",
      "34000: 0.06359519064426422\n",
      "34000: 0.0625750720500946\n",
      "Mean of last 34000: 0.05788469752789913\n",
      "34100: 0.05401176959276199\n",
      "34100: 0.05443795770406723\n",
      "34200: 0.05518302321434021\n",
      "34200: 0.05594926327466965\n",
      "34300: 0.049478840082883835\n",
      "34300: 0.06656508147716522\n",
      "34400: 0.054646603763103485\n",
      "34400: 0.05602308362722397\n",
      "34500: 0.06415251642465591\n",
      "34500: 0.05851680040359497\n",
      "34600: 0.057378679513931274\n",
      "34600: 0.06334882974624634\n",
      "34700: 0.05364086478948593\n",
      "34700: 0.06623958051204681\n",
      "34800: 0.05885886773467064\n",
      "34800: 0.06486646831035614\n",
      "34900: 0.06321459263563156\n",
      "34900: 0.06126534193754196\n",
      "35000: 0.049896206706762314\n",
      "35000: 0.05237400159239769\n",
      "Mean of last 35000: 0.05774611871425327\n",
      "35100: 0.06843092292547226\n",
      "35100: 0.04765776917338371\n",
      "35200: 0.05514958128333092\n",
      "35200: 0.06124972552061081\n",
      "35300: 0.05494951456785202\n",
      "35300: 0.06130392476916313\n",
      "35400: 0.053668063133955\n",
      "35400: 0.06078636273741722\n",
      "35500: 0.05779387801885605\n",
      "35500: 0.052603572607040405\n",
      "35600: 0.059731435030698776\n",
      "35600: 0.05737048387527466\n",
      "35700: 0.06877731531858444\n",
      "35700: 0.06036762520670891\n",
      "35800: 0.053581297397613525\n",
      "35800: 0.05939716100692749\n",
      "35900: 0.05681533366441727\n",
      "35900: 0.05551831051707268\n",
      "36000: 0.051812104880809784\n",
      "36000: 0.061212919652462006\n",
      "Mean of last 36000: 0.057827269725434546\n",
      "36100: 0.05183728039264679\n",
      "36100: 0.0558575801551342\n",
      "36200: 0.057769618928432465\n",
      "36200: 0.05496780201792717\n",
      "36300: 0.0537259578704834\n",
      "36300: 0.06536762416362762\n",
      "36400: 0.056080661714076996\n",
      "36400: 0.06821821630001068\n",
      "36500: 0.05644962191581726\n",
      "36500: 0.05836358666419983\n",
      "36600: 0.05811747908592224\n",
      "36600: 0.06713484972715378\n",
      "36700: 0.052054762840270996\n",
      "36700: 0.055183153599500656\n",
      "36800: 0.05756136029958725\n",
      "36800: 0.05476243793964386\n",
      "36900: 0.05464312434196472\n",
      "36900: 0.06193618103861809\n",
      "37000: 0.06093219667673111\n",
      "37000: 0.059898119419813156\n",
      "Mean of last 37000: 0.0576229137159162\n",
      "37100: 0.05515096336603165\n",
      "37100: 0.050370316952466965\n",
      "37200: 0.05785026773810387\n",
      "37200: 0.06698942929506302\n",
      "37300: 0.05705399066209793\n",
      "37300: 0.05058030039072037\n",
      "37400: 0.059924643486738205\n",
      "37400: 0.0653250440955162\n",
      "37500: 0.06487967818975449\n",
      "37500: 0.06871393322944641\n",
      "37600: 0.057535670697689056\n",
      "37600: 0.04971989989280701\n",
      "37700: 0.05344943702220917\n",
      "37700: 0.0551014244556427\n",
      "37800: 0.06077556312084198\n",
      "37800: 0.05445317551493645\n",
      "37900: 0.0578327476978302\n",
      "37900: 0.05650681257247925\n",
      "38000: 0.056838177144527435\n",
      "38000: 0.05659669637680054\n",
      "Mean of last 38000: 0.057454424914899285\n",
      "38100: 0.05559391900897026\n",
      "38100: 0.05911749228835106\n",
      "38200: 0.0643923431634903\n",
      "38200: 0.05172182247042656\n",
      "38300: 0.0533541664481163\n",
      "38300: 0.06032650172710419\n",
      "38400: 0.05452324077486992\n",
      "38400: 0.06105382740497589\n",
      "38500: 0.05484443157911301\n",
      "38500: 0.05401214212179184\n",
      "38600: 0.06119903177022934\n",
      "38600: 0.0552612841129303\n",
      "38700: 0.05760935693979263\n",
      "38700: 0.060005538165569305\n",
      "38800: 0.05598027631640434\n",
      "38800: 0.05596490204334259\n",
      "38900: 0.06923417747020721\n",
      "38900: 0.05422036349773407\n",
      "39000: 0.0485755018889904\n",
      "39000: 0.053332265466451645\n",
      "Mean of last 39000: 0.057304472700654564\n",
      "39100: 0.06608356535434723\n",
      "39100: 0.05315418168902397\n",
      "39200: 0.05032220482826233\n",
      "39200: 0.06635954976081848\n",
      "39300: 0.07548942416906357\n",
      "39300: 0.05574081838130951\n",
      "39400: 0.056718237698078156\n",
      "39400: 0.07023051381111145\n",
      "39500: 0.06253597140312195\n",
      "39500: 0.05707324668765068\n",
      "39600: 0.05583808943629265\n",
      "39600: 0.052347492426633835\n",
      "39700: 0.059401027858257294\n",
      "39700: 0.0504535436630249\n",
      "39800: 0.05904918164014816\n",
      "39800: 0.05418955907225609\n",
      "39900: 0.06620334088802338\n",
      "39900: 0.0635349377989769\n",
      "40000: 0.07212480902671814\n",
      "40000: 0.05251554399728775\n",
      "Mean of last 40000: 0.05739744555216272\n",
      "40100: 0.053367819637060165\n",
      "40100: 0.05941835045814514\n",
      "40200: 0.057976290583610535\n",
      "40200: 0.062261246144771576\n",
      "40300: 0.04762952774763107\n",
      "40300: 0.055661797523498535\n",
      "40400: 0.06455142796039581\n",
      "40400: 0.056790418922901154\n",
      "40500: 0.06871379911899567\n",
      "40500: 0.06887482851743698\n",
      "40600: 0.048213716596364975\n",
      "40600: 0.05522366613149643\n",
      "40700: 0.05332019180059433\n",
      "40700: 0.05302591249346733\n",
      "40800: 0.061267878860235214\n",
      "40800: 0.06145476549863815\n",
      "40900: 0.05435403436422348\n",
      "40900: 0.0571453720331192\n",
      "41000: 0.050938405096530914\n",
      "41000: 0.06023544818162918\n",
      "Mean of last 41000: 0.05698774475325178\n",
      "41100: 0.0548337921500206\n",
      "41100: 0.056718479841947556\n",
      "41200: 0.05853007733821869\n",
      "41200: 0.05599118396639824\n",
      "41300: 0.0623883381485939\n",
      "41300: 0.05289490148425102\n",
      "41400: 0.06032449007034302\n",
      "41400: 0.05155601724982262\n",
      "41500: 0.05548795312643051\n",
      "41500: 0.06076790392398834\n",
      "41600: 0.056644000113010406\n",
      "41600: 0.06301627308130264\n",
      "41700: 0.05483422800898552\n",
      "41700: 0.05886135622859001\n",
      "41800: 0.052499525249004364\n",
      "41800: 0.05631018429994583\n",
      "41900: 0.0567280575633049\n",
      "41900: 0.049765072762966156\n",
      "42000: 0.060773830860853195\n",
      "42000: 0.0622582733631134\n",
      "Mean of last 42000: 0.056949139234947634\n",
      "42100: 0.05798623710870743\n",
      "42100: 0.05239880084991455\n",
      "42200: 0.05926584452390671\n",
      "42200: 0.05619058012962341\n",
      "42300: 0.05591968446969986\n",
      "42300: 0.05603144317865372\n",
      "42400: 0.0580933541059494\n",
      "42400: 0.05199488252401352\n",
      "42500: 0.05807017534971237\n",
      "42500: 0.05745545029640198\n",
      "42600: 0.06119641661643982\n",
      "42600: 0.054795172065496445\n",
      "42700: 0.054332099854946136\n",
      "42700: 0.05707316845655441\n",
      "42800: 0.053890328854322433\n",
      "42800: 0.05310922861099243\n",
      "42900: 0.05381433293223381\n",
      "42900: 0.05288579314947128\n",
      "43000: 0.06332391500473022\n",
      "43000: 0.05525592714548111\n",
      "Mean of last 43000: 0.05701316272529153\n",
      "43100: 0.053660910576581955\n",
      "43100: 0.059922292828559875\n",
      "43200: 0.056939780712127686\n",
      "43200: 0.07395947724580765\n",
      "43300: 0.05959933251142502\n",
      "43300: 0.052843209356069565\n",
      "43400: 0.06486766040325165\n",
      "43400: 0.06263350695371628\n",
      "43500: 0.05221479386091232\n",
      "43500: 0.06246381253004074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43600: 0.06692329049110413\n",
      "43600: 0.049400489777326584\n",
      "43700: 0.04944548010826111\n",
      "43700: 0.06485666334629059\n",
      "43800: 0.05283121019601822\n",
      "43800: 0.06146940588951111\n",
      "43900: 0.06254786252975464\n",
      "43900: 0.05715715140104294\n",
      "44000: 0.05585648864507675\n",
      "44000: 0.05447451397776604\n",
      "Mean of last 44000: 0.05706732476187812\n",
      "44100: 0.05766493082046509\n",
      "44100: 0.054457731544971466\n",
      "44200: 0.06150113046169281\n",
      "44200: 0.05321021005511284\n",
      "44300: 0.05614892765879631\n",
      "44300: 0.0603424534201622\n",
      "44400: 0.05122390016913414\n",
      "44400: 0.05484074354171753\n",
      "44500: 0.05995931476354599\n",
      "44500: 0.05013582110404968\n",
      "44600: 0.05127326399087906\n",
      "44600: 0.06195414066314697\n",
      "44700: 0.05567854270339012\n",
      "44700: 0.0545332096517086\n",
      "44800: 0.056248586624860764\n",
      "44800: 0.0513850562274456\n",
      "44900: 0.05366077274084091\n",
      "44900: 0.05993074178695679\n",
      "45000: 0.047229453921318054\n",
      "45000: 0.046768467873334885\n",
      "Mean of last 45000: 0.056857575421462525\n",
      "45100: 0.05544225126504898\n",
      "45100: 0.06812845170497894\n",
      "45200: 0.05194106698036194\n",
      "45200: 0.05761175975203514\n",
      "45300: 0.052878450602293015\n",
      "45300: 0.055184945464134216\n",
      "45400: 0.05490558594465256\n",
      "45400: 0.059460997581481934\n",
      "45500: 0.055230628699064255\n",
      "45500: 0.05783068761229515\n",
      "45600: 0.05733875930309296\n",
      "45600: 0.06142324209213257\n",
      "45700: 0.060101430863142014\n",
      "45700: 0.06254567205905914\n",
      "45800: 0.060747288167476654\n",
      "45800: 0.06441393494606018\n",
      "45900: 0.050875671207904816\n",
      "45900: 0.06750108301639557\n",
      "46000: 0.05420389026403427\n",
      "46000: 0.05462309718132019\n",
      "Mean of last 46000: 0.05663469736534101\n",
      "46100: 0.051189836114645004\n",
      "46100: 0.04903728514909744\n",
      "46200: 0.059601545333862305\n",
      "46200: 0.05613034591078758\n",
      "46300: 0.06525527685880661\n",
      "46300: 0.05624290928244591\n",
      "46400: 0.05950417369604111\n",
      "46400: 0.05406472086906433\n",
      "46500: 0.06371026486158371\n",
      "46500: 0.053032755851745605\n",
      "46600: 0.05096307396888733\n",
      "46600: 0.04875517636537552\n",
      "46700: 0.05625616014003754\n",
      "46700: 0.05147217959165573\n",
      "46800: 0.06366698443889618\n",
      "46800: 0.05498456954956055\n",
      "46900: 0.05185885354876518\n",
      "46900: 0.05518754571676254\n",
      "47000: 0.059738121926784515\n",
      "47000: 0.05100027844309807\n",
      "Mean of last 47000: 0.056478310703903765\n",
      "47100: 0.05627664923667908\n",
      "47100: 0.060075730085372925\n",
      "47200: 0.050537072122097015\n",
      "47200: 0.049445539712905884\n",
      "47300: 0.05899196118116379\n",
      "47300: 0.05128167197108269\n",
      "47400: 0.05638524144887924\n",
      "47400: 0.05643923208117485\n",
      "47500: 0.05116172134876251\n",
      "47500: 0.05109267681837082\n",
      "47600: 0.05036495625972748\n",
      "47600: 0.04951908811926842\n",
      "47700: 0.06258207559585571\n",
      "47700: 0.05623476952314377\n",
      "47800: 0.05291187763214111\n",
      "47800: 0.05870547518134117\n",
      "47900: 0.05783258005976677\n",
      "47900: 0.05383221432566643\n",
      "48000: 0.0558227077126503\n",
      "48000: 0.05931749567389488\n",
      "Mean of last 48000: 0.05672273799017831\n",
      "48100: 0.05759283900260925\n",
      "48100: 0.0524517297744751\n",
      "48200: 0.054884862154722214\n",
      "48200: 0.05710805207490921\n",
      "48300: 0.0626552402973175\n",
      "48300: 0.05952601879835129\n",
      "48400: 0.054880574345588684\n",
      "48400: 0.05185927078127861\n",
      "48500: 0.05153054744005203\n",
      "48500: 0.05610005185008049\n",
      "48600: 0.05225691199302673\n",
      "48600: 0.058469682931900024\n",
      "48700: 0.060884468257427216\n",
      "48700: 0.05367600917816162\n",
      "48800: 0.062245748937129974\n",
      "48800: 0.054396044462919235\n",
      "48900: 0.050670139491558075\n",
      "48900: 0.05503825843334198\n",
      "49000: 0.056291431188583374\n",
      "49000: 0.0626046359539032\n",
      "Mean of last 49000: 0.05651881176788549\n",
      "49100: 0.062304385006427765\n",
      "49100: 0.05887306481599808\n",
      "49200: 0.05503128096461296\n",
      "49200: 0.057321932166814804\n",
      "49300: 0.05810324847698212\n",
      "49300: 0.055984240025281906\n",
      "49400: 0.04979116842150688\n",
      "49400: 0.051166873425245285\n",
      "49500: 0.05911048874258995\n",
      "49500: 0.06155123561620712\n",
      "49600: 0.056342512369155884\n",
      "49600: 0.045130036771297455\n",
      "49700: 0.0643930584192276\n",
      "49700: 0.06687494367361069\n",
      "49800: 0.057956330478191376\n",
      "49800: 0.04818958044052124\n",
      "49900: 0.04886236414313316\n",
      "49900: 0.04925213381648064\n",
      "50000: 0.06385674327611923\n",
      "50000: 0.05356670171022415\n",
      "Mean of last 50000: 0.05646935212132814\n",
      "50100: 0.05249854177236557\n",
      "50100: 0.05470556020736694\n",
      "50200: 0.05110456794500351\n",
      "50200: 0.05661332607269287\n",
      "50300: 0.057027872651815414\n",
      "50300: 0.05286722630262375\n",
      "50400: 0.060386866331100464\n",
      "50400: 0.052633605897426605\n",
      "50500: 0.06302106380462646\n",
      "50500: 0.07380377501249313\n",
      "50600: 0.06695795059204102\n",
      "50600: 0.05356556177139282\n",
      "50700: 0.05565237998962402\n",
      "50700: 0.06633596122264862\n",
      "50800: 0.057168107479810715\n",
      "50800: 0.056539617478847504\n",
      "50900: 0.055385053157806396\n",
      "50900: 0.05418185889720917\n",
      "51000: 0.04631010815501213\n",
      "51000: 0.05101190134882927\n",
      "Mean of last 51000: 0.05638614673349824\n",
      "51100: 0.056871503591537476\n",
      "51100: 0.05083327740430832\n",
      "51200: 0.050515785813331604\n",
      "51200: 0.053095996379852295\n",
      "51300: 0.06253444403409958\n",
      "51300: 0.05885554105043411\n",
      "51400: 0.05329982563853264\n",
      "51400: 0.05789528414607048\n",
      "51500: 0.055514417588710785\n",
      "51500: 0.05151655524969101\n",
      "51600: 0.05250298231840134\n",
      "51600: 0.048508040606975555\n",
      "51700: 0.04957204684615135\n",
      "51700: 0.05317311733961105\n",
      "51800: 0.05055975541472435\n",
      "51800: 0.05138298496603966\n",
      "51900: 0.05326439067721367\n",
      "51900: 0.055010031908750534\n",
      "52000: 0.06716042757034302\n",
      "52000: 0.0520157590508461\n",
      "Mean of last 52000: 0.05632861494482099\n",
      "52100: 0.051282577216625214\n",
      "52100: 0.046421170234680176\n",
      "52200: 0.051255252212285995\n",
      "52200: 0.05383288860321045\n",
      "52300: 0.05507243797183037\n",
      "52300: 0.05439131706953049\n",
      "52400: 0.055641524493694305\n",
      "52400: 0.05063356086611748\n",
      "52500: 0.08057676255702972\n",
      "52500: 0.05975760146975517\n",
      "52600: 0.050821781158447266\n",
      "52600: 0.05593261867761612\n",
      "52700: 0.04976750537753105\n",
      "52700: 0.0574648454785347\n",
      "52800: 0.05943978950381279\n",
      "52800: 0.05368911847472191\n",
      "52900: 0.050678253173828125\n",
      "52900: 0.05887088179588318\n",
      "53000: 0.04971285164356232\n",
      "53000: 0.05016767233610153\n",
      "Mean of last 53000: 0.056274566384447326\n",
      "53100: 0.059198033064603806\n",
      "53100: 0.05899592861533165\n",
      "53200: 0.04847472906112671\n",
      "53200: 0.052842043340206146\n",
      "53300: 0.051656972616910934\n",
      "53300: 0.05678681656718254\n",
      "53400: 0.0523010790348053\n",
      "53400: 0.061178676784038544\n",
      "53500: 0.05499010905623436\n",
      "53500: 0.05744219943881035\n",
      "53600: 0.05645378679037094\n",
      "53600: 0.04804440587759018\n",
      "53700: 0.06198606640100479\n",
      "53700: 0.061449017375707626\n",
      "53800: 0.05366794764995575\n",
      "53800: 0.0659833550453186\n",
      "53900: 0.055551331490278244\n",
      "53900: 0.047468289732933044\n",
      "54000: 0.05094417929649353\n",
      "54000: 0.061195723712444305\n",
      "Mean of last 54000: 0.05629960898045715\n",
      "54100: 0.05498456209897995\n",
      "54100: 0.05237048864364624\n",
      "54200: 0.05908036231994629\n",
      "54200: 0.05341377109289169\n",
      "54300: 0.0698469802737236\n",
      "54300: 0.06250451505184174\n",
      "54400: 0.05677088350057602\n",
      "54400: 0.05250319093465805\n",
      "54500: 0.056507449597120285\n",
      "54500: 0.056955620646476746\n",
      "54900: 0.05859090015292168\n",
      "54900: 0.0567975752055645\n",
      "55000: 0.05041792243719101\n",
      "55000: 0.05886472389101982\n",
      "Mean of last 55000: 0.05610922620176793\n",
      "55100: 0.055760156363248825\n",
      "55100: 0.0653090849518776\n",
      "55200: 0.05759359523653984\n",
      "55200: 0.058723628520965576\n",
      "55300: 0.057230185717344284\n",
      "55300: 0.05192960798740387\n",
      "55400: 0.0557900033891201\n",
      "55400: 0.05560290813446045\n",
      "55500: 0.05843385308980942\n",
      "55500: 0.048083141446113586\n",
      "55600: 0.05132823437452316\n",
      "55600: 0.053762104362249374\n",
      "55700: 0.06190384551882744\n",
      "55700: 0.06223386526107788\n",
      "55800: 0.05264247581362724\n",
      "55800: 0.05447733402252197\n",
      "55900: 0.06671562045812607\n",
      "55900: 0.05603356286883354\n",
      "56000: 0.056341078132390976\n",
      "56000: 0.054198019206523895\n",
      "Mean of last 56000: 0.05604839402173723\n",
      "56100: 0.05614530295133591\n",
      "56100: 0.05657768249511719\n",
      "56200: 0.05748516321182251\n",
      "56200: 0.049022771418094635\n",
      "56300: 0.056591376662254333\n",
      "56300: 0.05432429164648056\n",
      "56400: 0.06569074839353561\n",
      "56400: 0.05463729053735733\n",
      "56500: 0.05286677926778793\n",
      "56500: 0.05410231277346611\n",
      "56600: 0.06329423189163208\n",
      "56600: 0.05749835819005966\n",
      "56700: 0.0511518195271492\n",
      "56700: 0.05814511328935623\n",
      "56800: 0.05906176194548607\n",
      "56800: 0.054197005927562714\n",
      "56900: 0.05231788381934166\n",
      "56900: 0.05390365421772003\n",
      "57000: 0.05565924569964409\n",
      "57000: 0.056342437863349915\n",
      "Mean of last 57000: 0.056152892471119\n",
      "57100: 0.0506988987326622\n",
      "57100: 0.05864788591861725\n",
      "57200: 0.053494226187467575\n",
      "57200: 0.049038272351026535\n",
      "57300: 0.04854297637939453\n",
      "57300: 0.06118394434452057\n",
      "57400: 0.05894699692726135\n",
      "57400: 0.05895432457327843\n",
      "57500: 0.05606244131922722\n",
      "57500: 0.05948565527796745\n",
      "57600: 0.05045199394226074\n",
      "57600: 0.062360189855098724\n",
      "57700: 0.04992760345339775\n",
      "57700: 0.05045018717646599\n",
      "57800: 0.06021518260240555\n",
      "57800: 0.06316928565502167\n",
      "57900: 0.0596521720290184\n",
      "57900: 0.04960815608501434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58000: 0.06226753816008568\n",
      "58000: 0.05025523900985718\n",
      "Mean of last 58000: 0.055992533998949066\n",
      "58100: 0.05943102762103081\n",
      "58100: 0.06110147386789322\n",
      "58200: 0.06048579141497612\n",
      "58200: 0.0485861599445343\n",
      "58300: 0.05043044313788414\n",
      "58300: 0.064607173204422\n",
      "58400: 0.06025899946689606\n",
      "58400: 0.054099660366773605\n",
      "58500: 0.059862010180950165\n",
      "58500: 0.052016206085681915\n",
      "58600: 0.04996626079082489\n",
      "58600: 0.05623811483383179\n",
      "58700: 0.05557810515165329\n",
      "58700: 0.05674177408218384\n",
      "58800: 0.05635207146406174\n",
      "58800: 0.0506301075220108\n",
      "58900: 0.047315336763858795\n",
      "58900: 0.053199660032987595\n",
      "59000: 0.06573687493801117\n",
      "59000: 0.05299895256757736\n",
      "Mean of last 59000: 0.05582693374932527\n",
      "59100: 0.04894034191966057\n",
      "59100: 0.05840916186571121\n",
      "59200: 0.05469835549592972\n",
      "59200: 0.05581087991595268\n",
      "59300: 0.060465551912784576\n",
      "59300: 0.05151300132274628\n",
      "59400: 0.0548187792301178\n",
      "59400: 0.054058875888586044\n",
      "59500: 0.0528680793941021\n",
      "59500: 0.04744710028171539\n",
      "59600: 0.058691661804914474\n",
      "59600: 0.05736662074923515\n",
      "59700: 0.06258638203144073\n",
      "59700: 0.05146855115890503\n",
      "59800: 0.057396821677684784\n",
      "59800: 0.054485954344272614\n",
      "59900: 0.04790325090289116\n",
      "59900: 0.055932216346263885\n",
      "60000: 0.04717676341533661\n",
      "60000: 0.05498775467276573\n",
      "Mean of last 60000: 0.05576972972478841\n",
      "60100: 0.05667591094970703\n",
      "60100: 0.05370081588625908\n",
      "60200: 0.057215116918087006\n",
      "60200: 0.05920615792274475\n",
      "60300: 0.05233246833086014\n",
      "60300: 0.04921811446547508\n",
      "60400: 0.05638289451599121\n",
      "60400: 0.04891246557235718\n",
      "60500: 0.05626588687300682\n",
      "60500: 0.05264103412628174\n",
      "60600: 0.05598185583949089\n",
      "60600: 0.061559777706861496\n",
      "60700: 0.061631135642528534\n",
      "60700: 0.05662970244884491\n",
      "60800: 0.052768535912036896\n",
      "60800: 0.05855853483080864\n",
      "60900: 0.05926099419593811\n",
      "60900: 0.05689153075218201\n",
      "61000: 0.05870196223258972\n",
      "61000: 0.06249874830245972\n",
      "Mean of last 61000: 0.05610212595290416\n",
      "61100: 0.05875531584024429\n",
      "61100: 0.06538524478673935\n",
      "61200: 0.05581280589103699\n",
      "61200: 0.0516183041036129\n",
      "61300: 0.05101821944117546\n",
      "61300: 0.05627202242612839\n",
      "61400: 0.057964228093624115\n",
      "61400: 0.05117906630039215\n",
      "61500: 0.05882607027888298\n",
      "61500: 0.06200365722179413\n",
      "61600: 0.049678903073072433\n",
      "61600: 0.061674825847148895\n",
      "61700: 0.056031763553619385\n",
      "61700: 0.06417225301265717\n",
      "61800: 0.05878020077943802\n",
      "61800: 0.04678860306739807\n",
      "61900: 0.058286964893341064\n",
      "61900: 0.06147650629281998\n",
      "62000: 0.06342476606369019\n",
      "62000: 0.05526043474674225\n",
      "Mean of last 62000: 0.05603267884739748\n",
      "62100: 0.04783937335014343\n",
      "62100: 0.05909695476293564\n",
      "62200: 0.0546039454638958\n",
      "62200: 0.042234089225530624\n",
      "62300: 0.06350371241569519\n",
      "62300: 0.04726308584213257\n",
      "62400: 0.06026060879230499\n",
      "62400: 0.06039879843592644\n",
      "62500: 0.05174834281206131\n",
      "62500: 0.05444830283522606\n",
      "62600: 0.051281969994306564\n",
      "62600: 0.056639134883880615\n",
      "62700: 0.05896015092730522\n",
      "62700: 0.051564574241638184\n",
      "62800: 0.05419359728693962\n",
      "62800: 0.057411424815654755\n",
      "62900: 0.05343025550246239\n",
      "62900: 0.05496656894683838\n",
      "63000: 0.059584327042102814\n",
      "63000: 0.055545344948768616\n",
      "Mean of last 63000: 0.05580885660695982\n",
      "63100: 0.052935890853405\n",
      "63100: 0.056625913828611374\n",
      "63200: 0.05120871216058731\n",
      "63200: 0.056458692997694016\n",
      "63300: 0.049066781997680664\n",
      "63300: 0.05388733372092247\n",
      "63400: 0.04809875041246414\n",
      "63400: 0.05464520305395126\n",
      "63500: 0.054117947816848755\n",
      "63500: 0.05311621353030205\n",
      "63600: 0.0595637671649456\n",
      "63600: 0.052500903606414795\n",
      "63700: 0.052634283900260925\n",
      "63700: 0.05461473390460014\n",
      "63800: 0.059856217354536057\n",
      "63800: 0.05415883660316467\n",
      "63900: 0.06880571693181992\n",
      "63900: 0.05047747120261192\n",
      "64000: 0.057343076914548874\n",
      "64000: 0.04348047822713852\n",
      "Mean of last 64000: 0.055856376050875615\n",
      "64100: 0.049972593784332275\n",
      "64100: 0.05279488489031792\n",
      "64200: 0.053629856556653976\n",
      "64200: 0.053147684782743454\n",
      "64300: 0.04761221632361412\n",
      "64300: 0.05365285277366638\n",
      "64400: 0.05830390378832817\n",
      "64400: 0.049937598407268524\n",
      "64500: 0.05257871001958847\n",
      "64500: 0.06087980419397354\n",
      "64600: 0.05244870111346245\n",
      "64600: 0.0522356852889061\n",
      "64700: 0.048856016248464584\n",
      "64700: 0.06294849514961243\n",
      "64800: 0.0526566281914711\n",
      "64800: 0.054073430597782135\n",
      "64900: 0.05902653932571411\n",
      "64900: 0.06126291677355766\n",
      "65000: 0.05101954936981201\n",
      "65000: 0.0566432923078537\n",
      "Mean of last 65000: 0.05547473648122021\n",
      "65100: 0.06514199078083038\n",
      "65100: 0.05320955440402031\n",
      "65200: 0.05233866721391678\n",
      "65200: 0.053451985120773315\n",
      "65300: 0.05277625843882561\n",
      "65300: 0.054321449249982834\n",
      "65400: 0.056722190231084824\n",
      "65400: 0.05304109305143356\n",
      "65500: 0.05064959451556206\n",
      "65500: 0.05121568962931633\n",
      "65600: 0.05655405670404434\n",
      "65600: 0.05676689371466637\n",
      "65700: 0.049992285668849945\n",
      "65700: 0.05530667304992676\n",
      "65800: 0.05741630122065544\n",
      "65800: 0.054153233766555786\n",
      "65900: 0.05213502049446106\n",
      "65900: 0.059900544583797455\n",
      "66000: 0.05500095337629318\n",
      "66000: 0.055618107318878174\n",
      "Mean of last 66000: 0.055653085418559095\n",
      "66100: 0.05221972614526749\n",
      "66100: 0.06085832417011261\n",
      "66200: 0.04720952361822128\n",
      "66200: 0.05260395631194115\n",
      "66300: 0.06135323643684387\n",
      "66300: 0.05298032611608505\n",
      "66400: 0.055907510221004486\n",
      "66400: 0.05821792036294937\n",
      "66500: 0.05697999522089958\n",
      "66500: 0.05171864852309227\n",
      "66600: 0.05648193508386612\n",
      "66600: 0.05719630420207977\n",
      "66700: 0.05192871019244194\n",
      "66700: 0.05585557967424393\n",
      "66800: 0.05504196882247925\n",
      "66800: 0.05407609045505524\n",
      "66900: 0.051323018968105316\n",
      "66900: 0.05575871095061302\n",
      "67000: 0.04735385626554489\n",
      "67000: 0.0471586138010025\n",
      "Mean of last 67000: 0.05576811806781666\n",
      "67100: 0.05266670137643814\n",
      "67100: 0.06114871799945831\n",
      "67200: 0.051040660589933395\n",
      "67200: 0.053734324872493744\n",
      "67300: 0.06586616486310959\n",
      "67300: 0.06376321613788605\n",
      "67400: 0.047573354095220566\n",
      "67400: 0.05942313000559807\n",
      "67500: 0.058404915034770966\n",
      "67500: 0.051006853580474854\n",
      "67600: 0.05342657491564751\n",
      "67600: 0.056061722338199615\n",
      "67700: 0.05672401189804077\n",
      "67700: 0.052353035658597946\n",
      "67800: 0.054410599172115326\n",
      "67800: 0.06719865649938583\n",
      "67900: 0.050303321331739426\n",
      "67900: 0.05573016032576561\n",
      "68000: 0.06498686224222183\n",
      "68000: 0.06159007549285889\n",
      "Mean of last 68000: 0.05559163450353689\n",
      "68100: 0.047551363706588745\n",
      "68100: 0.05825517699122429\n",
      "68200: 0.05587686598300934\n",
      "68200: 0.05137715861201286\n",
      "68300: 0.05873747169971466\n",
      "68300: 0.06009156256914139\n",
      "68400: 0.05437041446566582\n",
      "68400: 0.050734248012304306\n",
      "68500: 0.05039535462856293\n",
      "68500: 0.0563691221177578\n",
      "68600: 0.050352565944194794\n",
      "68600: 0.05442452058196068\n",
      "68700: 0.0589212104678154\n",
      "68700: 0.05279241129755974\n",
      "68800: 0.05986546725034714\n",
      "68800: 0.06272102892398834\n",
      "68900: 0.05455498397350311\n",
      "68900: 0.05849280580878258\n",
      "69000: 0.044756364077329636\n",
      "69000: 0.04937155544757843\n",
      "Mean of last 69000: 0.0554393401218729\n",
      "69100: 0.055658888071775436\n",
      "69100: 0.057268038392066956\n",
      "69200: 0.055004995316267014\n",
      "69200: 0.051396023482084274\n",
      "69300: 0.06061230227351189\n",
      "69300: 0.05445275455713272\n",
      "69400: 0.047863081097602844\n",
      "69400: 0.051223378628492355\n",
      "69500: 0.050642043352127075\n",
      "69500: 0.058870039880275726\n",
      "69600: 0.044259727001190186\n",
      "69600: 0.048113685101270676\n",
      "69700: 0.05442536622285843\n",
      "69700: 0.06251423805952072\n",
      "69800: 0.06279616802930832\n",
      "69800: 0.0641997754573822\n",
      "69900: 0.04896245524287224\n",
      "69900: 0.05338025838136673\n",
      "70000: 0.05114724859595299\n",
      "70000: 0.05529343709349632\n",
      "Mean of last 70000: 0.05541717864528343\n",
      "70100: 0.06265970319509506\n",
      "70100: 0.05767517536878586\n",
      "70200: 0.06305670738220215\n",
      "70200: 0.05397368595004082\n",
      "70300: 0.05450822040438652\n",
      "70300: 0.05261770635843277\n",
      "70400: 0.05474799498915672\n",
      "70400: 0.047303032130002975\n",
      "70500: 0.05675528198480606\n",
      "70500: 0.04712224006652832\n",
      "70600: 0.05159139633178711\n",
      "70600: 0.049125831574201584\n",
      "70700: 0.055558450520038605\n",
      "70700: 0.05246520787477493\n",
      "70800: 0.052299946546554565\n",
      "70800: 0.06387075781822205\n",
      "70900: 0.060490675270557404\n",
      "70900: 0.05112774297595024\n",
      "71000: 0.056224092841148376\n",
      "71000: 0.07144278287887573\n",
      "Mean of last 71000: 0.05524861791192533\n",
      "71100: 0.05208203196525574\n",
      "71100: 0.05461684986948967\n",
      "71200: 0.0590771809220314\n",
      "71200: 0.05218226835131645\n",
      "71300: 0.060435421764850616\n",
      "71300: 0.05583382770419121\n",
      "71400: 0.06560135632753372\n",
      "71400: 0.05296388268470764\n",
      "71500: 0.05243835970759392\n",
      "71500: 0.048216454684734344\n",
      "71600: 0.0488528236746788\n",
      "71600: 0.057687729597091675\n",
      "71700: 0.05692892521619797\n",
      "71700: 0.055248863995075226\n",
      "71800: 0.053143203258514404\n",
      "71800: 0.05731382593512535\n",
      "71900: 0.054265689104795456\n",
      "71900: 0.06087886914610863\n",
      "72000: 0.053373198956251144\n",
      "72000: 0.05860285088419914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of last 72000: 0.05535673210350843\n",
      "72100: 0.04661230742931366\n",
      "72100: 0.05883002281188965\n",
      "72200: 0.047776978462934494\n",
      "72200: 0.049521446228027344\n",
      "72300: 0.054706867784261703\n",
      "72300: 0.055216968059539795\n",
      "72400: 0.05545011907815933\n",
      "72400: 0.058833517134189606\n",
      "72500: 0.056362658739089966\n",
      "72500: 0.05196535214781761\n",
      "72600: 0.051948755979537964\n",
      "72600: 0.05595563352108002\n",
      "72700: 0.05182245373725891\n",
      "72700: 0.05763205140829086\n",
      "72800: 0.06260308623313904\n",
      "72800: 0.04808979481458664\n",
      "72900: 0.06164517253637314\n",
      "72900: 0.05711009353399277\n",
      "73000: 0.06015748903155327\n",
      "73000: 0.06201181560754776\n",
      "Mean of last 73000: 0.055538909561879984\n",
      "73100: 0.04867437481880188\n",
      "73100: 0.0639081597328186\n",
      "73200: 0.055124666541814804\n",
      "73200: 0.06317825615406036\n",
      "73300: 0.05741114541888237\n",
      "73300: 0.05865609273314476\n",
      "73400: 0.060170553624629974\n",
      "73400: 0.049821637570858\n",
      "73500: 0.052909910678863525\n",
      "73500: 0.057162731885910034\n",
      "73600: 0.05872786045074463\n",
      "73600: 0.05071994662284851\n",
      "73700: 0.06654693931341171\n",
      "73700: 0.05578409880399704\n",
      "73800: 0.052446018904447556\n",
      "73800: 0.04986792430281639\n",
      "73900: 0.06084228307008743\n",
      "73900: 0.0543680340051651\n",
      "74000: 0.05710693448781967\n",
      "74000: 0.05551314353942871\n",
      "Mean of last 74000: 0.05553094771217097\n",
      "74100: 0.057486873120069504\n",
      "74100: 0.054108403623104095\n",
      "74200: 0.050958242267370224\n",
      "74200: 0.048329126089811325\n",
      "74300: 0.05693589895963669\n",
      "74300: 0.04608837887644768\n",
      "74400: 0.054161436855793\n",
      "74400: 0.055123221129179\n",
      "74500: 0.05626074969768524\n",
      "74500: 0.050674766302108765\n",
      "74600: 0.058346062898635864\n",
      "74600: 0.05035228654742241\n",
      "74700: 0.04994496703147888\n",
      "74700: 0.06287321448326111\n",
      "74800: 0.052625589072704315\n",
      "74800: 0.06612150371074677\n",
      "74900: 0.052912890911102295\n",
      "74900: 0.045624345541000366\n",
      "75000: 0.05589994788169861\n",
      "75000: 0.05112191289663315\n",
      "Mean of last 75000: 0.05543250140066926\n",
      "75100: 0.05886801704764366\n",
      "75100: 0.06133954972028732\n",
      "75200: 0.05604056641459465\n",
      "75200: 0.05849100276827812\n",
      "75300: 0.06098894402384758\n",
      "75300: 0.05695746839046478\n",
      "75400: 0.053896091878414154\n",
      "75400: 0.05226109176874161\n",
      "75500: 0.05287018418312073\n",
      "75500: 0.0623161718249321\n",
      "75600: 0.07018522918224335\n",
      "75600: 0.05803360044956207\n",
      "75700: 0.06771425902843475\n",
      "75700: 0.05344393476843834\n",
      "75800: 0.06097138673067093\n",
      "75800: 0.055184505879879\n",
      "75900: 0.05548272654414177\n",
      "75900: 0.053687822073698044\n",
      "76000: 0.06153158098459244\n",
      "76000: 0.0469556599855423\n",
      "Mean of last 76000: 0.055331923058265814\n",
      "76100: 0.06334066390991211\n",
      "76100: 0.05247423052787781\n",
      "76200: 0.06063085049390793\n",
      "76200: 0.05046268552541733\n",
      "76300: 0.052938997745513916\n",
      "76300: 0.059065401554107666\n",
      "76400: 0.05623077601194382\n",
      "76400: 0.06682337820529938\n",
      "76500: 0.052412763237953186\n",
      "76500: 0.048376500606536865\n",
      "76600: 0.06068318337202072\n",
      "76600: 0.05589045211672783\n",
      "76700: 0.05840575695037842\n",
      "76700: 0.0533178374171257\n",
      "76800: 0.05620260164141655\n",
      "76800: 0.057945068925619125\n",
      "76900: 0.060251444578170776\n",
      "76900: 0.05061101168394089\n",
      "77000: 0.04971390217542648\n",
      "77000: 0.0641733929514885\n",
      "Mean of last 77000: 0.05527541622125007\n",
      "77100: 0.04942874237895012\n",
      "77100: 0.05372172221541405\n",
      "77200: 0.05597090348601341\n",
      "77200: 0.06526565551757812\n",
      "77300: 0.0501568540930748\n",
      "77300: 0.05748580023646355\n",
      "77400: 0.05019119381904602\n",
      "77400: 0.04770967364311218\n",
      "77500: 0.05821707099676132\n",
      "77500: 0.05982483550906181\n",
      "77600: 0.05939602851867676\n",
      "77600: 0.04701908677816391\n",
      "77700: 0.0572642907500267\n",
      "77700: 0.053871940821409225\n",
      "77800: 0.05679257959127426\n",
      "77800: 0.049466006457805634\n",
      "77900: 0.04955577105283737\n",
      "77900: 0.04999181628227234\n",
      "78000: 0.044463224709033966\n",
      "78000: 0.05812681466341019\n",
      "Mean of last 78000: 0.05536514588005536\n",
      "78100: 0.05889403820037842\n",
      "78100: 0.05667371302843094\n",
      "78200: 0.059832364320755005\n",
      "78200: 0.05456770211458206\n",
      "78300: 0.05984404683113098\n",
      "78300: 0.05710601434111595\n",
      "78400: 0.05422303080558777\n",
      "78400: 0.04856295883655548\n",
      "78500: 0.051334626972675323\n",
      "78500: 0.05165545269846916\n",
      "78600: 0.05031506344676018\n",
      "78600: 0.05705630034208298\n",
      "78700: 0.06054885312914848\n",
      "78700: 0.05489576607942581\n",
      "78800: 0.06309207528829575\n",
      "78800: 0.049586474895477295\n",
      "78900: 0.05124879628419876\n",
      "78900: 0.05788525938987732\n",
      "79000: 0.05135027691721916\n",
      "79000: 0.05601774901151657\n",
      "Mean of last 79000: 0.05522910870060876\n",
      "79100: 0.05456079542636871\n",
      "79100: 0.051345840096473694\n",
      "79200: 0.05524756759405136\n",
      "79200: 0.05562704801559448\n",
      "79300: 0.04809030517935753\n",
      "79300: 0.05216320604085922\n",
      "79400: 0.051859136670827866\n",
      "79400: 0.05464066192507744\n",
      "79500: 0.05687975138425827\n",
      "79500: 0.05955304950475693\n",
      "79600: 0.05898473784327507\n",
      "79600: 0.05198044702410698\n",
      "79700: 0.05382551997900009\n",
      "79700: 0.06188294291496277\n",
      "79800: 0.05581269785761833\n",
      "79800: 0.05312705785036087\n",
      "79900: 0.0589655302464962\n",
      "79900: 0.04864653944969177\n",
      "80000: 0.057403564453125\n",
      "80000: 0.05768425762653351\n",
      "Mean of last 80000: 0.05513817652665473\n",
      "80100: 0.054889243096113205\n",
      "80100: 0.05110689625144005\n",
      "80200: 0.05779820680618286\n",
      "80200: 0.05293450877070427\n",
      "80300: 0.050327569246292114\n",
      "80300: 0.05405957251787186\n",
      "80400: 0.05328685790300369\n",
      "80400: 0.05060071870684624\n",
      "80500: 0.062269411981105804\n",
      "80500: 0.04810255765914917\n",
      "80600: 0.05498269945383072\n",
      "80600: 0.05389055609703064\n",
      "80700: 0.059942569583654404\n",
      "80700: 0.05530034750699997\n",
      "80800: 0.0579703226685524\n",
      "80800: 0.05682744085788727\n",
      "80900: 0.05625031515955925\n",
      "80900: 0.05808567255735397\n",
      "81000: 0.0552639476954937\n",
      "81000: 0.0629102811217308\n",
      "Mean of last 81000: 0.055177571570182535\n",
      "81100: 0.053827401250600815\n",
      "81100: 0.055591948330402374\n",
      "81200: 0.0497342050075531\n",
      "81200: 0.054482877254486084\n",
      "81300: 0.0452205091714859\n",
      "81300: 0.06059759855270386\n",
      "81400: 0.05636948347091675\n",
      "81400: 0.05328921601176262\n",
      "81500: 0.06453072279691696\n",
      "81500: 0.05344226211309433\n",
      "81600: 0.05325755476951599\n",
      "81600: 0.053779035806655884\n",
      "81700: 0.057469673454761505\n",
      "81700: 0.06479457020759583\n",
      "81800: 0.055505476891994476\n",
      "81800: 0.04427272826433182\n",
      "81900: 0.051089271903038025\n",
      "81900: 0.05105786770582199\n",
      "82000: 0.05380314216017723\n",
      "82000: 0.04959563538432121\n",
      "Mean of last 82000: 0.05522260422279666\n",
      "82100: 0.048284631222486496\n",
      "82100: 0.05712088942527771\n",
      "82200: 0.04996431991457939\n",
      "82200: 0.05891719087958336\n",
      "82300: 0.06821289658546448\n",
      "82300: 0.05563950166106224\n",
      "82400: 0.05131238326430321\n",
      "82400: 0.05467812344431877\n",
      "82500: 0.06383740156888962\n",
      "82500: 0.05411786958575249\n",
      "82600: 0.052062712609767914\n",
      "82600: 0.05510411784052849\n",
      "82700: 0.050434410572052\n",
      "82700: 0.05179399251937866\n",
      "82800: 0.06174948066473007\n",
      "82800: 0.05430891364812851\n",
      "82900: 0.05354102700948715\n",
      "82900: 0.053385816514492035\n",
      "83000: 0.05709293484687805\n",
      "83000: 0.051590196788311005\n",
      "Mean of last 83000: 0.05516190193667934\n",
      "83100: 0.04894265532493591\n",
      "83100: 0.05673844739794731\n",
      "83200: 0.05690472573041916\n",
      "83200: 0.07206641882658005\n",
      "83300: 0.057952508330345154\n",
      "83300: 0.054613202810287476\n",
      "83400: 0.04964327812194824\n",
      "83400: 0.05045311152935028\n",
      "83500: 0.057000428438186646\n",
      "83500: 0.06389456987380981\n",
      "83600: 0.05168475955724716\n",
      "83600: 0.05497794598340988\n",
      "83700: 0.05352601408958435\n",
      "83700: 0.05128819867968559\n",
      "83800: 0.052389901131391525\n",
      "83800: 0.05735328793525696\n",
      "83900: 0.05641632899641991\n",
      "83900: 0.046330325305461884\n",
      "84000: 0.05399798974394798\n",
      "84000: 0.05368923768401146\n",
      "Mean of last 84000: 0.05511850558154352\n",
      "84100: 0.06389361619949341\n",
      "84100: 0.048369091004133224\n",
      "84200: 0.06134263426065445\n",
      "84200: 0.05386229604482651\n",
      "84300: 0.06465122103691101\n",
      "84300: 0.055355995893478394\n",
      "84400: 0.052031707018613815\n",
      "84400: 0.05954788252711296\n",
      "84500: 0.05965852737426758\n",
      "84500: 0.06714218109846115\n",
      "84600: 0.04850280284881592\n",
      "84600: 0.05851533263921738\n",
      "84700: 0.052661530673503876\n",
      "84700: 0.05408922955393791\n",
      "84800: 0.049355752766132355\n",
      "84800: 0.046788230538368225\n",
      "84900: 0.048753898590803146\n",
      "84900: 0.051359038800001144\n",
      "85000: 0.05728432536125183\n",
      "85000: 0.057722307741642\n",
      "Mean of last 85000: 0.05537446911868218\n",
      "85100: 0.05410700663924217\n",
      "85100: 0.06531275808811188\n",
      "85200: 0.051272060722112656\n",
      "85200: 0.06006568670272827\n",
      "85300: 0.05492696911096573\n",
      "85300: 0.04845237731933594\n",
      "85400: 0.05766448378562927\n",
      "85400: 0.04825238138437271\n",
      "85500: 0.05646916478872299\n",
      "85500: 0.054553624242544174\n",
      "85600: 0.043639421463012695\n",
      "85600: 0.06789010763168335\n",
      "85700: 0.05037064477801323\n",
      "85700: 0.050978273153305054\n",
      "85800: 0.061063699424266815\n",
      "85800: 0.06135764718055725\n",
      "85900: 0.05321214348077774\n",
      "85900: 0.05259593576192856\n",
      "86000: 0.0549393892288208\n",
      "86000: 0.058766912668943405\n",
      "86300: 0.05034273862838745\n",
      "86300: 0.06137735769152641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86400: 0.07506129890680313\n",
      "86400: 0.052501555532217026\n",
      "86500: 0.05830478295683861\n",
      "86500: 0.04809248447418213\n",
      "86600: 0.058127790689468384\n",
      "86600: 0.05676217004656792\n",
      "86700: 0.049844659864902496\n",
      "86700: 0.05104339122772217\n",
      "86800: 0.052617400884628296\n",
      "86800: 0.05531437322497368\n",
      "86900: 0.05549917370080948\n",
      "86900: 0.05447795242071152\n",
      "87000: 0.05583327263593674\n",
      "87000: 0.0507730171084404\n",
      "Mean of last 87000: 0.05510960696088327\n",
      "87100: 0.04834523797035217\n",
      "87100: 0.048225294798612595\n",
      "87200: 0.06107592582702637\n",
      "87200: 0.04395874962210655\n",
      "87300: 0.05068035051226616\n",
      "87300: 0.056810759007930756\n",
      "87400: 0.053541071712970734\n",
      "87400: 0.05670925974845886\n",
      "87500: 0.059514373540878296\n",
      "87500: 0.06257785111665726\n",
      "87600: 0.05926794931292534\n",
      "87600: 0.05672013759613037\n",
      "87700: 0.04883980005979538\n",
      "87700: 0.062461476773023605\n",
      "87800: 0.0589405857026577\n",
      "87800: 0.051410265266895294\n",
      "87900: 0.06435242295265198\n",
      "87900: 0.05215143784880638\n",
      "88000: 0.0523194819688797\n",
      "88000: 0.056800320744514465\n",
      "Mean of last 88000: 0.05507018191220758\n",
      "88100: 0.055381517857313156\n",
      "88100: 0.05363432317972183\n",
      "88200: 0.05594661831855774\n",
      "88200: 0.06912504136562347\n",
      "88300: 0.0715787410736084\n",
      "88300: 0.059531331062316895\n",
      "88400: 0.05521330237388611\n",
      "88400: 0.05062505230307579\n",
      "88500: 0.04924021288752556\n",
      "88500: 0.046834468841552734\n",
      "88600: 0.06629393994808197\n",
      "88600: 0.05330703407526016\n",
      "88700: 0.05672374367713928\n",
      "88700: 0.06926552206277847\n",
      "88800: 0.05315900966525078\n",
      "88800: 0.0543021559715271\n",
      "88900: 0.05178267881274223\n",
      "88900: 0.05399894341826439\n",
      "89000: 0.04878377169370651\n",
      "89000: 0.046957846730947495\n",
      "Mean of last 89000: 0.05504765337543352\n",
      "89100: 0.052436958998441696\n",
      "89100: 0.058555182069540024\n",
      "89200: 0.05911526083946228\n",
      "89200: 0.05732625722885132\n",
      "89300: 0.04809526726603508\n",
      "89300: 0.06402696669101715\n",
      "89700: 0.04945647716522217\n",
      "89700: 0.05241076275706291\n",
      "89800: 0.05182156711816788\n",
      "89800: 0.05090950429439545\n",
      "89900: 0.05398627743124962\n",
      "89900: 0.050238899886608124\n",
      "90000: 0.061595164239406586\n",
      "90000: 0.058028992265462875\n",
      "Mean of last 90000: 0.05487677308690774\n",
      "90100: 0.05442982539534569\n",
      "90100: 0.055279187858104706\n",
      "90200: 0.05476760119199753\n",
      "90200: 0.05397063493728638\n",
      "90300: 0.06016596779227257\n",
      "90300: 0.059784285724163055\n",
      "90400: 0.060807548463344574\n",
      "90400: 0.048468440771102905\n",
      "90500: 0.05324640870094299\n",
      "90500: 0.051094070076942444\n",
      "90600: 0.0577908419072628\n",
      "90600: 0.047972194850444794\n",
      "90700: 0.045851290225982666\n",
      "90700: 0.05310266464948654\n",
      "90800: 0.0540427565574646\n",
      "90800: 0.06224813312292099\n",
      "90900: 0.05613589286804199\n",
      "90900: 0.057371821254491806\n",
      "91000: 0.04950833320617676\n",
      "91000: 0.06197155639529228\n",
      "Mean of last 91000: 0.0550198710517033\n",
      "91100: 0.052061911672353745\n",
      "91100: 0.04983409494161606\n",
      "91200: 0.05227936431765556\n",
      "91200: 0.056604206562042236\n",
      "91300: 0.057626329362392426\n",
      "91300: 0.04943399876356125\n",
      "91400: 0.05481552332639694\n",
      "91400: 0.05775035545229912\n",
      "91500: 0.057435762137174606\n",
      "91500: 0.04794209823012352\n",
      "91600: 0.058370135724544525\n",
      "91600: 0.050591304898262024\n",
      "91700: 0.05367773026227951\n",
      "91700: 0.05528102442622185\n",
      "91800: 0.05402660369873047\n",
      "91800: 0.05255429074168205\n",
      "91900: 0.05746049806475639\n",
      "91900: 0.05743587762117386\n",
      "92000: 0.057713426649570465\n",
      "92000: 0.05112059414386749\n",
      "Mean of last 92000: 0.054832868847426594\n",
      "92100: 0.048717450350522995\n",
      "92100: 0.052949219942092896\n",
      "92200: 0.050578534603118896\n",
      "92200: 0.05200859159231186\n",
      "92300: 0.05267734453082085\n",
      "92300: 0.04939725622534752\n",
      "92400: 0.05835111066699028\n",
      "92400: 0.0536062978208065\n",
      "92500: 0.057009920477867126\n",
      "92500: 0.0496533177793026\n",
      "92600: 0.05759085714817047\n",
      "92600: 0.05259646475315094\n",
      "92700: 0.04615340381860733\n",
      "92700: 0.05170873925089836\n",
      "92800: 0.058122605085372925\n",
      "92800: 0.06379085779190063\n",
      "92900: 0.06094072014093399\n",
      "92900: 0.06590346992015839\n",
      "93000: 0.05853935331106186\n",
      "93000: 0.04960823804140091\n",
      "Mean of last 93000: 0.054912735003751\n",
      "93100: 0.062205761671066284\n",
      "93100: 0.051639359444379807\n",
      "93200: 0.059294819831848145\n",
      "93200: 0.05990191921591759\n",
      "93300: 0.054467543959617615\n",
      "93300: 0.05709938332438469\n",
      "93400: 0.05670614540576935\n",
      "93400: 0.05310039967298508\n",
      "93500: 0.05889188498258591\n",
      "93500: 0.06069366633892059\n",
      "93600: 0.07205754518508911\n",
      "93600: 0.05237151309847832\n",
      "93700: 0.04938072711229324\n",
      "93700: 0.05500176548957825\n",
      "93800: 0.04963494464755058\n",
      "93800: 0.05710818991065025\n",
      "93900: 0.05737197399139404\n",
      "93900: 0.05353999882936478\n",
      "94000: 0.05409974977374077\n",
      "94000: 0.06478109210729599\n",
      "Mean of last 94000: 0.054939780594570775\n",
      "94100: 0.0564521849155426\n",
      "94100: 0.04802783951163292\n",
      "94200: 0.04978456348180771\n",
      "94200: 0.05549267679452896\n",
      "94300: 0.050542086362838745\n",
      "94300: 0.049214333295822144\n",
      "94400: 0.051742684096097946\n",
      "94400: 0.05613713711500168\n",
      "94500: 0.05832088738679886\n",
      "94500: 0.049727313220500946\n",
      "94600: 0.04984460398554802\n",
      "94600: 0.046101897954940796\n",
      "94700: 0.05760733410716057\n",
      "94700: 0.052590511739254\n",
      "94800: 0.051777057349681854\n",
      "94800: 0.06277927756309509\n",
      "94900: 0.06117284297943115\n",
      "94900: 0.05553678795695305\n",
      "95000: 0.05727192014455795\n",
      "95000: 0.058766961097717285\n",
      "Mean of last 95000: 0.054798666959057205\n",
      "95100: 0.048141032457351685\n",
      "95100: 0.06043205410242081\n",
      "95200: 0.058381225913763046\n",
      "95200: 0.05654396861791611\n",
      "95300: 0.04667395353317261\n",
      "95300: 0.04996868222951889\n",
      "95400: 0.049468398094177246\n",
      "95400: 0.049145109951496124\n",
      "95500: 0.052926864475011826\n",
      "95500: 0.05769827589392662\n",
      "95600: 0.049601368606090546\n",
      "95600: 0.05625293403863907\n",
      "95700: 0.05402236804366112\n",
      "95700: 0.053043872117996216\n",
      "95800: 0.06130127236247063\n",
      "95800: 0.061551839113235474\n",
      "95900: 0.05591868981719017\n",
      "95900: 0.06012636050581932\n",
      "96000: 0.053151823580265045\n",
      "96000: 0.05086870118975639\n",
      "Mean of last 96000: 0.05491603588262995\n",
      "96100: 0.052328482270240784\n",
      "96100: 0.05777488276362419\n",
      "96200: 0.05896466225385666\n",
      "96200: 0.049677036702632904\n",
      "96300: 0.05542521923780441\n",
      "96300: 0.05113636702299118\n",
      "96400: 0.052386462688446045\n",
      "96400: 0.05080833658576012\n",
      "96500: 0.05025514215230942\n",
      "96500: 0.06332512199878693\n",
      "96600: 0.05240971967577934\n",
      "96600: 0.059503328055143356\n",
      "96700: 0.05945396423339844\n",
      "96700: 0.051981501281261444\n",
      "96800: 0.05495451018214226\n",
      "96800: 0.054285623133182526\n",
      "96900: 0.06502661108970642\n",
      "96900: 0.053928326815366745\n",
      "97000: 0.05947049707174301\n",
      "97000: 0.05167514085769653\n",
      "Mean of last 97000: 0.05477089663366457\n",
      "97100: 0.05680926889181137\n",
      "97100: 0.0474751740694046\n",
      "97200: 0.047932129353284836\n",
      "97200: 0.06411585211753845\n",
      "97300: 0.06233355402946472\n",
      "97300: 0.05586887523531914\n",
      "97400: 0.049759283661842346\n",
      "97400: 0.0577833466231823\n",
      "97500: 0.055800020694732666\n",
      "97500: 0.05783028528094292\n",
      "97600: 0.05387920141220093\n",
      "97600: 0.048818282783031464\n",
      "97700: 0.051229506731033325\n",
      "97700: 0.0528145395219326\n",
      "97800: 0.05266911908984184\n",
      "97800: 0.05877505987882614\n",
      "97900: 0.04895752668380737\n",
      "97900: 0.06071021407842636\n",
      "98000: 0.053065910935401917\n",
      "98000: 0.04920985549688339\n",
      "Mean of last 98000: 0.054830561744627894\n",
      "98100: 0.05481337755918503\n",
      "98100: 0.05210357531905174\n",
      "98200: 0.04815030097961426\n",
      "98200: 0.049280911684036255\n",
      "98300: 0.05979018658399582\n",
      "98300: 0.053853683173656464\n",
      "98400: 0.0503503791987896\n",
      "98400: 0.0515834242105484\n",
      "98500: 0.05654902011156082\n",
      "98500: 0.04485085606575012\n",
      "98600: 0.05131601542234421\n",
      "98600: 0.057958923280239105\n",
      "98700: 0.06307774037122726\n",
      "98700: 0.04772502928972244\n",
      "98800: 0.05539517104625702\n",
      "98800: 0.05582303926348686\n",
      "98900: 0.06710565090179443\n",
      "98900: 0.06493088603019714\n",
      "99000: 0.06695830076932907\n",
      "99000: 0.0643957108259201\n",
      "Mean of last 99000: 0.05480696147235183\n",
      "99100: 0.0593855045735836\n",
      "99100: 0.05580577254295349\n",
      "99200: 0.05166780948638916\n",
      "99200: 0.05217424035072327\n",
      "99300: 0.04852200672030449\n",
      "99300: 0.058526404201984406\n",
      "99400: 0.047331392765045166\n",
      "99400: 0.060535214841365814\n",
      "99500: 0.052306197583675385\n",
      "99500: 0.049359869211912155\n",
      "99600: 0.050565119832754135\n",
      "99600: 0.05148402601480484\n",
      "99700: 0.04519931599497795\n",
      "99700: 0.05634244903922081\n",
      "99800: 0.04700801894068718\n",
      "99800: 0.057900719344615936\n",
      "99900: 0.05186019092798233\n",
      "99900: 0.05850079655647278\n",
      "100000: 0.051966797560453415\n",
      "100000: 0.053924791514873505\n",
      "Mean of last 100000: 0.05479593615193705\n",
      "100100: 0.05159352347254753\n",
      "100100: 0.043378107249736786\n",
      "100200: 0.05116531252861023\n",
      "100200: 0.05126163363456726\n",
      "100300: 0.04703789949417114\n",
      "100300: 0.05090136453509331\n",
      "100400: 0.04546962305903435\n",
      "100400: 0.06108696013689041\n",
      "100500: 0.06205558776855469\n",
      "100500: 0.05079052969813347\n",
      "100600: 0.057490818202495575\n",
      "100600: 0.05187831446528435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100700: 0.0491824671626091\n",
      "100700: 0.0593436062335968\n",
      "100800: 0.05843053758144379\n",
      "100800: 0.04991501197218895\n",
      "100900: 0.05392683669924736\n",
      "100900: 0.04854113981127739\n",
      "101000: 0.05327954888343811\n",
      "101000: 0.05175359174609184\n",
      "Mean of last 101000: 0.05459483454634736\n",
      "101100: 0.04236907511949539\n",
      "101100: 0.06339385360479355\n",
      "101200: 0.051036536693573\n",
      "101200: 0.054109930992126465\n",
      "101300: 0.05273902416229248\n",
      "101300: 0.054089367389678955\n",
      "101400: 0.05734430253505707\n",
      "101400: 0.05360274761915207\n",
      "101500: 0.05687251314520836\n",
      "101500: 0.057145021855831146\n",
      "101600: 0.05145154520869255\n",
      "101600: 0.05227992683649063\n",
      "101700: 0.05520119518041611\n",
      "101700: 0.06432244181632996\n",
      "101800: 0.06578636169433594\n",
      "101800: 0.0505249947309494\n",
      "101900: 0.052096616476774216\n",
      "101900: 0.06150878965854645\n",
      "102000: 0.0567222461104393\n",
      "102000: 0.0509864017367363\n",
      "Mean of last 102000: 0.054636798676226166\n",
      "102100: 0.06166496500372887\n",
      "102100: 0.05667005106806755\n",
      "102200: 0.05575151368975639\n",
      "102200: 0.05775140970945358\n",
      "102300: 0.05217086523771286\n",
      "102300: 0.05711157247424126\n",
      "102400: 0.05671652406454086\n",
      "102400: 0.050613150000572205\n",
      "102500: 0.0620574876666069\n",
      "102500: 0.0475224070250988\n",
      "102600: 0.05268437787890434\n",
      "102600: 0.05006670951843262\n",
      "102700: 0.047639600932598114\n",
      "102700: 0.05000927299261093\n",
      "102800: 0.056297801434993744\n",
      "102800: 0.06174706667661667\n",
      "102900: 0.0585503876209259\n",
      "102900: 0.05949673801660538\n",
      "103000: 0.06479164958000183\n",
      "103000: 0.0503324531018734\n",
      "Mean of last 103000: 0.05450009381385533\n",
      "103100: 0.053172510117292404\n",
      "103100: 0.05235406011343002\n",
      "103200: 0.05412900447845459\n",
      "103200: 0.056217920035123825\n",
      "103300: 0.05405057594180107\n",
      "103300: 0.054156284779310226\n",
      "103400: 0.05293111130595207\n",
      "103400: 0.05503162741661072\n",
      "103500: 0.0522080734372139\n",
      "103500: 0.05202972888946533\n",
      "103600: 0.05467399209737778\n",
      "103600: 0.05338779091835022\n",
      "103700: 0.06198780983686447\n",
      "103700: 0.05689005181193352\n",
      "103800: 0.05601624771952629\n",
      "103800: 0.054022304713726044\n",
      "103900: 0.047319453209638596\n",
      "103900: 0.05632294341921806\n",
      "104000: 0.078542560338974\n",
      "104000: 0.04895243048667908\n",
      "Mean of last 104000: 0.05468464628993334\n",
      "104100: 0.056681983172893524\n",
      "104100: 0.05542895942926407\n",
      "104200: 0.050182830542325974\n",
      "104200: 0.05291737616062164\n",
      "104300: 0.06095929071307182\n",
      "104300: 0.05497671291232109\n",
      "104400: 0.055145975202322006\n",
      "104400: 0.053833507001399994\n",
      "104500: 0.05889899283647537\n",
      "104500: 0.05935264751315117\n",
      "104600: 0.0532236211001873\n",
      "104600: 0.06500489264726639\n",
      "104700: 0.05884452909231186\n",
      "104700: 0.05547497794032097\n",
      "104800: 0.05758379027247429\n",
      "104800: 0.05118688941001892\n",
      "104900: 0.05753868445754051\n",
      "104900: 0.05809870362281799\n",
      "105000: 0.049547743052244186\n",
      "105000: 0.05034826323390007\n",
      "Mean of last 105000: 0.054795272626005094\n",
      "105100: 0.06656288355588913\n",
      "105100: 0.047685589641332626\n",
      "105200: 0.05545220896601677\n",
      "105200: 0.05172565579414368\n",
      "105300: 0.05696703493595123\n",
      "105300: 0.06366676092147827\n",
      "105400: 0.05917477607727051\n",
      "105400: 0.058217864483594894\n",
      "105500: 0.05302230641245842\n",
      "105500: 0.055352579802274704\n",
      "105600: 0.06229659914970398\n",
      "105600: 0.05373680219054222\n",
      "105700: 0.05506717413663864\n",
      "105700: 0.05333054065704346\n",
      "105800: 0.05488710105419159\n",
      "105800: 0.05764263868331909\n",
      "105900: 0.05365332216024399\n",
      "105900: 0.0525352917611599\n",
      "106000: 0.053386133164167404\n",
      "106000: 0.053470730781555176\n",
      "Mean of last 106000: 0.05474602399611628\n",
      "106100: 0.045337460935115814\n",
      "106100: 0.06040311977267265\n",
      "106200: 0.056505244225263596\n",
      "106200: 0.050307851284742355\n",
      "106300: 0.05050746724009514\n",
      "106300: 0.05705321580171585\n",
      "106400: 0.04899480566382408\n",
      "106400: 0.05628760904073715\n",
      "106500: 0.0480639711022377\n",
      "106500: 0.05247639864683151\n",
      "106600: 0.04535294696688652\n",
      "106600: 0.05217771977186203\n",
      "106700: 0.05575376749038696\n",
      "106700: 0.05176512897014618\n",
      "106800: 0.052875369787216187\n",
      "106800: 0.05763824284076691\n",
      "106900: 0.0523359477519989\n",
      "106900: 0.059519410133361816\n",
      "107000: 0.060146402567625046\n",
      "107000: 0.05698094889521599\n",
      "Mean of last 107000: 0.05449310169703179\n",
      "107100: 0.05722728371620178\n",
      "107100: 0.05210410803556442\n",
      "107200: 0.05190451070666313\n",
      "107200: 0.05232689902186394\n",
      "107300: 0.06376871466636658\n",
      "107300: 0.06222803518176079\n",
      "107400: 0.05407646298408508\n",
      "107400: 0.05002177879214287\n",
      "107500: 0.0574178546667099\n",
      "107500: 0.0548766665160656\n",
      "107600: 0.05210227891802788\n",
      "107600: 0.054230716079473495\n",
      "107700: 0.057191282510757446\n",
      "107700: 0.05195101350545883\n",
      "107800: 0.04864104092121124\n",
      "107800: 0.050888072699308395\n",
      "107900: 0.06022097170352936\n",
      "107900: 0.05850186571478844\n",
      "108000: 0.05653650313615799\n",
      "108000: 0.05582413822412491\n",
      "Mean of last 108000: 0.05468187698690625\n",
      "108100: 0.05668538436293602\n",
      "108100: 0.05577319115400314\n",
      "108200: 0.052735429257154465\n",
      "108200: 0.05520377680659294\n",
      "108300: 0.05201960727572441\n",
      "108300: 0.06880456209182739\n",
      "108400: 0.05042826384305954\n",
      "108400: 0.04947129637002945\n",
      "108500: 0.05097794532775879\n",
      "108500: 0.060059644281864166\n",
      "108600: 0.05148876830935478\n",
      "108600: 0.05968521535396576\n",
      "108700: 0.05419669672846794\n",
      "108700: 0.06100330874323845\n",
      "108800: 0.05204778537154198\n",
      "108800: 0.05220327526330948\n",
      "108900: 0.04919005185365677\n",
      "108900: 0.0523923859000206\n",
      "109000: 0.05008677393198013\n",
      "109000: 0.06342180073261261\n",
      "Mean of last 109000: 0.05477727423203396\n",
      "109100: 0.06460870057344437\n",
      "109100: 0.0432620570063591\n",
      "109200: 0.051682811230421066\n",
      "109200: 0.05370263755321503\n",
      "109300: 0.06489147245883942\n",
      "109300: 0.05595618486404419\n",
      "109400: 0.05453161522746086\n",
      "109400: 0.05677809566259384\n",
      "109500: 0.0503849983215332\n",
      "109500: 0.05317084118723869\n",
      "109600: 0.050807785242795944\n",
      "109600: 0.060909777879714966\n",
      "109700: 0.0569324791431427\n",
      "109700: 0.05323054641485214\n",
      "109800: 0.05647249147295952\n",
      "109800: 0.05682481825351715\n",
      "109900: 0.04865286871790886\n",
      "109900: 0.0604591891169548\n",
      "110000: 0.04914893954992294\n",
      "110000: 0.05762719362974167\n",
      "Mean of last 110000: 0.054553700099279595\n",
      "110100: 0.049510836601257324\n",
      "110100: 0.060612522065639496\n",
      "110200: 0.05697896331548691\n",
      "110200: 0.05324653908610344\n",
      "110300: 0.048676878213882446\n",
      "110300: 0.05355678126215935\n",
      "110400: 0.058334819972515106\n",
      "110400: 0.051615890115499496\n",
      "110500: 0.049055278301239014\n",
      "110500: 0.06139616295695305\n",
      "110600: 0.06292833387851715\n",
      "110600: 0.05239998549222946\n",
      "110700: 0.06429648399353027\n",
      "110700: 0.05420013517141342\n",
      "110800: 0.05455949902534485\n",
      "110800: 0.04925768822431564\n",
      "110900: 0.04884248971939087\n",
      "110900: 0.050930123776197433\n",
      "111000: 0.06351101398468018\n",
      "111000: 0.04947607219219208\n",
      "Mean of last 111000: 0.05471577307211233\n",
      "111100: 0.05676719546318054\n",
      "111100: 0.04644013196229935\n",
      "111200: 0.052644334733486176\n",
      "111200: 0.06401468813419342\n",
      "111300: 0.05529480427503586\n",
      "111300: 0.06428168714046478\n",
      "111400: 0.04855173081159592\n",
      "111400: 0.05972534418106079\n",
      "111500: 0.0519656166434288\n",
      "111500: 0.049775850027799606\n",
      "111600: 0.04923390597105026\n",
      "111600: 0.05509398877620697\n",
      "111700: 0.052951764315366745\n",
      "111700: 0.04434504359960556\n",
      "111800: 0.049017757177352905\n",
      "111800: 0.052521489560604095\n",
      "111900: 0.05932919681072235\n",
      "111900: 0.058589354157447815\n",
      "112000: 0.05406753718852997\n",
      "112000: 0.05417940020561218\n",
      "Mean of last 112000: 0.05460786184744461\n",
      "112100: 0.05583515763282776\n",
      "112100: 0.06223878264427185\n",
      "112200: 0.05676284432411194\n",
      "112200: 0.059164997190237045\n",
      "112300: 0.041974689811468124\n",
      "112300: 0.04945659637451172\n",
      "112400: 0.05924222990870476\n",
      "112400: 0.050240181386470795\n",
      "112500: 0.05245447903871536\n",
      "112500: 0.06138045713305473\n",
      "112600: 0.055895186960697174\n",
      "112600: 0.05668305605649948\n",
      "112700: 0.05474245175719261\n",
      "112700: 0.04455394670367241\n",
      "112800: 0.05219417065382004\n",
      "112800: 0.05646920204162598\n",
      "112900: 0.05903512239456177\n",
      "112900: 0.06761014461517334\n",
      "113000: 0.06137213110923767\n",
      "113000: 0.05961822718381882\n",
      "Mean of last 113000: 0.05433789689417605\n",
      "113100: 0.05279170721769333\n",
      "113100: 0.05987677723169327\n",
      "113200: 0.05888267606496811\n",
      "113200: 0.07762569189071655\n",
      "113300: 0.05016649514436722\n",
      "113300: 0.06872482597827911\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_469/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m                 \u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{self.step}: {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, *args, **kwargs)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'height and width of image must be {img_size}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataset_Aug1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mp_losses\u001b[0;34m(self, x_start, x_end, t)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_routine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Final'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0mx_mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_end\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mx_recon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdenoise_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_start\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx_recon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, time)\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconvnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvnext2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownsample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdowns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvnext2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, time_emb)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b c -> b c 1 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mres_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_469/1202521062.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munbiased\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPreNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
